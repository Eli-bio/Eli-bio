{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eli-bio/Eli-bio/blob/main/Pathrise_Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY3GITtRV_3b"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "fSvk9k0l3I9e",
        "outputId": "230e6976-2f57-49b3-8936-0515812e90eb"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eec2a873-5cb7-4f99-a683-a346043ddfa1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eec2a873-5cb7-4f99-a683-a346043ddfa1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ed2fd71b4a2f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    165\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVvIH3FxWfws"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41IZvmrrWTM1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('Data_Pathrise (1).xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2_aa7-z4Qz8"
      },
      "outputs": [],
      "source": [
        "!pip install lime shap\n",
        "!pip install altair_viewer altair vega_datasets\n",
        "!pip install category_encoders\n",
        "!pip install shapash\n",
        "!pip install catboost\n",
        "!pip uninstall lightgbm -y\n",
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUo1mjkK4R7m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import altair as alt\n",
        "import altair_viewer\n",
        "from vega_datasets import data\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from shapash.data.data_loader import data_loading\n",
        "from shapash import SmartExplainer\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from scipy import stats\n",
        "from scipy.stats import norm\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.subplots as sp\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from scipy.interpolate import interp2d\n",
        "from scipy.stats import gaussian_kde\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import re\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor, BaggingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_validate, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import make_scorer\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, cross_validate, cross_val_predict\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import re\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu7bWBySm3mH"
      },
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\", color_codes=True)\n",
        "sns.set(font_scale=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN9ghDgq4VnL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('Data_Pathrise (1).xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4UzH6CJ0O5Q"
      },
      "outputs": [],
      "source": [
        "columns_to_consider = [col for col in df.columns if col != 'id']\n",
        "duplicates = df.duplicated(subset=columns_to_consider, keep='first')\n",
        "num_duplicates = duplicates.sum()\n",
        "print(\"Number of duplicated rows (excluding the first occurrence):\", num_duplicates)\n",
        "print(df[duplicates])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pboVoxjv4aNa"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr6dGr8-5pNs"
      },
      "source": [
        "Columns:\n",
        "\n",
        "1.   pathrise_status\n",
        "2.   primary_track\n",
        "2.   cohort_tag\n",
        "\n",
        "Targets:\n",
        "\n",
        "1.   placed\n",
        "2.   program_duration_days\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZBxAaRq8d-1"
      },
      "source": [
        "Number of missing values for these 3 columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng0fTSypPYch"
      },
      "source": [
        "# **Exploratory data analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2hylBpX4srZ"
      },
      "outputs": [],
      "source": [
        "missing_values = df[['pathrise_status', 'primary_track', 'cohort_tag']].isnull().sum()\n",
        "\n",
        "fig = go.Figure(data=[go.Bar(\n",
        "    x=missing_values.index,\n",
        "    y=missing_values.values,\n",
        "    # Assign vibrant colors for each bar\n",
        "    marker_color=['#E63946', '#F4C430', '#0077B6'],  # Bright red, saffron, and vivid blue\n",
        "    # marker_line_color='rgb(8,48,107)',  # Deep blue for border color of the bars\n",
        "    # marker_line_width=1.5,  # Border width of the bars to make them stand out\n",
        "    opacity=0.8)])  # Slightly higher opacity for richer color presentation\n",
        "\n",
        "# Enhancing the layout with specified aesthetic preferences\n",
        "fig.update_layout(\n",
        "    title='Number of Missing Values for Selected Columns (Filtered Data)',\n",
        "    xaxis_title='Column',\n",
        "    yaxis=dict(title='Number of Missing Values'),\n",
        "    title_x=0.5,  # Center the title\n",
        "    paper_bgcolor='white',  # Background color\n",
        "    # title_font=dict(size=22, color='RebeccaPurple'),  # Title styling\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),  # Font styling\n",
        "    legend_title_font_color='green',  # Legend title font color\n",
        "    width=700,\n",
        "    height=500)\n",
        "\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipsC0cBqVMeT"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby('pathrise_status').size().reset_index(name='count')\n",
        "total_entries = df.shape[0]\n",
        "df_grouped['percentage'] = (df_grouped['count'] / total_entries) * 100\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Dataroadmap/grouped_dataframe.csv'\n",
        "\n",
        "df_grouped.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XiRlyLXXLWc"
      },
      "outputs": [],
      "source": [
        "\n",
        "file_path = '/content/drive/MyDrive/Dataroadmap/grouped_dataframe.csv'\n",
        "\n",
        "df_grouped = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ed4f3Sb-pzL"
      },
      "source": [
        "Classification based on the pathrise_status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbGkld1w-vmO"
      },
      "outputs": [],
      "source": [
        "# Create the plot with an enhanced visual style\n",
        "fig = px.bar(df_grouped, x='pathrise_status', y='percentage',\n",
        "             text='count',\n",
        "             labels={'pathrise_status': 'Pathrise Status', 'percentage': 'Percentage'},\n",
        "             title='Distribution of Pathrise Status',\n",
        "             color='percentage',\n",
        "             color_continuous_scale='Agsunset')\n",
        "\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside',\n",
        "                  marker_line_color='rgb(8,48,107)',\n",
        "                  marker_line_width=0,\n",
        "                  opacity=0.6)\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Pathrise Status',\n",
        "    yaxis=dict(title='Percentage'),\n",
        "    title_x=0.5,\n",
        "    paper_bgcolor='white',\n",
        "    # title_font=dict(size=22, color='RebeccaPurple'),\n",
        "    font=dict(family='Raleway, sans-serif'),\n",
        "    legend_title_font_color='green',\n",
        "    width=800,\n",
        "    height=600,\n",
        "    coloraxis_colorbar=dict(title='Percentage %')\n",
        ")\n",
        "\n",
        "fig.update_layout(coloraxis=dict(colorscale='Bluered_r'))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rsn49-l6Qac"
      },
      "source": [
        "Targets:\n",
        "\n",
        "1.   placed\n",
        "2.   program_duration_days\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJagXbXtzI8n"
      },
      "outputs": [],
      "source": [
        "custom_colors = ['#FF6384', '#36A2EB', '#FFCE56', '#4BC0C0', '#9966FF', '#FF9F40', '#C9CBCF', '#FFC0CB']\n",
        "\n",
        "# Create the Pie Chart with Custom Colors\n",
        "fig = px.pie(\n",
        "    df_grouped,\n",
        "    names='pathrise_status',\n",
        "    values='percentage',\n",
        "    title='Distribution of Pathrise Status',\n",
        "    color='pathrise_status',  # Assign a unique color to each 'pathrise_status' category\n",
        "    color_discrete_sequence=custom_colors,  # Use the custom color sequence\n",
        "    hole=0.3  # Create a donut-like appearance\n",
        ")\n",
        "\n",
        "# Enhancements and Layout Customization\n",
        "fig.update_traces(\n",
        "    textinfo='percent+label',  # Display percentage and label for clarity\n",
        "    pull=[0.1 if i == df_grouped['percentage'].idxmax() else 0 for i in range(len(df_grouped))]\n",
        "    # Emphasize the largest segment by pulling it out\n",
        ")\n",
        "fig.update_layout(\n",
        "    title_x=0.5,  # Center the title\n",
        "    paper_bgcolor='white',  # Clean white background\n",
        "    showlegend=True,  # Show the legend for reference\n",
        "    legend_title_text='Pathrise Status',  # Clarify the legend title\n",
        "    font=dict(\n",
        "        family='Raleway, sans-serif',  # Stylish sans-serif font\n",
        "        size=12,  # Readable text size\n",
        "        color='black'  # High-contrast text color\n",
        "    )\n",
        ")\n",
        "\n",
        "# Display the Pie Chart\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RWbNPgD_yPe"
      },
      "outputs": [],
      "source": [
        "mean_duration = df['program_duration_days'].mean()\n",
        "std_duration = df['program_duration_days'].std()\n",
        "\n",
        "mean_duration = df['program_duration_days'].mean()\n",
        "std_duration = df['program_duration_days'].std()\n",
        "\n",
        "# Generate the x values for the normal distribution curve\n",
        "x_values = np.linspace(df['program_duration_days'].min(), df['program_duration_days'].max(), 100)\n",
        "\n",
        "# Calculate the y values for the normal distribution curve\n",
        "y_values = norm.pdf(x_values, mean_duration, std_duration)\n",
        "\n",
        "# Adjust y_values if needed here to match your specific representation requirements\n",
        "\n",
        "# Histogram for the empirical distribution\n",
        "histogram = go.Histogram(\n",
        "    x=df['program_duration_days'],\n",
        "    name='Program Duration',\n",
        "    opacity=0.6,\n",
        "    marker=dict(color='dodgerblue', line=dict(color='white', width=2)),\n",
        "    nbinsx=30,\n",
        "    histnorm='probability density'  # Consider changing to 'probability' for percentage of total\n",
        ")\n",
        "\n",
        "# Line plot for the normal distribution\n",
        "line_plot = go.Scatter(\n",
        "    x=x_values,\n",
        "    y=y_values,\n",
        "    mode='lines',\n",
        "    name='Normal Distribution',\n",
        "    line=dict(color='Crimson', width=3, dash='dot')\n",
        ")\n",
        "\n",
        "# Create the figure and add both plots\n",
        "fig = go.Figure(data=[histogram, line_plot])\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Comparison of Program Duration Days with Normal Distribution',\n",
        "    title_x=0.5,\n",
        "    # title_font=dict(size=22, color='RebeccaPurple'),\n",
        "    xaxis_title='Program Duration Days',\n",
        "    yaxis=dict(title='Density (as % of Total)', tickformat=',.2%'),  # Display y-axis values as percentages\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    legend_title_font_color='green',\n",
        "    width=800, height=600\n",
        ")\n",
        "\n",
        "# Display the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv7lRtPWXZFg"
      },
      "outputs": [],
      "source": [
        "relevant_df = df.dropna(subset=['program_duration_days'])\n",
        "\n",
        "mean_duration = relevant_df['program_duration_days'].mean()\n",
        "std_duration = relevant_df['program_duration_days'].std()\n",
        "\n",
        "# Generate the x values for the normal distribution curve\n",
        "x_values = np.linspace(relevant_df['program_duration_days'].min(), relevant_df['program_duration_days'].max(), 100)\n",
        "\n",
        "# Calculate the y values for the normal distribution curve\n",
        "y_values_norm = norm.pdf(x_values, mean_duration, std_duration)\n",
        "\n",
        "# Calculate the y values for the KDE\n",
        "kde = gaussian_kde(relevant_df['program_duration_days'])\n",
        "y_values_kde = kde(x_values)\n",
        "\n",
        "# Histogram for the empirical distribution\n",
        "histogram = go.Histogram(\n",
        "    x=relevant_df['program_duration_days'],\n",
        "    name='Program Duration',\n",
        "    opacity=0.6,\n",
        "    marker=dict(color='dodgerblue', line=dict(color='white', width=2)),\n",
        "    nbinsx=30,\n",
        "    histnorm='probability density'\n",
        ")\n",
        "\n",
        "# Line plot for the normal distribution\n",
        "line_plot_norm = go.Scatter(\n",
        "    x=x_values,\n",
        "    y=y_values_norm,\n",
        "    mode='lines',\n",
        "    name='Normal Distribution',\n",
        "    line=dict(color='Crimson', width=3, dash='dot')\n",
        ")\n",
        "\n",
        "# Line plot for the KDE\n",
        "line_plot_kde = go.Scatter(\n",
        "    x=x_values,\n",
        "    y=y_values_kde,\n",
        "    mode='lines',\n",
        "    name='KDE',\n",
        "    line=dict(color='green', width=3, dash='dash')\n",
        ")\n",
        "\n",
        "# Create the figure and add all plots\n",
        "fig = go.Figure(data=[histogram, line_plot_norm, line_plot_kde])\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Comparison of Program Duration Days with Normal Distribution and KDE',\n",
        "    title_x=0.5,\n",
        "    # title_font=dict(size=22, color='RebeccaPurple'),\n",
        "    xaxis_title='Program Duration Days',\n",
        "    yaxis=dict(title='Density (as % of Total)', tickformat=',.2%'),\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    legend_title_font_color='green',\n",
        "    width=800, height=600\n",
        ")\n",
        "\n",
        "# Display the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhAbWXF5xC0C"
      },
      "outputs": [],
      "source": [
        "placed_df = df[df['pathrise_status'] == 'Placed']\n",
        "\n",
        "# Calculate mean and standard deviation for program_duration_days of placed participants\n",
        "mean_duration = placed_df['program_duration_days'].mean()\n",
        "std_duration = placed_df['program_duration_days'].std()\n",
        "\n",
        "# Generate the x values for the normal distribution curve\n",
        "x_values = np.linspace(placed_df['program_duration_days'].min(), placed_df['program_duration_days'].max(), 100)\n",
        "\n",
        "# Calculate the y values for the normal distribution curve\n",
        "y_values = norm.pdf(x_values, mean_duration, std_duration)\n",
        "\n",
        "# Histogram for the empirical distribution of placed participants\n",
        "histogram = go.Histogram(\n",
        "    x=placed_df['program_duration_days'],\n",
        "    name='Program Duration of Placed Participants',\n",
        "    opacity=0.6,\n",
        "    marker=dict(color='dodgerblue', line=dict(color='white', width=2)),\n",
        "    # Set bin size to 5\n",
        "    xbins=dict(start=placed_df['program_duration_days'].min(), end=placed_df['program_duration_days'].max(), size=5),\n",
        "    histnorm='probability density'\n",
        ")\n",
        "\n",
        "# Line plot for the normal distribution\n",
        "line_plot = go.Scatter(\n",
        "    x=x_values,\n",
        "    y=y_values,\n",
        "    mode='lines',\n",
        "    name='Normal Distribution Fit',\n",
        "    line=dict(color='Crimson', width=3, dash='dot')\n",
        ")\n",
        "\n",
        "# Create the figure and add both plots\n",
        "fig = go.Figure(data=[histogram, line_plot])\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distribution of Program Duration Days for Placed Participants vs. Normal Distribution',\n",
        "    xaxis_title='Program Duration Days',\n",
        "    yaxis_title='Density',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    legend_title_font_color='green',\n",
        "    title_x=0.5,\n",
        "    width=1200, height=600\n",
        ")\n",
        "\n",
        "# Display the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOOFX18eYlI6"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[df['pathrise_status'] == 'Placed'].dropna(subset=['program_duration_days'])\n",
        "\n",
        "mean_duration = relevant_df['program_duration_days'].mean()\n",
        "std_duration = relevant_df['program_duration_days'].std()\n",
        "\n",
        "# Generate the x values for the normal distribution curve\n",
        "x_values = np.linspace(relevant_df['program_duration_days'].min(), relevant_df['program_duration_days'].max(), 100)\n",
        "\n",
        "# Calculate the y values for the normal distribution curve\n",
        "y_values_norm = norm.pdf(x_values, mean_duration, std_duration)\n",
        "\n",
        "# Calculate the y values for the KDE\n",
        "kde = gaussian_kde(relevant_df['program_duration_days'])\n",
        "y_values_kde = kde(x_values)\n",
        "\n",
        "# Histogram for the empirical distribution of placed participants\n",
        "histogram = go.Histogram(\n",
        "    x=relevant_df['program_duration_days'],\n",
        "    name='Program Duration of Placed Participants',\n",
        "    opacity=0.6,\n",
        "    marker=dict(color='dodgerblue', line=dict(color='white', width=2)),\n",
        "    xbins=dict(start=relevant_df['program_duration_days'].min(), end=relevant_df['program_duration_days'].max(), size=5),\n",
        "    histnorm='probability density'\n",
        ")\n",
        "\n",
        "# Line plot for the normal distribution\n",
        "line_plot_norm = go.Scatter(\n",
        "    x=x_values,\n",
        "    y=y_values_norm,\n",
        "    mode='lines',\n",
        "    name='Normal Distribution Fit',\n",
        "    line=dict(color='Crimson', width=3, dash='dot')\n",
        ")\n",
        "\n",
        "# Line plot for the KDE\n",
        "line_plot_kde = go.Scatter(\n",
        "    x=x_values,\n",
        "    y=y_values_kde,\n",
        "    mode='lines',\n",
        "    name='KDE Fit',\n",
        "    line=dict(color='green', width=3, dash='dash')\n",
        ")\n",
        "\n",
        "# Create the figure and add all plots\n",
        "fig = go.Figure(data=[histogram, line_plot_norm, line_plot_kde])\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distribution of Program Duration Days for Placed Participants vs. Normal Distribution and KDE',\n",
        "    xaxis_title='Program Duration Days',\n",
        "    yaxis_title='Density',\n",
        "    paper_bgcolor='white',\n",
        "    title_x=0.5,\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    legend_title_font_color='green',\n",
        "    width=1200, height=600\n",
        ")\n",
        "\n",
        "# Display the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chMlhzHR7bKU"
      },
      "outputs": [],
      "source": [
        "\n",
        "placed_df = df[df['pathrise_status'] == 'Placed']\n",
        "\n",
        "placed_df = placed_df[(placed_df['program_duration_days'] >= 14) & (placed_df['program_duration_days'] <= 365)]\n",
        "\n",
        "# Adjust the bin range to ensure it covers the max duration\n",
        "min_duration = 14  # Starting from 14 as we exclude durations less than 14\n",
        "max_duration = 365  # Upto 365 as we exclude durations more than 365\n",
        "bin_size = 5\n",
        "\n",
        "# Extend bins slightly beyond max duration to ensure the last data point is included\n",
        "bins = np.arange(min_duration, max_duration + bin_size + 1, bin_size)\n",
        "\n",
        "# Generate bin labels representing the range of each bin\n",
        "bin_labels = [f\"{int(left)}-{int(right)-1}\" for left, right in zip(bins[:-1], bins[1:])]\n",
        "\n",
        "# Initialize an array for counts per bin\n",
        "counts_per_bin = np.zeros(len(bins) - 1)\n",
        "\n",
        "# Generate bin labels representing the range of each bin\n",
        "bin_labels = [f\"{int(left)}-{int(right)-1}\" for left, right in zip(bins[:-1], bins[1:])]\n",
        "# Use np.digitize to find which bin each duration belongs to\n",
        "binned_indices = np.digitize(placed_df['program_duration_days'], bins, right=False)\n",
        "\n",
        "# Accumulate counts in each bin\n",
        "np.add.at(counts_per_bin, binned_indices-1, 1)\n",
        "\n",
        "# Create a subplot with adjusted row heights\n",
        "fig = make_subplots(rows=2, cols=1, row_heights=[0.3, 0.5], vertical_spacing=0.3,\n",
        "                    specs=[[{\"type\": \"box\"}], [{\"type\": \"heatmap\"}]])\n",
        "\n",
        "# Add a horizontal boxplot on the first row without showing its legend (we'll add an annotation instead)\n",
        "fig.add_trace(go.Box(x=placed_df['program_duration_days'], name='Program Duration',\n",
        "                      marker_color='blue', orientation='h', showlegend=False), row=1, col=1)\n",
        "\n",
        "# Calculate the mean of program durations\n",
        "mean_duration = placed_df['program_duration_days'].mean()\n",
        "\n",
        "# Add a scatter plot to mark the mean on the boxplot, also without showing its legend\n",
        "fig.add_trace(go.Scatter(x=[mean_duration], y=[0], mode='markers', marker=dict(color='red', size=10),\n",
        "                         name='Mean Duration', showlegend=False), row=1, col=1)\n",
        "\n",
        "# Add the heatmap on the second row\n",
        "fig.add_trace(go.Heatmap(z=[counts_per_bin], x=bin_labels, y=['Program Durations'], colorscale='Viridis',\n",
        "                         colorbar=dict(title='Number of Participants')), row=2, col=1)\n",
        "\n",
        "# Update layout to improve legend placement\n",
        "fig.update_layout(\n",
        "    title='Program Duration Days for Placed Participants with Boxplot Summary',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Arial, sans-serif', size=12, color='black'),\n",
        "    width=800, height=300,\n",
        "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
        ")\n",
        "\n",
        "\n",
        "# Display the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCDTo5L9ACHU"
      },
      "outputs": [],
      "source": [
        "placed_df = df[df['pathrise_status'] == 'Placed']\n",
        "\n",
        "# Set bin size to 5 days for granularity\n",
        "bin_size = 5\n",
        "max_duration = placed_df['program_duration_days'].max()\n",
        "bins = np.arange(0, max_duration + bin_size, bin_size)\n",
        "\n",
        "# Initialize an array for counts per bin\n",
        "counts_per_bin = np.zeros(len(bins) - 1)\n",
        "# Accumulate counts in each bin\n",
        "np.add.at(counts_per_bin, binned_indices-1, 1)\n",
        "\n",
        "# Generate bin labels representing the range of each bin\n",
        "bin_labels = [f\"{int(left)}-{int(right)-1}\" for left, right in zip(bins[:-1], bins[1:])]\n",
        "# Use np.digitize to find which bin each duration belongs to\n",
        "binned_indices = np.digitize(placed_df['program_duration_days'], bins, right=False)\n",
        "\n",
        "# Accumulate counts in each bin\n",
        "np.add.at(counts_per_bin, binned_indices-1, 1)\n",
        "\n",
        "# Create a subplot with adjusted row heights\n",
        "fig = make_subplots(rows=2, cols=1, row_heights=[0.3, 0.5], vertical_spacing=0.3,\n",
        "                    specs=[[{\"type\": \"box\"}], [{\"type\": \"heatmap\"}]])\n",
        "\n",
        "# Add a horizontal boxplot on the first row without showing its legend (we'll add an annotation instead)\n",
        "fig.add_trace(go.Box(x=placed_df['program_duration_days'], name='Program Duration',\n",
        "                      marker_color='blue', orientation='h', showlegend=False), row=1, col=1)\n",
        "\n",
        "# Calculate the mean of program durations\n",
        "mean_duration = placed_df['program_duration_days'].mean()\n",
        "\n",
        "# Add a scatter plot to mark the mean on the boxplot, also without showing its legend\n",
        "fig.add_trace(go.Scatter(x=[mean_duration], y=[0], mode='markers', marker=dict(color='red', size=10),\n",
        "                         name='Mean Duration', showlegend=False), row=1, col=1)\n",
        "\n",
        "# Add the heatmap on the second row\n",
        "fig.add_trace(go.Heatmap(z=[counts_per_bin], x=bin_labels, y=['Program Durations'], colorscale='Viridis',\n",
        "                         colorbar=dict(title='Number of Participants')), row=2, col=1)\n",
        "\n",
        "# Update layout to improve legend placement\n",
        "fig.update_layout(\n",
        "    title='Program Duration Days for Placed Participants with Boxplot Summary',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Arial, sans-serif', size=12, color='black'),\n",
        "    width=800, height=300,\n",
        "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
        ")\n",
        "\n",
        "\n",
        "# Display the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SOE6q9v_OPu"
      },
      "outputs": [],
      "source": [
        "placed_df = df[df['pathrise_status'] == 'Placed']\n",
        "\n",
        "# Set bin size to 5 days for granularity\n",
        "bin_size = 5\n",
        "max_duration = placed_df['program_duration_days'].max()\n",
        "bins = np.arange(0, max_duration + bin_size, bin_size)\n",
        "\n",
        "# Initialize an array for counts per bin\n",
        "counts_per_bin = np.zeros(len(bins) - 1)\n",
        "\n",
        "# Use np.digitize to find which bin each duration belongs to\n",
        "binned_indices = np.digitize(placed_df['program_duration_days'], bins, right=False)\n",
        "\n",
        "# Accumulate counts in each bin\n",
        "np.add.at(counts_per_bin, binned_indices-1, 1)\n",
        "\n",
        "# Generate bin labels representing the range of each bin\n",
        "bin_labels = [f\"{int(left)}-{int(right)-1}\" for left, right in zip(bins[:-1], bins[1:])]\n",
        "\n",
        "# Create a subplot with adjusted row heights\n",
        "fig = make_subplots(rows=2, cols=1, row_heights=[0.3, 0.5], vertical_spacing=0.3,\n",
        "                    specs=[[{\"type\": \"box\"}], [{\"type\": \"heatmap\"}]],\n",
        "                    shared_xaxes=False)  # Ensure x-axes are not shared\n",
        "\n",
        "# Add a horizontal boxplot on the first row\n",
        "fig.add_trace(go.Box(x=placed_df['program_duration_days'], name='', marker_color='blue', orientation='h'), row=1, col=1)\n",
        "\n",
        "# Add the heatmap on the second row\n",
        "fig.add_trace(go.Heatmap(z=[counts_per_bin], x=bin_labels, y=['Program Durations'], colorscale='Viridis',\n",
        "                         colorbar=dict(title='Number of Participants')), row=2, col=1)\n",
        "\n",
        "# Update layout for clarity and to manage axes individually\n",
        "fig.update_layout(\n",
        "    title='Program Duration Days for Placed Participants with Boxplot Summary',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Arial, sans-serif', size=12, color='black'),\n",
        "    width=800, height=300)\n",
        "\n",
        "# Intentionally leave out the x-axis title for the boxplot to avoid overlap\n",
        "# You can use annotations if you need to label the axis specifically\n",
        "\n",
        "# Update x-axis for the heatmap for clarity\n",
        "fig.update_xaxes(title_text='Program Duration Days (Range)', row=2, col=1)\n",
        "\n",
        "# Since the heatmap effectively labels the \"Program Duration Days\" concept, we may not need to repeat it for the boxplot\n",
        "\n",
        "# Display the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4PR3qejQFQX"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby(['primary_track', 'pathrise_status']).size().reset_index(name='count')\n",
        "\n",
        "# Calculate total counts for each 'primary_track'\n",
        "track_totals = df_grouped.groupby('primary_track')['count'].transform('sum')\n",
        "\n",
        "# Step 2: Calculate the percentage of each 'pathrise_status' relative to the total number of entries in the dataset\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "# Step 3: Calculate the percentage of each 'pathrise_status' within its 'primary_track'\n",
        "df_grouped['percentage_within_track'] = (df_grouped['count'] / track_totals) * 100\n",
        "\n",
        "# Format the 'percentage_within_track' column for display as text on top of each bar\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_track'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Create the bar chart using the 'percentage_of_total' for the y-axis values\n",
        "# and display the formatted 'percentage_within_track' as text on top of each bar\n",
        "fig = px.bar(df_grouped, x='primary_track', y='percentage_of_total', color='pathrise_status',\n",
        "             text='percentage_text',  # Use the percentage_within_track as text on top of each bar\n",
        "             title='Distribution of Pathrise Status by Primary Track',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'primary_track': 'Primary Track', 'pathrise_status': 'Pathrise Status'},\n",
        "             barmode='group')  # Use 'group' to place bars side by side\n",
        "\n",
        "# Apply custom formatting for text on bars for better visibility\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "# Update layout for better readability and aesthetics\n",
        "fig.update_layout(\n",
        "    xaxis_title='Primary Track',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),  # Formatting y-axis as a percentage with one decimal place\n",
        "    legend_title='Pathrise Status',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1800, height=800\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wE0j2OEVuyt"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby(['employment_status ', 'pathrise_status']).size().reset_index(name='count')\n",
        "\n",
        "# Calculate total counts for each 'employment_status'\n",
        "status_totals = df_grouped.groupby('employment_status ')['count'].transform('sum')\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' relative to the total number of entries in the dataset\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' within its 'employment_status'\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "# Format the 'percentage_within_status' column for display as text on top of each bar\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Create the bar chart using the 'percentage_of_total' for the y-axis values\n",
        "# and display the formatted 'percentage_within_status' as text on top of each bar\n",
        "fig = px.bar(df_grouped, x='employment_status ', y='percentage_of_total', color='pathrise_status',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Pathrise Status by Employment Status',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'employment_status ': 'Employment Status', 'pathrise_status': 'Pathrise Status'},\n",
        "             barmode='group')  # Use 'group' to place bars side by side\n",
        "\n",
        "# Apply custom formatting for text on bars for better visibility\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "# Update layout for better readability and aesthetics\n",
        "fig.update_layout(\n",
        "    xaxis_title='Employment Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Pathrise Status',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1800, height=800\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3On50BQvb9Px"
      },
      "outputs": [],
      "source": [
        "df_placed = df[df['pathrise_status'] == 'Placed']\n",
        "\n",
        "fig = px.box(df_placed, x='primary_track', y='program_duration_days',\n",
        "             title='Time to Placement by Primary Track for Placed Individuals',\n",
        "             labels={'program_duration_days': 'Time to Placement', 'primary_track': 'Primary Track'},\n",
        "             color='primary_track',\n",
        "             points='all')\n",
        "\n",
        "mean_time_to_place = df_placed.groupby('primary_track')['program_duration_days'].mean().reset_index()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=mean_time_to_place['primary_track'], y=mean_time_to_place['program_duration_days'],\n",
        "                         mode='markers', marker=dict(color='black', size=10, symbol='x'),\n",
        "                         name='Mean Time to Placement'))\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Primary Track',\n",
        "    yaxis_title='Time to Placement',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=800, height=600,\n",
        "    legend_title_text='Primary Track'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9RIlKILl94N"
      },
      "outputs": [],
      "source": [
        "df_placed = df[df['pathrise_status'] == 'Placed']\n",
        "\n",
        "# Set the style of the visualization\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a violin plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "violin = sns.violinplot(x='primary_track', y='program_duration_days', data=df_placed,\n",
        "                        scale=\"width\", palette=\"muted\")\n",
        "\n",
        "# Set titles and labels\n",
        "violin.set_title('Distribution of Time to Placement by Primary Track for Placed Individuals')\n",
        "violin.set_xlabel('Primary Track')\n",
        "violin.set_ylabel('Time to Placement')\n",
        "\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.tight_layout()  # Adjust layout to make room for the rotated x-axis labels\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAFGcUeuwmAn"
      },
      "outputs": [],
      "source": [
        "df[\"starting_month\"] = df['cohort_tag'].str.slice(0, 3)\n",
        "df[\"starting_year\"] = df['cohort_tag'].apply(lambda x: '20' + str(x)[3:5])\n",
        "df.drop(columns=['cohort_tag'], inplace=True)\n",
        "df\n",
        "file_path = '/content/drive/MyDrive/Dataroadmap/dataframe_split_cohorttag.csv'\n",
        "\n",
        "df.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_VR-1uhZIZc"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/Dataroadmap/dataframe_split_cohorttag.csv'\n",
        "\n",
        "df_grouped_loaded = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIZAwqk9bn46"
      },
      "outputs": [],
      "source": [
        "month_order = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']\n",
        "\n",
        "df_grouped = df.groupby(['employment_status ', 'starting_month']).size().reset_index(name='count')\n",
        "\n",
        "total_counts_per_month = df.groupby('starting_month')['starting_month'].count().rename('month_total')\n",
        "\n",
        "df_grouped = df_grouped.merge(total_counts_per_month, on='starting_month', how='left')\n",
        "\n",
        "df_grouped['status_percentage'] = (df_grouped['count'] / df_grouped['month_total'] * 100).round(2)\n",
        "\n",
        "df_grouped['starting_month'] = pd.Categorical(df_grouped['starting_month'], categories=month_order, ordered=True)\n",
        "df_grouped.sort_values('starting_month', inplace=True)\n",
        "\n",
        "total_count = df.shape[0]\n",
        "\n",
        "df_grouped['month_percentage_of_total'] = (df_grouped['month_total'] / total_count * 100).round(2)\n",
        "\n",
        "fig = px.bar(df_grouped, x='starting_month', y='month_percentage_of_total', color='employment_status ', text='status_percentage',\n",
        "             labels={'starting_month': 'Starting Month', 'count': 'Count'},\n",
        "             title='Distribution of Employment Status by Starting Month')\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:.2f}%', textposition='inside', textfont_size=12)\n",
        "\n",
        "for i, month in enumerate(month_order):\n",
        "    if month in df_grouped['starting_month'].values:\n",
        "        month_percentage = df_grouped[df_grouped['starting_month'] == month]['month_percentage_of_total'].iloc[0]\n",
        "        fig.add_annotation(x=i, y=105, text=f\"{month_percentage}%\", showarrow=False, textangle=-45)\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_title='Percentage',\n",
        "    xaxis_title='Starting Month',\n",
        "    height=1000,\n",
        "    width=1000,\n",
        "    title_x=0.5,\n",
        "    bargap=0.2,\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXX5w9QHvGDo"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWqwjU-ynfXD"
      },
      "outputs": [],
      "source": [
        "df_filtered = df[df['starting_year'] != '20']\n",
        "\n",
        "df_grouped = df_filtered.groupby(['employment_status ', 'starting_year']).size().reset_index(name='count')\n",
        "\n",
        "yearly_totals = df_filtered.groupby('starting_year').size().reset_index(name='total')\n",
        "\n",
        "df_grouped = pd.merge(df_grouped, yearly_totals, on='starting_year')\n",
        "\n",
        "df_grouped['within_year_percentage'] = (df_grouped['count'] / df_grouped['total'] * 100).round(2)\n",
        "\n",
        "df_grouped['overall_percentage'] = (df_grouped['count'] / df_filtered['employment_status '].count() * 100).round(2)\n",
        "\n",
        "# Create the bar chart\n",
        "fig = px.bar(df_grouped, y='starting_year', x='overall_percentage', color='employment_status ', text='within_year_percentage',\n",
        "             labels={'starting_year': 'Starting Year', 'overall_percentage': 'Percentage'},\n",
        "             title='Distribution of Employment Status by Starting Year', orientation='h')\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:.2f}%', textposition='inside', textfont_size=12)\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis_title='Starting Year',\n",
        "    xaxis_title='Percentage',\n",
        "    width=1400,\n",
        "    height=400,\n",
        "    title_x=0.5,\n",
        "    bargap=0.2,\n",
        ")\n",
        "\n",
        "# year_order = df_grouped['starting_year'].unique()\n",
        "# # for i, year in enumerate(year_order):\n",
        "# #     if year in df_grouped['starting_year'].values:\n",
        "# #         year_percentage = df_grouped[df_grouped['starting_year'] == year]['overall_percentage'].sum()\n",
        "# #         fig.add_annotation(x=105, y=i, text=f\"{year_percentage:.2f}%\", showarrow=False, textangle=0, xanchor='left')\n",
        "\n",
        "# fig.update_layout(\n",
        "#     bargap=0.1,\n",
        "#     margin=dict(r=200),\n",
        "#     xaxis=dict(range=[0, 120])\n",
        "# )\n",
        "\n",
        "# for i, year in enumerate(year_order):\n",
        "#     if year in df_grouped['starting_year'].values:\n",
        "#         year_percentage = df_grouped[df_grouped['starting_year'] == year]['overall_percentage'].sum()\n",
        "#         fig.add_annotation(x=115, y=i, text=f\"{year_percentage:.2f}%\", showarrow=False, textangle=0, xanchor='left')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtL9crmthS2d"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame and it's already defined\n",
        "\n",
        "relevant_df = df[(df['pathrise_status'].isin(['Placed'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365) &\n",
        "                 (df['starting_year'] != '20')]\n",
        "\n",
        "relevant_df.dropna(subset=['starting_year'], inplace=True)\n",
        "\n",
        "# Ensure 'starting_year' is treated as an ordered categorical type\n",
        "# This will help in sorting and ensuring the legend and y-axis follow this order\n",
        "relevant_df['starting_year'] = pd.Categorical(relevant_df['starting_year'], ordered=True)\n",
        "\n",
        "# Calculate mean values\n",
        "mean_values = relevant_df.groupby('starting_year')['program_duration_days'].mean().reset_index()\n",
        "mean_values['starting_year'] = pd.Categorical(mean_values['starting_year'], categories=relevant_df['starting_year'].cat.categories, ordered=True)\n",
        "\n",
        "# Now sort by 'starting_year' to ensure the plots are in order\n",
        "relevant_df = relevant_df.sort_values('starting_year')\n",
        "\n",
        "# Plotting\n",
        "fig = px.box(relevant_df, y='starting_year', x='program_duration_days',\n",
        "             color='starting_year',\n",
        "             labels={'program_duration_days': 'Program Duration Days', 'starting_year': 'Starting Year'},\n",
        "             title='Program Duration Days by Starting Year for Placed Individuals',\n",
        "             points=\"all\")\n",
        "\n",
        "# Adding mean values\n",
        "fig.add_trace(go.Scatter(y=mean_values['starting_year'], x=mean_values['program_duration_days'],\n",
        "                         mode='markers+text',\n",
        "                         text=[f\"{x:.2f}\" for x in mean_values['program_duration_days']],  # Format text to 2 decimal places\n",
        "                         textposition=\"top center\",\n",
        "                         marker=dict(color='black', size=8, symbol=\"x\"),\n",
        "                         name='Mean'))\n",
        "\n",
        "# Update layout with your specified titles and dimensions, and correct category order for y-axis\n",
        "fig.update_layout(showlegend=True,\n",
        "                  xaxis_title='Program Duration Days',\n",
        "                  yaxis_title='Starting Year', title_x=0.5,\n",
        "                  width=800, height=500)\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBIOs1hsHWuR"
      },
      "outputs": [],
      "source": [
        "df_placed = df[df['placed'] == 1].copy()\n",
        "\n",
        "# Combine starting_month and starting_year into a single string column for grouping\n",
        "df_placed['start_month_year'] = df_placed['starting_month'].str.title() + '-' + df_placed['starting_year']\n",
        "\n",
        "# Create a temporary datetime column for sorting purposes\n",
        "df_placed['temp_start_date'] = pd.to_datetime(df_placed['starting_month'].str.title() + '-1-' + df_placed['starting_year'], format='%b-%d-%Y')\n",
        "\n",
        "# Sort df_placed by this temporary column to ensure chronological order\n",
        "df_placed.sort_values('temp_start_date', inplace=True)\n",
        "\n",
        "# Now that the DataFrame is sorted, you can drop the temporary column (optional)\n",
        "df_placed.drop('temp_start_date', inplace=True, axis=1)\n",
        "\n",
        "# Calculate the average program duration for each sorted start_month_year group\n",
        "avg_durations = df_placed.groupby('start_month_year')['program_duration_days'].mean().reset_index()\n",
        "\n",
        "# Create a box plot to show distribution of program durations by start month and year\n",
        "fig = px.box(df_placed, x='start_month_year', y='program_duration_days',\n",
        "             title='Program Duration to Placement by Start Month and Year',\n",
        "             labels={'program_duration_days': 'Program Duration (Days)', 'start_month_year': 'Start Month-Year'},\n",
        "             color_discrete_sequence=px.colors.qualitative.Pastel)\n",
        "\n",
        "# Customize box plot look\n",
        "fig.update_traces(boxmean=True, boxpoints='all', jitter=0.4, pointpos=-1.8)\n",
        "\n",
        "# Add scatter plot on top of the box plot for average program durations\n",
        "fig.add_trace(go.Scatter(x=avg_durations['start_month_year'], y=avg_durations['program_duration_days'],\n",
        "                         mode='markers+text', name='Average Duration',\n",
        "                         marker=dict(color='red', size=8),\n",
        "                         text=avg_durations['program_duration_days'].round(1),\n",
        "                         textposition=\"top center\",\n",
        "                         hoverinfo='y+name'))\n",
        "\n",
        "# Enhance the layout for better readability\n",
        "fig.update_layout(xaxis_title='Start Month-Year',\n",
        "                  yaxis_title='Program Duration (Days)',\n",
        "                  template='plotly_dark',\n",
        "                  plot_bgcolor='rgba(255,255,255,0)',\n",
        "                  paper_bgcolor='rgba(0,0,0,0)',\n",
        "                  font=dict(family=\"Arial, sans-serif\", size=10, color=\"black\"),\n",
        "                  showlegend=False)\n",
        "\n",
        "# Rotate x-axis labels for clarity\n",
        "fig.update_xaxes(tickangle=45, tickfont=dict(family='Rockwell', color='black', size=10))\n",
        "\n",
        "# Improve y-axis gridlines for better readability\n",
        "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='DimGray')\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1nkKUUuHwOg"
      },
      "outputs": [],
      "source": [
        "df_placed = df[df['placed'] == 1].copy()\n",
        "\n",
        "# Combine starting_month and starting_year into a single string column for grouping\n",
        "df_placed['start_month_year'] = df_placed['starting_month'].str.title() + '-' + df_placed['starting_year']\n",
        "\n",
        "# Create a temporary datetime column for sorting purposes\n",
        "df_placed['temp_start_date'] = pd.to_datetime(df_placed['starting_month'].str.title() + '-1-' + df_placed['starting_year'], format='%b-%d-%Y')\n",
        "\n",
        "# Sort df_placed by this temporary column to ensure chronological order\n",
        "df_placed.sort_values('temp_start_date', inplace=True)\n",
        "\n",
        "# Now that the DataFrame is sorted, you can drop the temporary column (optional)\n",
        "df_placed.drop('temp_start_date', inplace=True, axis=1)\n",
        "\n",
        "# Calculate the average program duration for each sorted start_month_year group\n",
        "avg_durations = df_placed.groupby('start_month_year')['program_duration_days'].mean().reset_index()\n",
        "\n",
        "# Create a box plot to show distribution of program durations by start month and year\n",
        "fig = px.box(df_placed, x='start_month_year', y='program_duration_days',\n",
        "             title='Program Duration to Placement by Start Month and Year',\n",
        "             labels={'program_duration_days': 'Program Duration (Days)', 'start_month_year': 'Start Month-Year'},\n",
        "             color_discrete_sequence=px.colors.qualitative.Set2)\n",
        "\n",
        "# Customize box plot look\n",
        "fig.update_traces(boxmean=True, boxpoints='all', jitter=0.4, pointpos=-1.8)\n",
        "\n",
        "# Add scatter plot on top of the box plot for average program durations\n",
        "fig.add_trace(go.Scatter(x=avg_durations['start_month_year'], y=avg_durations['program_duration_days'],\n",
        "                         mode='markers+text', name='Average Duration',\n",
        "                         marker=dict(color='RoyalBlue', size=8),\n",
        "                         text=avg_durations['program_duration_days'].round(1),\n",
        "                         textposition=\"top center\",\n",
        "                         hoverinfo='y+name'))\n",
        "\n",
        "# Enhance the layout for better readability, with a white background\n",
        "fig.update_layout(xaxis_title='Start Month-Year',\n",
        "                  yaxis_title='Program Duration (Days)',\n",
        "                  template='plotly_white',\n",
        "                  plot_bgcolor='white',\n",
        "                  paper_bgcolor='white',\n",
        "                  font=dict(family=\"Arial, sans-serif\", size=10, color=\"Black\"),\n",
        "                  title_x=0.5,\n",
        "                  showlegend=False)\n",
        "\n",
        "# Rotate x-axis labels for clarity\n",
        "fig.update_xaxes(tickangle=45, tickfont=dict(family='Arial', color='black', size=10))\n",
        "\n",
        "# Improve y-axis gridlines for better readability on a white background\n",
        "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTLddedhJ17E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# Filter out irrelevant pathrise_status groups and participants who remained for less than 14 or more than 365 days\n",
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "# Calculate placement rate by employment status\n",
        "placement_rate = relevant_df.groupby('employment_status ')['placed'].mean().reset_index()\n",
        "\n",
        "# Calculate average program duration for placed participants by employment status\n",
        "avg_duration = relevant_df[relevant_df['placed'] == 1].groupby('employment_status ')['program_duration_days'].mean().reset_index()\n",
        "\n",
        "# Create subplot layout\n",
        "fig = sp.make_subplots(rows=1, cols=2, subplot_titles=(\"Placement Rate\", \"Average Program Duration\"))\n",
        "\n",
        "# Add bar chart for placement rate\n",
        "fig.add_trace(go.Bar(x=placement_rate['employment_status '], y=placement_rate['placed'], name='Placement Rate'),\n",
        "              row=1, col=1)\n",
        "\n",
        "# Add bar chart for average program duration\n",
        "fig.add_trace(go.Bar(x=avg_duration['employment_status '], y=avg_duration['program_duration_days'], name='Average Duration'),\n",
        "              row=1, col=2)\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(title_text=\"Job Placement Analysis by Employment Status\",\n",
        "                  xaxis_title=\"Employment Status\",\n",
        "                  yaxis_title=\"Rate / Duration\",\n",
        "                  plot_bgcolor='white',\n",
        "                  paper_bgcolor='white',\n",
        "                  font=dict(family=\"Arial, sans-serif\", size=12, color=\"Black\"))\n",
        "\n",
        "# Update xaxis properties\n",
        "fig.update_xaxes(title_text=\"Employment Status\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Employment Status\", row=1, col=2)\n",
        "\n",
        "# Update yaxis properties\n",
        "fig.update_yaxes(title_text=\"Placement Rate\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Average Duration (Days)\", row=1, col=2)\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiN4iA4bX8IZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# Filter out irrelevant pathrise_status groups and participants who remained for less than 14 or more than 365 days\n",
        "relevant_df = df[(df['pathrise_status'].isin(['Placed', 'Withdrawn (Failed)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "# Calculate placement rate by employment status\n",
        "placement_rate = relevant_df.groupby('employment_status ')['placed'].mean().reset_index()\n",
        "\n",
        "# Calculate average program duration for placed participants by employment status\n",
        "avg_duration = relevant_df[relevant_df['placed'] == 1].groupby('employment_status ')['program_duration_days'].mean().reset_index()\n",
        "\n",
        "# Create subplot layout\n",
        "fig = sp.make_subplots(rows=1, cols=2, subplot_titles=(\"Placement Rate\", \"Average Program Duration\"))\n",
        "\n",
        "# Add bar chart for placement rate\n",
        "fig.add_trace(go.Bar(x=placement_rate['employment_status '], y=placement_rate['placed'], name='Placement Rate'),\n",
        "              row=1, col=1)\n",
        "\n",
        "# Add bar chart for average program duration\n",
        "fig.add_trace(go.Bar(x=avg_duration['employment_status '], y=avg_duration['program_duration_days'], name='Average Duration'),\n",
        "              row=1, col=2)\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(title_text=\"Job Placement Analysis by Employment Status\",\n",
        "                  xaxis_title=\"Employment Status\",\n",
        "                  yaxis_title=\"Rate / Duration\",\n",
        "                  plot_bgcolor='white',\n",
        "                  paper_bgcolor='white',\n",
        "                  font=dict(family=\"Arial, sans-serif\", size=12, color=\"Black\"))\n",
        "\n",
        "# Update xaxis properties\n",
        "fig.update_xaxes(title_text=\"Employment Status\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Employment Status\", row=1, col=2)\n",
        "\n",
        "# Update yaxis properties\n",
        "fig.update_yaxes(title_text=\"Placement Rate\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Average Duration (Days)\", row=1, col=2)\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13Kh92Z_QNFz"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "placement_rate = relevant_df.groupby('employment_status ')['placed'].mean().reset_index()\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Placement Rate by Employment Status\", \"Program Duration Distribution by Employment Status\"),\n",
        "                    specs=[[{\"type\": \"bar\"}, {\"type\": \"box\"}]])\n",
        "\n",
        "relevant_df = relevant_df[relevant_df['placed'] == 1]\n",
        "\n",
        "fig.add_trace(go.Bar(x=placement_rate['employment_status '], y=placement_rate['placed'], name='Placement Rate'),\n",
        "              row=1, col=1)\n",
        "\n",
        "avg_durations = []\n",
        "\n",
        "for status in relevant_df['employment_status '].unique():\n",
        "    status_df = relevant_df[relevant_df['employment_status '] == status]\n",
        "    avg_duration = status_df['program_duration_days'].mean()\n",
        "    avg_durations.append(avg_duration)\n",
        "    fig.add_trace(go.Box(y=status_df['program_duration_days'], name=status,\n",
        "                         marker_color='lightseagreen',\n",
        "                         boxpoints='all',\n",
        "                         jitter=0.5,\n",
        "                         pointpos=-1.8,\n",
        "                         boxmean=False,\n",
        "                        ), row=1, col=2)\n",
        "\n",
        "fig.add_trace(go.Scatter(x=relevant_df['employment_status '].unique(), y=avg_durations,\n",
        "                         mode='markers', marker=dict(color='red', size=10),\n",
        "                         name='Average Duration'), row=1, col=2)\n",
        "\n",
        "fig.update_layout(title_text=\"Job Placement Analysis by Employment Status\",\n",
        "                  plot_bgcolor='white', paper_bgcolor='white',\n",
        "                  font=dict(family=\"Arial, sans-serif\", size=12, color=\"Black\"),\n",
        "                  width=1000, height=600,\n",
        "                  title_x=0.5)\n",
        "\n",
        "fig.update_xaxes(title_text=\"Employment Status\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Placement Rate\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Employment Status\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Program Duration (Days)\", row=1, col=2)\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH4eGoQMOqf-"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['employment_status ', 'placed']).size().reset_index(name='count')\n",
        "\n",
        "track_totals = df_grouped.groupby('employment_status ')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(relevant_df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status_class'] = (df_grouped['count'] / track_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "total_counts_per_challenge = df_grouped.groupby('employment_status ')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_within_status_class'] = (df_grouped['count'] / total_counts_per_challenge) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Mapping 'placed' status to descriptive names\n",
        "df_grouped['placed'] = df_grouped['placed'].map({0: 'Not Placed', 1: 'Placed'})\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add traces\n",
        "for name, group in df_grouped.groupby('placed'):\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=group['employment_status '],\n",
        "        y=group['percentage_of_total'],\n",
        "        name=str(name),  # This now uses the descriptive names 'Not Placed' and 'Placed'\n",
        "        text=group['percentage_text'],\n",
        "        textposition='outside'\n",
        "    ))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distribution of Getting a Job by Prior Employment Status',\n",
        "    xaxis_title='Biggest Challenge in Search',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Being Placed',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    title_x=0.5,\n",
        "    barmode='group',\n",
        "    width=600, height=600\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-keaJ_tYn_c"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['employment_status ', 'placed']).size().reset_index(name='count')\n",
        "\n",
        "track_totals = df_grouped.groupby('employment_status ')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(relevant_df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status_class'] = (df_grouped['count'] / track_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "total_counts_per_challenge = df_grouped.groupby('employment_status ')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_within_status_class'] = (df_grouped['count'] / total_counts_per_challenge) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Mapping 'placed' status to descriptive names\n",
        "df_grouped['placed'] = df_grouped['placed'].map({0: 'Not Placed', 1: 'Placed'})\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add traces\n",
        "for name, group in df_grouped.groupby('placed'):\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=group['employment_status '],\n",
        "        y=group['percentage_of_total'],\n",
        "        name=str(name),  # This now uses the descriptive names 'Not Placed' and 'Placed'\n",
        "        text=group['percentage_text'],\n",
        "        textposition='outside'\n",
        "    ))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distribution of Getting a Job by Prior Employment Status',\n",
        "    xaxis_title='Biggest Challenge in Search',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Being Placed',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    title_x=0.5,\n",
        "    barmode='group',\n",
        "    width=600, height=600\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E_fzEiolsLu"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "# Calculate placement rate by highest_level_of_education\n",
        "placement_rate = relevant_df.groupby('highest_level_of_education')['placed'].mean().reset_index()\n",
        "\n",
        "# Create subplot layout\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Placement Rate by Highest Level of Education\", \"Program Duration Distribution by Highest Level of Education\"),\n",
        "                    specs=[[{\"type\": \"bar\"}, {\"type\": \"box\"}]])\n",
        "\n",
        "# Filter for participants who found a job\n",
        "relevant_df_placed = relevant_df[relevant_df['placed'] == 1]\n",
        "\n",
        "# Add bar chart for placement rate by highest level of education\n",
        "fig.add_trace(go.Bar(x=placement_rate['highest_level_of_education'], y=placement_rate['placed'], name='Placement Rate'),\n",
        "              row=1, col=1)\n",
        "\n",
        "# Add box plot for program duration for each highest level of education, showing all data points\n",
        "# for level in relevant_df['highest_level_of_education'].unique():\n",
        "#     level_df = relevant_df[relevant_df['highest_level_of_education'] == level]\n",
        "#     # fig.add_trace(go.Box(y=level_df['program_duration_days'], name=level,\n",
        "#     #                      marker_color='lightseagreen',\n",
        "#     #                      boxpoints='all',  # Show all points\n",
        "#     #                      jitter=0.5,  # Spread out data points horizontally to avoid overlap\n",
        "#     #                      pointpos=-1.8,  # Position points to the left of the box\n",
        "#     #                     ), row=1, col=2)\n",
        "#     # fig.add_trace(go.Scatter(x=[level], y=[mean_duration], mode='markers', marker=dict(color='red', size=10, symbol='x'),\n",
        "#     #                       name='Mean Duration' if level == relevant_df_placed['highest_level_of_education'].unique()[0] else None,\n",
        "#     #                     ), row=1, col=2)\n",
        "#     fig.add_trace(go.Box(y=level_df['program_duration_days'], name=level,\n",
        "#                          marker_color='lightseagreen',\n",
        "#                          boxpoints='all',  # Optionally, show all points to visualize the distribution\n",
        "#                          jitter=0.5,  # Spread out data points to avoid overlap\n",
        "#                          pointpos=-1.8),  # Position points to the left of the box\n",
        "#                   row=1, col=2)\n",
        "\n",
        "#     # Calculate the mean program duration for the current level of education\n",
        "#     mean_duration = level_df['program_duration_days'].mean()\n",
        "\n",
        "#     # Add a marker for the mean duration\n",
        "#     # fig.add_trace(go.Scatter(x=[level]*len(level_df), y=[mean_duration],\n",
        "#     #                          mode='markers', marker=dict(color='red', size=10, symbol='x'),\n",
        "#     #                          name='Mean' if level == relevant_df['highest_level_of_education'].unique()[0] else None),  # Show legend entry only once\n",
        "#     #               row=1, col=2)\n",
        "#     # fig.add_trace(go.Scatter(x=relevant_df['highest_level_of_education'].unique(), y=mean_duration,\n",
        "#     #                      mode='markers', marker=dict(color='red', size=10),\n",
        "#     #                      name='Average Duration'), row=1, col=2)\n",
        "#     fig.add_trace(go.Scatter(x=[level]*len(level_df), y=[mean_duration],\n",
        "#                           mode='markers', marker=dict(color='red', size=10, symbol='x'),\n",
        "#                           name='Mean' if level == relevant_df['highest_level_of_education'].unique()[0] else None),  # Show legend entry only once\n",
        "#               row=1, col=2)\n",
        "first_legend = True\n",
        "for level in relevant_df['highest_level_of_education'].unique():\n",
        "    # Filter data for the current level of education\n",
        "    level_df = relevant_df[relevant_df['highest_level_of_education'] == level]\n",
        "\n",
        "    # Calculate the mean program duration for the current level of education\n",
        "    mean_duration = level_df['program_duration_days'].mean()\n",
        "\n",
        "    # Add box plot for the current level of education\n",
        "    fig.add_trace(go.Box(y=level_df['program_duration_days'], name=level, boxmean=False,\n",
        "                         marker_color='lightseagreen', boxpoints='all', jitter=0.5, pointpos=-1.8),\n",
        "                  row=1, col=2)\n",
        "\n",
        "    # Add a marker for the mean duration\n",
        "    fig.add_trace(go.Scatter(x=[level], y=[mean_duration], mode='markers',\n",
        "                             marker=dict(color='red', size=10),\n",
        "                             name='Mean Duration' if first_legend else None,\n",
        "                             showlegend=first_legend),\n",
        "                  row=1, col=2)\n",
        "    first_legend = False  # Update flag so that legend entry is added only once\n",
        "\n",
        "fig.update_layout(title_text=\"Job Placement Analysis by Highest Level of Education\",\n",
        "                  plot_bgcolor='white', paper_bgcolor='white',\n",
        "                  font=dict(family=\"Arial, sans-serif\", size=12, color=\"Black\"),\n",
        "                  width=1200, height=600,\n",
        "                  title_x=0.5)\n",
        "\n",
        "fig.update_xaxes(title_text=\"Highest Level of Education\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Placement Rate\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Highest Level of Education\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Program Duration (Days)\", row=1, col=2)\n",
        "\n",
        "# Optionally, adjust legend to manage visibility or location\n",
        "fig.update_layout(showlegend=True)\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt_DiJo0PAEF"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['highest_level_of_education', 'placed']).size().reset_index(name='count')\n",
        "\n",
        "track_totals = df_grouped.groupby('highest_level_of_education')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(relevant_df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_education_class'] = (df_grouped['count'] / track_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_education_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "total_counts_per_challenge = df_grouped.groupby('highest_level_of_education')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_within_education_class'] = (df_grouped['count'] / total_counts_per_challenge) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_education_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Mapping 'placed' status to descriptive names\n",
        "df_grouped['placed'] = df_grouped['placed'].map({0: 'Not Placed', 1: 'Placed'})\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add traces\n",
        "for name, group in df_grouped.groupby('placed'):\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=group['highest_level_of_education'],\n",
        "        y=group['percentage_of_total'],\n",
        "        name=str(name),  # This now uses the descriptive names 'Not Placed' and 'Placed'\n",
        "        text=group['percentage_text'],\n",
        "        textposition='outside'\n",
        "    ))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distribution of Getting a Job by Highest Level of Education',\n",
        "    xaxis_title='Biggest Challenge in Search',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Being Placed',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    title_x=0.5,\n",
        "    barmode='group',\n",
        "    width=800, height=600\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOp8HYPYMX9O"
      },
      "outputs": [],
      "source": [
        "category_order = [\n",
        "    'Less than one month',\n",
        "    '1-2 months',\n",
        "    '3-5 months',\n",
        "    '6 months to a year',\n",
        "    'Over a year'\n",
        "]\n",
        "\n",
        "# colors = ['#FFFF00',  # Yellow\n",
        "#           '#BFBF00',  # Yellow-Green\n",
        "#           '#808000',  # Olive Green\n",
        "#           '#404000',  # Dark Olive Green\n",
        "#           '#0000FF']  # Blue\n",
        "\n",
        "\n",
        "# color_mapping = {category: colors[i] for i, category in enumerate(category_order)}\n",
        "\n",
        "custom_palette = sns.color_palette(\"Spectral\", n_colors=len(category_order)).as_hex()\n",
        "\n",
        "# Map your categories to this custom palette\n",
        "color_mapping = {category: custom_palette[i] for i, category in enumerate(category_order)}\n",
        "\n",
        "\n",
        "df_placed_filtered = df[(df['placed'] == 1) &\n",
        "                        (df['program_duration_days'] >= 14) &\n",
        "                        (df['program_duration_days'] <= 365) &\n",
        "                        (df['number_of_applications'] <= 250)&\n",
        "                        (df['length_of_job_search'] != \"Unknown\")].copy()\n",
        "\n",
        "df_placed_filtered.dropna(subset=['length_of_job_search'], inplace=True)\n",
        "df_placed_filtered.dropna(subset=['number_of_interviews'], inplace=True)\n",
        "df_placed_filtered.dropna(subset=['number_of_applications'], inplace=True)\n",
        "df_placed_filtered.dropna(subset=['program_duration_days'], inplace=True)\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "for category in category_order:\n",
        "    filtered_df = df_placed_filtered[df_placed_filtered['length_of_job_search'] == category]\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=filtered_df['number_of_interviews'],\n",
        "        y=filtered_df['number_of_applications'],\n",
        "        z=filtered_df['program_duration_days'],\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=5,\n",
        "            color=color_mapping[category],  # Use the ordered color mapping\n",
        "        ),\n",
        "        name=category  # Use the ordered category for the legend\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='3D Scatter Plot: Job Search Metrics for Placed Participants',\n",
        "    scene=dict(\n",
        "        xaxis_title='Number of Interviews',\n",
        "        yaxis_title='Number of Applications',\n",
        "        zaxis_title='Program Duration Days'\n",
        "    ),\n",
        "    legend_title=\"Length of Job Search\",\n",
        "    margin=dict(l=0, r=0, b=0, t=30),\n",
        "    height=950,\n",
        "    title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRmKRKy8Pvog"
      },
      "outputs": [],
      "source": [
        "df_filtered = df.dropna(subset=['length_of_job_search', 'program_duration_days'])[(df['placed'] == 1) &\n",
        "                        (df['program_duration_days'] >= 14) &\n",
        "                        (df['program_duration_days'] <= 365) &\n",
        "                        (df['number_of_applications'] <= 250)&\n",
        "                        (df['length_of_job_search'] != \"Unknown\")]\n",
        "\n",
        "# Creating a box plot\n",
        "fig = px.box(df_filtered,\n",
        "             x='length_of_job_search',\n",
        "             y='program_duration_days',\n",
        "             category_orders={\"length_of_job_search\": [\"Less than one month\", \"1-2 months\", \"3-5 months\", \"6 months to a year\", \"Over a year\"]},\n",
        "             title='Correlation between Length of Job Search and Program Duration Days')\n",
        "\n",
        "# Update layout for clarity\n",
        "fig.update_layout(\n",
        "    title_x=0.5,\n",
        "    title_font_size=11,\n",
        "    xaxis_title='Length of Job Search',\n",
        "    yaxis_title='Program Duration Days',\n",
        "    width=450,\n",
        "    xaxis={'categoryorder':'array', 'categoryarray':[\"Less than one month\", \"1-2 months\", \"3-5 months\", \"6 months to a year\", \"Over a year\"]}\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dopxA7IOU5kF"
      },
      "outputs": [],
      "source": [
        "category_orders = [\"Less than one month\", \"1-2 months\", \"3-5 months\", \"6 months to a year\", \"Over a year\"]\n",
        "\n",
        "df_filtered = df.dropna(subset=['length_of_job_search', 'program_duration_days'])[(df['placed'] == 1) &\n",
        "                        (df['program_duration_days'] >= 14) &\n",
        "                        (df['program_duration_days'] <= 365) &\n",
        "                        (df['number_of_applications'] <= 250)&\n",
        "                        (df['length_of_job_search'] != \"Unknown\")]\n",
        "\n",
        "fig = make_subplots(rows=1, cols=3, subplot_titles=(\"Program Duration vs Number of Applications\",\n",
        "                                                    \"Program Duration vs Number of Interviews\",\n",
        "                                                    \"Program Duration vs Length of Job Search\"))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_filtered['number_of_applications'], y=df_filtered['program_duration_days'],\n",
        "                         mode='markers', name='Applications vs Duration'), row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_filtered['number_of_interviews'], y=df_filtered['program_duration_days'],\n",
        "                         mode='markers', name='Interviews vs Duration'), row=1, col=2)\n",
        "\n",
        "violin_fig = px.violin(df_filtered, y='program_duration_days', x='length_of_job_search', color='length_of_job_search',\n",
        "                       category_orders={\"length_of_job_search\": [\"Less than one month\", \"1-2 months\", \"3-5 months\", \"6 months to a year\", \"Over a year\"]},\n",
        "                       box=True, points=\"all\", title='Program Duration vs Length of Job Search')\n",
        "\n",
        "for trace in violin_fig.data:\n",
        "    fig.add_trace(trace, row=1, col=3)\n",
        "\n",
        "category_counts = df_filtered['length_of_job_search'].value_counts(normalize=True) * 100\n",
        "categories = category_counts.index\n",
        "percentages = category_counts.values\n",
        "\n",
        "for i, (category, percentage) in enumerate(zip(categories, percentages)):\n",
        "    fig.add_annotation(\n",
        "        x=i,  # This may need adjustment based on your plot's layout\n",
        "        y=max(df_filtered['program_duration_days']),  # Adjust this value as needed\n",
        "        text=f\"{percentage:.2f}%\",  # Formatting to 2 decimal places\n",
        "        showarrow=False,\n",
        "        xref=f\"x3\",  # Reference the third subplot for the x axis\n",
        "        yref=\"y3\",  # Reference the third subplot for the y axis (might need to adjust based on actual data range)\n",
        "        font=dict(size=10),\n",
        "        ax=0,  # These ensure the annotation is placed directly above the specified x position\n",
        "        ay=120  # Negative value to place the annotation above the plot; adjust as needed\n",
        "    )\n",
        "\n",
        "# Update layout for the entire figure\n",
        "fig.update_layout(height=600, width=1400, title_text=\"Correlations with Program Duration Days\",\n",
        "    title_x=0.5)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1hQSxxOtNU_"
      },
      "outputs": [],
      "source": [
        "# Create subplots\n",
        "# Bin edges definitions\n",
        "application_bins = np.linspace(df_filtered['number_of_applications'].min(), df_filtered['number_of_applications'].max(), 20)\n",
        "duration_bins = np.linspace(df_filtered['program_duration_days'].min(), df_filtered['program_duration_days'].max(), 20)\n",
        "interview_bins = np.linspace(df_filtered['number_of_interviews'].min(), df_filtered['number_of_interviews'].max(), 20)\n",
        "\n",
        "# Digitize or bin the x data\n",
        "application_bin_indices = np.digitize(df_filtered['number_of_applications'], application_bins)\n",
        "interview_bin_indices = np.digitize(df_filtered['number_of_interviews'], interview_bins)\n",
        "\n",
        "# Create 2D histograms for heatmaps\n",
        "heatmap1, _, _ = np.histogram2d(df_filtered['program_duration_days'], df_filtered['number_of_applications'], bins=(duration_bins, application_bins))\n",
        "heatmap2, _, _ = np.histogram2d(df_filtered['program_duration_days'], df_filtered['number_of_interviews'], bins=(duration_bins, interview_bins))\n",
        "\n",
        "fig = make_subplots(rows=1, cols=3, subplot_titles=(\"Program Duration vs Number of Applications\",\n",
        "                                                    \"Program Duration vs Number of Interviews\",\n",
        "                                                    \"Program Duration vs Length of Job Search\"))\n",
        "\n",
        "# Add the heatmap for number_of_applications vs program_duration_days\n",
        "fig.add_trace(go.Heatmap(z=heatmap1, x=application_bins, y=duration_bins, colorscale='Viridis', showscale=False), row=1, col=1)\n",
        "\n",
        "# Add the heatmap for number_of_interviews vs program_duration_days\n",
        "fig.add_trace(go.Heatmap(z=heatmap2, x=interview_bins, y=duration_bins, colorscale='Viridis', showscale=False), row=1, col=2)\n",
        "\n",
        "# Add the violin plot\n",
        "violin_fig = px.violin(df_filtered, y='program_duration_days', x='length_of_job_search', color='length_of_job_search',\n",
        "                       category_orders={\"length_of_job_search\": [\"Less than one month\", \"1-2 months\", \"3-5 months\", \"6 months to a year\", \"Over a year\"]},\n",
        "                       box=True, points=\"all\", title='Program Duration vs Length of Job Search')\n",
        "\n",
        "for trace in violin_fig.data:\n",
        "    fig.add_trace(trace, row=1, col=3)\n",
        "\n",
        "category_counts = df_filtered['length_of_job_search'].value_counts(normalize=True) * 100\n",
        "categories = category_counts.index\n",
        "percentages = category_counts.values\n",
        "\n",
        "for i, (category, percentage) in enumerate(zip(categories, percentages)):\n",
        "    fig.add_annotation(\n",
        "        x=i,  # This may need adjustment based on your plot's layout\n",
        "        y=max(df_filtered['program_duration_days']),  # Adjust this value as needed\n",
        "        text=f\"{percentage:.2f}%\",  # Formatting to 2 decimal places\n",
        "        showarrow=False,\n",
        "        xref=f\"x3\",  # Reference the third subplot for the x axis\n",
        "        yref=\"y3\",  # Reference the third subplot for the y axis (might need to adjust based on actual data range)\n",
        "        font=dict(size=10),\n",
        "        ax=0,  # These ensure the annotation is placed directly above the specified x position\n",
        "        ay=120  # Negative value to place the annotation above the plot; adjust as needed\n",
        "    )\n",
        "\n",
        "# Assuming the annotation setup remains the same\n",
        "# ...\n",
        "\n",
        "# Update layout for the entire figure\n",
        "fig.update_layout(height=600, width=1400, title_text=\"Correlations with Program Duration Days\",\n",
        "                  title_x=0.5)\n",
        "\n",
        "# Set y-axis to only show min and max\n",
        "for i in range(1, 4):\n",
        "    fig.update_yaxes(tickvals=[df_filtered['program_duration_days'].min(), df_filtered['program_duration_days'].max()], row=1, col=i)\n",
        "\n",
        "fig.update_layout(height=600, width=1400, title_text=\"Correlations with Program Duration Days\",\n",
        "                  title_x=0.5)\n",
        "min_duration = df_filtered['program_duration_days'].min()\n",
        "max_duration = df_filtered['program_duration_days'].max()\n",
        "duration_range = max_duration - min_duration\n",
        "\n",
        "# Determine the interval size for approximately 59 ticks\n",
        "# We subtract 1 because we include both the start and the end values in the count\n",
        "interval_size = 50\n",
        "\n",
        "# Generate the tick values\n",
        "tick_vals = np.arange(0, max_duration + interval_size, interval_size)\n",
        "\n",
        "# Update the y-axis settings for each subplot\n",
        "fig.update_yaxes(tickvals=tick_vals, row=1, col=1)\n",
        "fig.update_yaxes(tickvals=tick_vals, row=1, col=2)\n",
        "# Assuming you want the same for the third subplot\n",
        "fig.update_yaxes(tickvals=tick_vals, row=1, col=3)\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUU53NFaht0Y"
      },
      "outputs": [],
      "source": [
        "relevant_df = df.dropna(subset=['length_of_job_search', 'program_duration_days', 'number_of_applications', 'number_of_interviews'])\n",
        "\n",
        "relevant_df = relevant_df[\n",
        "    (relevant_df['program_duration_days'] >= 14) &\n",
        "    (relevant_df['program_duration_days'] <= 365) &\n",
        "    (relevant_df['number_of_applications'] <= 250) &\n",
        "    (relevant_df['length_of_job_search'] != \"Unknown\")\n",
        "]\n",
        "\n",
        "relevant_df = relevant_df.dropna(subset=['number_of_interviews', 'number_of_applications'])\n",
        "\n",
        "interview_bins = np.linspace(relevant_df['number_of_interviews'].min(), relevant_df['number_of_interviews'].max(), 6, endpoint=True)\n",
        "application_bins = np.linspace(relevant_df['number_of_applications'].min(), relevant_df['number_of_applications'].max(), 6, endpoint=True)\n",
        "\n",
        "relevant_df['interview_bin'] = pd.cut(relevant_df['number_of_interviews'], bins=interview_bins, include_lowest=True, right=True).astype(str)\n",
        "relevant_df['application_bin'] = pd.cut(relevant_df['number_of_applications'], bins=application_bins, include_lowest=True, right=True).astype(str)\n",
        "\n",
        "def convert_to_int_range(interval):\n",
        "    # Extract start and end values from the interval\n",
        "    start, end = map(float, interval.strip('()[]').split(', '))\n",
        "\n",
        "    # Convert negative values to zero\n",
        "    if start < 0:\n",
        "        start = 0\n",
        "    if end < 0:\n",
        "        end = 0\n",
        "\n",
        "    # Convert to integers\n",
        "    start = int(start)\n",
        "    end = int(end)\n",
        "\n",
        "    # Create integer range string\n",
        "    return f\"{start}-{end}\"\n",
        "\n",
        "# Define the order of the x ticks for interview and application bins\n",
        "interview_bin_labels = [convert_to_int_range(interval) for interval in sorted(relevant_df['interview_bin'].unique())]\n",
        "application_bin_labels = [convert_to_int_range(interval) for interval in sorted(relevant_df['application_bin'].unique())]\n",
        "\n",
        "\n",
        "def convert_to_int_range(interval):\n",
        "    start, end = map(float, interval.strip('()[]').split(', '))\n",
        "    start, end = max(start, 0), max(end, 0)\n",
        "    return f\"{int(start)}-{int(end)}\"\n",
        "\n",
        "# Creating mappings for sorting\n",
        "interview_bin_order = {interval: i for i, interval in enumerate(sorted(relevant_df['interview_bin'].unique(), key=lambda x: float(x.split(', ')[0].strip('()[]'))))}\n",
        "application_bin_order = {interval: i for i, interval in enumerate(sorted(relevant_df['application_bin'].unique(), key=lambda x: float(x.split(', ')[0].strip('()[]'))))}\n",
        "\n",
        "# Sort 'relevant_df' by these mappings\n",
        "relevant_df['interview_bin_sort'] = relevant_df['interview_bin'].map(interview_bin_order)\n",
        "relevant_df['application_bin_sort'] = relevant_df['application_bin'].map(application_bin_order)\n",
        "relevant_df.sort_values(['interview_bin_sort', 'application_bin_sort'], inplace=True)\n",
        "\n",
        "# Generate sorted bin labels for plotting\n",
        "interview_bin_labels = [convert_to_int_range(interval) for interval in sorted(relevant_df['interview_bin'].unique(), key=lambda x: interview_bin_order[x])]\n",
        "application_bin_labels = [convert_to_int_range(interval) for interval in sorted(relevant_df['application_bin'].unique(), key=lambda x: application_bin_order[x])]\n",
        "\n",
        "relevant_df['application_bin'] = pd.cut(relevant_df['number_of_applications'], bins=application_bins, include_lowest=True, right=True).astype(str)\n",
        "relevant_df['interview_bin'] = pd.cut(relevant_df['number_of_interviews'], bins=interview_bins, include_lowest=True, right=True).astype(str)\n",
        "\n",
        "# Now, apply the updated conversion function to these bins to format the labels\n",
        "relevant_df['application_bin'] = relevant_df['application_bin'].apply(convert_to_int_range)\n",
        "relevant_df['interview_bin'] = relevant_df['interview_bin'].apply(convert_to_int_range)\n",
        "\n",
        "length_of_job_search_labels = [\n",
        "    'Less than one month',\n",
        "    '1-2 months',\n",
        "    '3-5 months',\n",
        "    '6 months to a year',\n",
        "    'Over a year'\n",
        "]\n",
        "\n",
        "fig = make_subplots(rows=1, cols=3, subplot_titles=('Number of Interviews', 'Number of Applications', 'Length of Job Search'))\n",
        "\n",
        "legend_added = {'Placed': False, 'Not Placed': False}  # Keep track of whether the legend was added\n",
        "\n",
        "def plot_column_data(df, column, col):\n",
        "    data_counts = df.groupby([column, 'placed']).size().reset_index(name='count')\n",
        "    total_counts_per_category = df.groupby(column).size().reset_index(name='total')\n",
        "    data_counts = pd.merge(data_counts, total_counts_per_category, on=column)\n",
        "    data_counts['percentage_of_category'] = (data_counts['count'] / data_counts['total']) * 100\n",
        "\n",
        "    colors = {True: 'rgba(102,194,165,1)', False: 'rgba(252,141,98,1)'}  # Custom colors for Placed and Not Placed\n",
        "\n",
        "    for placed_value in [True, False]:\n",
        "        subset = data_counts[data_counts['placed'] == placed_value]\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=subset[column],\n",
        "            y=subset['count']/ df.shape[0] * 100,\n",
        "            name='Placed' if placed_value else 'Not Placed',\n",
        "            marker_color=colors[placed_value],\n",
        "            text=subset['percentage_of_category'].apply(lambda x: f\"{x:.1f}%\"),\n",
        "            textposition='outside',\n",
        "            showlegend=not legend_added['Placed'] if placed_value else not legend_added['Not Placed']\n",
        "        ), row=1, col=col)\n",
        "\n",
        "        if not legend_added['Placed'] and placed_value:\n",
        "            legend_added['Placed'] = True\n",
        "        elif not legend_added['Not Placed'] and not placed_value:\n",
        "            legend_added['Not Placed'] = True\n",
        "\n",
        "# Plotting data for each category\n",
        "plot_column_data(relevant_df, 'interview_bin', 1)\n",
        "plot_column_data(relevant_df, 'application_bin', 2)\n",
        "plot_column_data(relevant_df, 'length_of_job_search', 3)\n",
        "\n",
        "# Update x axes\n",
        "fig.update_xaxes(categoryorder='array', categoryarray=interview_bin_labels, row=1, col=1)\n",
        "fig.update_xaxes(categoryorder='array', categoryarray=application_bin_labels, row=1, col=2)\n",
        "fig.update_xaxes(categoryorder='array', categoryarray=length_of_job_search_labels, row=1, col=3)\n",
        "\n",
        "# Update the layout for a better look\n",
        "fig.update_layout(\n",
        "    height=500,  # Increase height to accommodate legend without overlapping\n",
        "    width=1400,  # Adjust width if necessary\n",
        "    title_text=\"Placement Analysis by Categories\",\n",
        "    barmode='group',\n",
        "    title_x=0.5,\n",
        "    plot_bgcolor='white',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(color='black'),\n",
        "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.4, xanchor=\"right\", x=1)  # Adjust legend position\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sA5a7CGGNr4"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['biggest_challenge_in_search', 'placed']).size().reset_index(name='count')\n",
        "\n",
        "track_totals = df_grouped.groupby('biggest_challenge_in_search')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(relevant_df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_challenge'] = (df_grouped['count'] / track_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_challenge'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "total_counts_per_challenge = df_grouped.groupby('biggest_challenge_in_search')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_within_challenge'] = (df_grouped['count'] / total_counts_per_challenge) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_challenge'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Mapping 'placed' status to descriptive names\n",
        "df_grouped['placed'] = df_grouped['placed'].map({0: 'Not Placed', 1: 'Placed'})\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add traces\n",
        "for name, group in df_grouped.groupby('placed'):\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=group['biggest_challenge_in_search'],\n",
        "        y=group['percentage_of_total'],\n",
        "        name=str(name),  # This now uses the descriptive names 'Not Placed' and 'Placed'\n",
        "        text=group['percentage_text'],\n",
        "        textposition='outside'\n",
        "    ))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distribution of Getting a Job by Biggest Challenge in Search',\n",
        "    xaxis_title='Biggest Challenge in Search',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Being Placed',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    title_x=0.5,\n",
        "    barmode='group',\n",
        "    width=1000, height=600\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjjLBluqdqQz"
      },
      "outputs": [],
      "source": [
        "df_filtered = df[(df['placed'] == 1) &\n",
        "                        (df['program_duration_days'] >= 14) &\n",
        "                        (df['program_duration_days'] <= 365)]\n",
        "\n",
        "mean_values = df_filtered.groupby('biggest_challenge_in_search')['program_duration_days'].mean().reset_index()\n",
        "\n",
        "# Create the box plot with Plotly Express\n",
        "fig = px.box(df_filtered, y='biggest_challenge_in_search', x='program_duration_days',\n",
        "             color='biggest_challenge_in_search',\n",
        "             labels={'program_duration_days': 'Program Duration Days', 'biggest_challenge_in_search': 'Biggest Challenge in Job Search'},\n",
        "             title='Program Duration Days by Biggest Challenge in Job Search for Placed Individuals',\n",
        "             points=\"all\")  # Show all points as dots\n",
        "\n",
        "# Add scatter plot of mean values on top of the box plots\n",
        "fig.add_trace(go.Scatter(y=mean_values['biggest_challenge_in_search'], x=mean_values['program_duration_days'],\n",
        "                         mode='markers', marker=dict(color='black', size=8, symbol=\"x\"),\n",
        "                         name='Mean', showlegend=False))\n",
        "\n",
        "# Remove all legends and adjust layout\n",
        "fig.update_layout(showlegend=False,  # This hides all legends\n",
        "                  yaxis={'categoryorder':'total ascending'},\n",
        "                  xaxis_title='Program Duration Days',\n",
        "                  yaxis_title='Biggest Challenge in Job Search', title_x=0.5,\n",
        "    width=800, height=700)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjN5fAyieTqT"
      },
      "outputs": [],
      "source": [
        "category_order = [\n",
        "    'Less than one month',\n",
        "    '1-2 months',\n",
        "    '3-5 months',\n",
        "    '6 months to a year',\n",
        "    'Over a year'\n",
        "]\n",
        "\n",
        "# relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred'])) &\n",
        "#                  (df['program_duration_days'] >= 14) &\n",
        "#                  (df['program_duration_days'] <= 365)]\n",
        "\n",
        "relevant_df = df.copy()\n",
        "\n",
        "df_grouped = relevant_df.groupby(['length_of_job_search', 'biggest_challenge_in_search']).size().reset_index(name='count')\n",
        "\n",
        "# Calculate total counts for each 'employment_status'\n",
        "status_totals = df_grouped.groupby('length_of_job_search')['count'].transform('sum')\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' relative to the total number of entries in the dataset\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' within its 'employment_status'\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "# Format the 'percentage_within_status' column for display as text on top of each bar\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Create the bar chart using the 'percentage_of_total' for the y-axis values\n",
        "# and display the formatted 'percentage_within_status' as text on top of each bar\n",
        "fig = px.bar(df_grouped, x='length_of_job_search', y='percentage_of_total', color='biggest_challenge_in_search',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Biggest Challenge in Job Search by Length of Job Search',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'length_of_job_search': 'Length of Job Search', 'biggest_challenge_in_search': 'Biggest Challenge in Job Search'},\n",
        "             category_orders={'length_of_job_search': category_order},\n",
        "             barmode='group')  # Use 'group' to place bars side by side\n",
        "\n",
        "# Apply custom formatting for text on bars for better visibility\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "# Update layout for better readability and aesthetics\n",
        "fig.update_layout(\n",
        "    xaxis_title='Length of Job Search',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Biggest Challenge in Job Search',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'), title_x=0.5,\n",
        "    width=1900, height=800\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u772SikMkJXy"
      },
      "outputs": [],
      "source": [
        "# relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred'])) &\n",
        "#                  (df['starting_year'] != '20') &\n",
        "#                  (df['program_duration_days'] >= 14) &\n",
        "#                  (df['program_duration_days'] <= 365)]\n",
        "\n",
        "relevant_df = df[(df['starting_year'] != '20')]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['starting_year', 'biggest_challenge_in_search']).size().reset_index(name='count')\n",
        "\n",
        "# Calculate total counts for each 'employment_status'\n",
        "status_totals = df_grouped.groupby('starting_year')['count'].transform('sum')\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' relative to the total number of entries in the dataset\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' within its 'employment_status'\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "# Format the 'percentage_within_status' column for display as text on top of each bar\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Create the bar chart using the 'percentage_of_total' for the y-axis values\n",
        "# and display the formatted 'percentage_within_status' as text on top of each bar\n",
        "fig = px.bar(df_grouped, x='starting_year', y='percentage_of_total', color='biggest_challenge_in_search',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Biggest Challenge in Job Search by Starting Year',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'starting_year': 'Starting Year', 'biggest_challenge_in_search': 'Biggest Challenge in Job Search'},\n",
        "             category_orders={'starting_year': category_order},\n",
        "             barmode='group')  # Use 'group' to place bars side by side\n",
        "\n",
        "# Apply custom formatting for text on bars for better visibility\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "# Update layout for better readability and aesthetics\n",
        "fig.update_layout(\n",
        "    xaxis_title='Length of Job Search',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Biggest Challenge in Job Search',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'), title_x=0.5,\n",
        "    width=1500, height=800\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD0tY4XNtRW-"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['employment_status ', 'biggest_challenge_in_search']).size().reset_index(name='count')\n",
        "\n",
        "# Calculate total counts for each 'employment_status'\n",
        "status_totals = df_grouped.groupby('employment_status ')['count'].transform('sum')\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' relative to the total number of entries in the dataset\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' within its 'employment_status'\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "# Format the 'percentage_within_status' column for display as text on top of each bar\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Create the bar chart using the 'percentage_of_total' for the y-axis values\n",
        "# and display the formatted 'percentage_within_status' as text on top of each bar\n",
        "fig = px.bar(df_grouped, x='employment_status ', y='percentage_of_total', color='biggest_challenge_in_search',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Biggest Challenge in Job Search by Employment Status',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'employment_status ': 'Employment Status', 'biggest_challenge_in_search': 'Biggest Challenge in Job Search'},\n",
        "             barmode='group')  # Use 'group' to place bars side by side\n",
        "\n",
        "# Apply custom formatting for text on bars for better visibility\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "# Update layout for better readability and aesthetics\n",
        "fig.update_layout(\n",
        "    xaxis_title='Employment Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Biggest Challenge in Job Search',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'), title_x=0.5,\n",
        "    width=1900, height=800\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-uZ_QiRJOra"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-l25OGVwB98"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['primary_track', 'biggest_challenge_in_search']).size().reset_index(name='count')\n",
        "\n",
        "# Calculate total counts for each 'employment_status'\n",
        "status_totals = df_grouped.groupby('primary_track')['count'].transform('sum')\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' relative to the total number of entries in the dataset\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' within its 'employment_status'\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "# Format the 'percentage_within_status' column for display as text on top of each bar\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Create the bar chart using the 'percentage_of_total' for the y-axis values\n",
        "# and display the formatted 'percentage_within_status' as text on top of each bar\n",
        "fig = px.bar(df_grouped, x='primary_track', y='percentage_of_total', color='biggest_challenge_in_search',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Biggest Challenge in Job Search by Primary Track',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'primary_track': 'Primary Track', 'biggest_challenge_in_search': 'Biggest Challenge in Job Search'},\n",
        "             barmode='group')  # Use 'group' to place bars side by side\n",
        "\n",
        "# Apply custom formatting for text on bars for better visibility\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "# Update layout for better readability and aesthetics\n",
        "fig.update_layout(\n",
        "    xaxis_title='Primary Track',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Biggest Challenge in Job Search',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'), title_x=0.5,\n",
        "    width=2100, height=800\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mr46VGuszquf"
      },
      "outputs": [],
      "source": [
        "df_filtered = df[(df['number_of_applications'] < 250)]\n",
        "\n",
        "mean_values = df_filtered.groupby('biggest_challenge_in_search')['number_of_applications'].mean().reset_index()\n",
        "\n",
        "# Create the box plot with Plotly Express\n",
        "fig = px.box(df_filtered, y='biggest_challenge_in_search', x='number_of_applications',\n",
        "             color='biggest_challenge_in_search',\n",
        "             labels={'number_of_applications': 'Number of Applications', 'biggest_challenge_in_search': 'Biggest Challenge in Job Search'},\n",
        "             title='Number of Applications by Biggest Challenge in Job Search',\n",
        "             points=\"all\")  # Show all points as dots\n",
        "\n",
        "# Add scatter plot of mean values on top of the box plots\n",
        "fig.add_trace(go.Scatter(y=mean_values['biggest_challenge_in_search'], x=mean_values['number_of_applications'],\n",
        "                         mode='markers', marker=dict(color='black', size=8, symbol=\"x\"),\n",
        "                         name='Mean', showlegend=False))\n",
        "\n",
        "# Remove all legends and adjust layout\n",
        "fig.update_layout(showlegend=False,  # This hides all legends\n",
        "                  yaxis={'categoryorder':'total ascending'},\n",
        "                  xaxis_title='Number of Applications',\n",
        "                  yaxis_title='Biggest Challenge in Job Search', title_x=0.5,\n",
        "    width=800, height=700)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWxpEgq-6YNB"
      },
      "outputs": [],
      "source": [
        "challenges = df['biggest_challenge_in_search'].dropna().unique()\n",
        "n_challenges = len(challenges)\n",
        "\n",
        "# Determine the number of rows and columns for subplots\n",
        "n_cols = 4\n",
        "n_rows = n_challenges // n_cols + (n_challenges % n_cols > 0)\n",
        "\n",
        "# Create subplots\n",
        "fig = make_subplots(rows=n_rows, cols=n_cols, subplot_titles=challenges)\n",
        "\n",
        "# Track the current position\n",
        "current_row = 1\n",
        "current_col = 1\n",
        "\n",
        "for challenge in challenges:\n",
        "    filtered_df = df[df['biggest_challenge_in_search'] == challenge]['number_of_applications'].dropna()\n",
        "\n",
        "    # Calculate histogram manually\n",
        "    counts, bins = np.histogram(filtered_df, bins=20)\n",
        "    bins_center = 0.5 * (bins[:-1] + bins[1:])\n",
        "\n",
        "    # Add the line plot for the histogram\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=bins_center, y=counts, mode='lines+markers', name=challenge),\n",
        "        row=current_row, col=current_col\n",
        "    )\n",
        "\n",
        "    current_col += 1\n",
        "    if current_col > n_cols:\n",
        "        current_row += 1\n",
        "        current_col = 1\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(height=400*n_rows, width=1700, title_text=\"Count of Number of Applications by Biggest Challenge in Search\",title_x=0.5, showlegend=False)\n",
        "fig.update_yaxes(title_text=\"Count\")\n",
        "fig.update_xaxes(title_text=\"Number of Applications\")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3Fs8Sc17dLf"
      },
      "outputs": [],
      "source": [
        "bins = np.linspace(df['number_of_applications'].min(), df['number_of_applications'].max(), 20)\n",
        "df['application_bins'] = pd.cut(df['number_of_applications'], bins)\n",
        "\n",
        "# Prepare a DataFrame for plotting\n",
        "plot_data = df.groupby(['biggest_challenge_in_search', 'application_bins'])['id'].count().reset_index(name='count')\n",
        "plot_data['bin_center'] = plot_data['application_bins'].apply(lambda x: x.mid).astype(float)\n",
        "\n",
        "# Select a vibrant color palette\n",
        "palette = sns.color_palette(\"tab10\")  # This is an example of a vibrant palette\n",
        "\n",
        "# Create a line plot for each challenge using the selected palette\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.lineplot(data=plot_data, x='bin_center', y='count', hue='biggest_challenge_in_search', marker='o', palette=palette)\n",
        "\n",
        "plt.title('Number of Applications Distribution Across Challenges', fontsize=16)\n",
        "plt.xlabel('Number of Applications', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.legend(title='Biggest Challenge in Search', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
        "plt.grid(True)  # Adding grid for better readability\n",
        "plt.tight_layout()\n",
        "fig.update_layout(height=500, width=500)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1x85J0MAn3P"
      },
      "outputs": [],
      "source": [
        "challenges = df[df['number_of_applications'] <= 25]['biggest_challenge_in_search'].dropna().unique()\n",
        "n_challenges = len(challenges)\n",
        "\n",
        "# Determine the number of rows and columns for subplots\n",
        "n_cols = 4\n",
        "n_rows = n_challenges // n_cols + (n_challenges % n_cols > 0)\n",
        "\n",
        "# Create subplots\n",
        "fig = make_subplots(rows=n_rows, cols=n_cols, subplot_titles=challenges)\n",
        "\n",
        "# Track the current position\n",
        "current_row = 1\n",
        "current_col = 1\n",
        "\n",
        "# Define bins from 0 to 26, ensuring each bin corresponds to an integer value\n",
        "bins = np.arange(0, 27)  # Creates an array [0, 1, 2, ..., 25, 26]\n",
        "\n",
        "for challenge in challenges:\n",
        "    filtered_df = df[(df['number_of_applications'] <= 25) & (df['biggest_challenge_in_search'] == challenge)]['number_of_applications'].dropna()\n",
        "\n",
        "    # Calculate histogram manually with defined bins\n",
        "    counts, _ = np.histogram(filtered_df, bins=bins)\n",
        "\n",
        "    # Use bin centers as x values for plotting\n",
        "    bins_center = 0.5 * (bins[:-1] + bins[1:])\n",
        "\n",
        "    # Add the line plot for the histogram\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=bins[:-1], y=counts, mode='lines+markers', name=challenge),\n",
        "        row=current_row, col=current_col\n",
        "    )\n",
        "\n",
        "    current_col += 1\n",
        "    if current_col > n_cols:\n",
        "        current_row += 1\n",
        "        current_col = 1\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(height=400*n_rows, width=1700, title_text=\"Count of Number of Applications by Biggest Challenge in Search\", showlegend=False, title_x=0.5)\n",
        "\n",
        "# Set tick values for the x-axis to appear every 5 units\n",
        "xticks = np.arange(0, 26, 5)  # Generates [0, 5, 10, 15, 20, 25]\n",
        "\n",
        "# Apply the xticks setting to each subplot\n",
        "for i in range(1, n_rows+1):\n",
        "    for j in range(1, n_cols+1):\n",
        "        fig.update_xaxes(title_text=\"Number of Applications\", tickvals=xticks, row=i, col=j)\n",
        "\n",
        "fig.update_yaxes(title_text=\"Count\")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwxxc1SB2gqS"
      },
      "outputs": [],
      "source": [
        "df_filtered = df.copy()\n",
        "\n",
        "mean_values = df_filtered.groupby('biggest_challenge_in_search')['number_of_interviews'].mean().reset_index()\n",
        "\n",
        "# Create the box plot with Plotly Express\n",
        "fig = px.box(df_filtered, y='biggest_challenge_in_search', x='number_of_interviews',\n",
        "             color='biggest_challenge_in_search',\n",
        "             labels={'number_of_interviews': 'Number of Interviews', 'biggest_challenge_in_search': 'Biggest Challenge in Job Search'},\n",
        "             title='Number of interviews by Biggest Challenge in Job Search',\n",
        "             points=\"all\")  # Show all points as dots\n",
        "\n",
        "# Add scatter plot of mean values on top of the box plots\n",
        "fig.add_trace(go.Scatter(y=mean_values['biggest_challenge_in_search'], x=mean_values['number_of_interviews'],\n",
        "                         mode='markers+text', marker=dict(color='black', size=8, symbol=\"x\"),\n",
        "                         textposition=\"top center\",\n",
        "                         text=[f\"{x:.2f}\" for x in mean_values['number_of_interviews']],\n",
        "                         name='Mean', showlegend=False))\n",
        "\n",
        "# fig.add_trace(go.Scatter(y=mean_values['professional_experience'], x=mean_values['program_duration_days'],\n",
        "#                          mode='markers+text',\n",
        "#                          text=[f\"{x:.2f}\" for x in mean_values['program_duration_days']],  # Format text to 2 decimal places\n",
        "#                          textposition=\"top center\",\n",
        "#                          marker=dict(color='black', size=8, symbol=\"x\"),\n",
        "#                          name='Mean'))\n",
        "\n",
        "\n",
        "# Remove all legends and adjust layout\n",
        "fig.update_layout(showlegend=False,  # This hides all legends\n",
        "                  yaxis={'categoryorder':'total ascending'},\n",
        "                  xaxis_title='Number of interviews',\n",
        "                  yaxis_title='Biggest Challenge in Job Search', title_x=0.5,\n",
        "                  width=800, height=700)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lanzTQ0ciUgM"
      },
      "source": [
        "Mostly positively skewed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzvSHRor7L3f"
      },
      "outputs": [],
      "source": [
        "challenges = df['biggest_challenge_in_search'].dropna().unique()\n",
        "n_challenges = len(challenges)\n",
        "\n",
        "# Determine the number of rows and columns for subplots\n",
        "n_cols = 4\n",
        "n_rows = n_challenges // n_cols + (n_challenges % n_cols > 0)\n",
        "\n",
        "# Create subplots\n",
        "fig = make_subplots(rows=n_rows, cols=n_cols, subplot_titles=challenges)\n",
        "\n",
        "# Track the current position\n",
        "current_row = 1\n",
        "current_col = 1\n",
        "\n",
        "for challenge in challenges:\n",
        "    filtered_df = df[df['biggest_challenge_in_search'] == challenge]['number_of_interviews'].dropna()\n",
        "\n",
        "    # Calculate histogram manually\n",
        "    counts, bins = np.histogram(filtered_df, bins=20)\n",
        "    bins_center = 0.5 * (bins[:-1] + bins[1:])\n",
        "\n",
        "    # Add the line plot for the histogram\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=bins_center, y=counts, mode='lines+markers', name=challenge),\n",
        "        row=current_row, col=current_col\n",
        "    )\n",
        "\n",
        "    current_col += 1\n",
        "    if current_col > n_cols:\n",
        "        current_row += 1\n",
        "        current_col = 1\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(height=400*n_rows, width=1700, title_text=\"Count of Number of Interviews by Biggest Challenge in Search\", showlegend=False, title_x=0.5)\n",
        "fig.update_yaxes(title_text=\"Count\")\n",
        "fig.update_xaxes(title_text=\"Number of Interviews\")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVEe-d-AC18k"
      },
      "outputs": [],
      "source": [
        "bins = np.linspace(df['number_of_interviews'].min(), df['number_of_interviews'].max(), 20)\n",
        "df['interviews_bins'] = pd.cut(df['number_of_interviews'], bins)\n",
        "\n",
        "# Prepare a DataFrame for plotting\n",
        "plot_data = df.groupby(['biggest_challenge_in_search', 'interviews_bins'])['id'].count().reset_index(name='count')\n",
        "plot_data['bin_center'] = plot_data['interviews_bins'].apply(lambda x: x.mid).astype(float)\n",
        "\n",
        "# Select a vibrant color palette\n",
        "palette = sns.color_palette(\"tab10\")  # This is an example of a vibrant palette\n",
        "\n",
        "# Create a line plot for each challenge using the selected palette\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.lineplot(data=plot_data, x='bin_center', y='count', hue='biggest_challenge_in_search', marker='o', palette=palette)\n",
        "\n",
        "plt.title('Number of Interviews Distribution Across Challenges', fontsize=16)\n",
        "plt.xlabel('Number of Interviews', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.legend(title='Biggest Challenge in Search', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
        "plt.grid(True)  # Adding grid for better readability\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AE368nCDKws"
      },
      "outputs": [],
      "source": [
        "challenges = df[df['number_of_interviews'] <= 20]['biggest_challenge_in_search'].dropna().unique()\n",
        "n_challenges = len(challenges)\n",
        "\n",
        "# Determine the number of rows and columns for subplots\n",
        "n_cols = 4\n",
        "n_rows = n_challenges // n_cols + (n_challenges % n_cols > 0)\n",
        "\n",
        "# Create subplots\n",
        "fig = make_subplots(rows=n_rows, cols=n_cols, subplot_titles=challenges)\n",
        "\n",
        "# Track the current position\n",
        "current_row = 1\n",
        "current_col = 1\n",
        "\n",
        "# Define bins from 0 to 26, ensuring each bin corresponds to an integer value\n",
        "bins = np.arange(0, 22)  # Creates an array [0, 1, 2, ..., 25, 26]\n",
        "\n",
        "for challenge in challenges:\n",
        "    filtered_df = df[(df['number_of_interviews'] <= 20) & (df['biggest_challenge_in_search'] == challenge)]['number_of_interviews'].dropna()\n",
        "\n",
        "    # Calculate histogram manually with defined bins\n",
        "    counts, _ = np.histogram(filtered_df, bins=bins)\n",
        "\n",
        "    # Use bin centers as x values for plotting\n",
        "    bins_center = 0.5 * (bins[:-1] + bins[1:])\n",
        "\n",
        "    # Add the line plot for the histogram\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=bins[:-1], y=counts, mode='lines+markers', name=challenge),\n",
        "        row=current_row, col=current_col\n",
        "    )\n",
        "\n",
        "    current_col += 1\n",
        "    if current_col > n_cols:\n",
        "        current_row += 1\n",
        "        current_col = 1\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(height=400*n_rows, width=1700, title_text=\"Count of Number of Interviews by Biggest Challenge in Search\", showlegend=False, title_x=0.5)\n",
        "\n",
        "# Set tick values for the x-axis to appear every 5 units\n",
        "xticks = np.arange(0, 26, 5)  # Generates [0, 5, 10, 15, 20, 25]\n",
        "\n",
        "# Apply the xticks setting to each subplot\n",
        "for i in range(1, n_rows+1):\n",
        "    for j in range(1, n_cols+1):\n",
        "        fig.update_xaxes(title_text=\"Number of Interviews\", tickvals=xticks, row=i, col=j)\n",
        "\n",
        "fig.update_yaxes(title_text=\"Count\")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLn-_dBpLibv"
      },
      "outputs": [],
      "source": [
        "category_order = [\n",
        "    'Less than one year',\n",
        "    '1-2 years',\n",
        "    '3-4 years',\n",
        "    '5+ years'\n",
        "]\n",
        "\n",
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['professional_experience', 'placed']).size().reset_index(name='count')\n",
        "\n",
        "track_totals = df_grouped.groupby('professional_experience')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(relevant_df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_experience_class'] = (df_grouped['count'] / track_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_experience_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "total_counts_per_challenge = df_grouped.groupby('professional_experience')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_within_experience_class'] = (df_grouped['count'] / total_counts_per_challenge) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_experience_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Mapping 'placed' status to descriptive names\n",
        "df_grouped['placed'] = df_grouped['placed'].map({0: 'Not Placed', 1: 'Placed'})\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add traces\n",
        "for name, group in df_grouped.groupby('placed'):\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=group['professional_experience'],\n",
        "        y=group['percentage_of_total'],\n",
        "        name=str(name),  # This now uses the descriptive names 'Not Placed' and 'Placed'\n",
        "        text=group['percentage_text'],\n",
        "        textposition='outside'\n",
        "    ))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distribution of Getting a Job by Prior Professional Experience',\n",
        "    xaxis_title='Prior Professional Experience',\n",
        "    xaxis=dict(\n",
        "        categoryorder='array',\n",
        "        categoryarray=category_order  # Ensure the x-axis categories are ordered as desired\n",
        "    ),\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Being Placed',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    title_x=0.5,\n",
        "    barmode='group',\n",
        "    width=600, height=600\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2DILDMzL9Ot"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(df['pathrise_status'].isin(['Placed'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "category_order = ['Less than one year', '1-2 years', '3-4 years', '5+ years']\n",
        "relevant_df['professional_experience'] = pd.Categorical(relevant_df['professional_experience'], categories=category_order, ordered=True)\n",
        "\n",
        "mean_values = relevant_df.groupby('professional_experience')['program_duration_days'].mean().reset_index()\n",
        "\n",
        "fig = px.box(relevant_df, y='professional_experience', x='program_duration_days',\n",
        "             color='professional_experience',\n",
        "             labels={'program_duration_days': 'Program Duration Days', 'professional_experience': 'Professional Experience'},\n",
        "             title='Program Duration Days by Professional Experience for Placed Individuals',\n",
        "             points=\"all\")\n",
        "\n",
        "fig.add_trace(go.Scatter(y=mean_values['professional_experience'], x=mean_values['program_duration_days'],\n",
        "                         mode='markers+text',\n",
        "                         text=[f\"{x:.2f}\" for x in mean_values['program_duration_days']],  # Format text to 2 decimal places\n",
        "                         textposition=\"top center\",\n",
        "                         marker=dict(color='black', size=8, symbol=\"x\"),\n",
        "                         name='Mean'))\n",
        "\n",
        "fig.update_layout(showlegend=True,\n",
        "                  yaxis={'categoryorder':'array', 'categoryarray': category_order},\n",
        "                  xaxis_title='Program Duration Days',\n",
        "                  yaxis_title='Professional Experience', title_x=0.5,\n",
        "                  width=800, height=600)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnw2aDsAzIBD"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojQNb9tfzIah"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JniMzeuHfpTd"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "relevant_df.dropna(subset=['work_authorization_status'], inplace=True)\n",
        "\n",
        "df_grouped = relevant_df.groupby(['work_authorization_status', 'placed']).size().reset_index(name='count')\n",
        "\n",
        "track_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(relevant_df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_experience_class'] = (df_grouped['count'] / track_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_experience_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "total_counts_per_challenge = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_within_experience_class'] = (df_grouped['count'] / total_counts_per_challenge) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_experience_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Mapping 'placed' status to descriptive names\n",
        "df_grouped['placed'] = df_grouped['placed'].map({0: 'Not Placed', 1: 'Placed'})\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add traces\n",
        "for name, group in df_grouped.groupby('placed'):\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=group['work_authorization_status'],\n",
        "        y=group['percentage_of_total'],\n",
        "        name=str(name),  # This now uses the descriptive names 'Not Placed' and 'Placed'\n",
        "        text=group['percentage_text'],\n",
        "        textposition='outside'\n",
        "    ))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distribution of Getting a Job by Work Authorization Status',\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    xaxis=dict(\n",
        "        categoryorder='array',\n",
        "        categoryarray=category_order  # Ensure the x-axis categories are ordered as desired\n",
        "    ),\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Being Placed',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    title_x=0.5,\n",
        "    barmode='group',\n",
        "    width=1000, height=600\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UFpVA8zfqm1"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(df['pathrise_status'].isin(['Placed'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "relevant_df.dropna(subset=['work_authorization_status'], inplace=True)\n",
        "\n",
        "mean_values = relevant_df.groupby('work_authorization_status')['program_duration_days'].mean().reset_index()\n",
        "\n",
        "\n",
        "fig = px.box(relevant_df, y='work_authorization_status', x='program_duration_days',\n",
        "             color='work_authorization_status',\n",
        "             labels={'program_duration_days': 'Program Duration Days', 'work_authorization_status': 'Work Authorization Status'},\n",
        "             title='Program Duration Days by Work Authorization Status for Placed Individuals',\n",
        "             points=\"all\")\n",
        "\n",
        "fig.add_trace(go.Scatter(y=mean_values['work_authorization_status'], x=mean_values['program_duration_days'],\n",
        "                         mode='markers+text',\n",
        "                         text=[f\"{x:.2f}\" for x in mean_values['program_duration_days']],  # Format text to 2 decimal places\n",
        "                         textposition=\"top center\",\n",
        "                         marker=dict(color='black', size=8, symbol=\"x\"),\n",
        "                         name='Mean'))\n",
        "\n",
        "fig.update_layout(showlegend=True,\n",
        "                  yaxis={'categoryorder':'array', 'categoryarray': category_order},\n",
        "                  xaxis_title='Program Duration Days',\n",
        "                  yaxis_title='Work Authorization Status', title_x=0.5,\n",
        "                  width=800, height=800)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF08tVOYytv4"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby(['work_authorization_status', 'employment_status ']).size().reset_index(name='count')\n",
        "\n",
        "# Calculate total counts for each 'employment_status'\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' relative to the total number of entries in the dataset\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' within its 'employment_status'\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "# Format the 'percentage_within_status' column for display as text on top of each bar\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Create the bar chart using the 'percentage_of_total' for the y-axis values\n",
        "# and display the formatted 'percentage_within_status' as text on top of each bar\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='employment_status ',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Employment Status',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'employment_status ': 'Employment Status'},\n",
        "             barmode='group')  # Use 'group' to place bars side by side\n",
        "\n",
        "# Apply custom formatting for text on bars for better visibility\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "# Update layout for better readability and aesthetics\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Employment Status',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1900, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcmtw8LWuvL3"
      },
      "outputs": [],
      "source": [
        "df_filterd = df[df['placed'] == 1]\n",
        "\n",
        "df_grouped = df_filterd.groupby(['work_authorization_status', 'employment_status ']).size().reset_index(name='count')\n",
        "\n",
        "# Calculate total counts for each 'employment_status'\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' relative to the total number of entries in the dataset\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df_filterd)) * 100\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' within its 'employment_status'\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "# Format the 'percentage_within_status' column for display as text on top of each bar\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Create the bar chart using the 'percentage_of_total' for the y-axis values\n",
        "# and display the formatted 'percentage_within_status' as text on top of each bar\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='employment_status ',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Employment Status',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'employment_status ': 'Employment Status'},\n",
        "             barmode='group')  # Use 'group' to place bars side by side\n",
        "\n",
        "# Apply custom formatting for text on bars for better visibility\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "# Update layout for better readability and aesthetics\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Employment Status',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1900, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mc-v9_a0AAv"
      },
      "outputs": [],
      "source": [
        "job_search_order = [\n",
        "    'Less than one month',\n",
        "    '1-2 months',\n",
        "    '3-5 months',\n",
        "    '6 months to a year',\n",
        "    'Over a year'\n",
        "]\n",
        "\n",
        "\n",
        "color_map = {\n",
        "    'Less than one month': '#FA8072',\n",
        "    '1-2 months': '#FDB147',\n",
        "    '3-5 months': '#9ACD32',\n",
        "    '6 months to a year': '#6495ED',\n",
        "    'Over a year': '#BA55D3'\n",
        "}\n",
        "\n",
        "df_grouped = df.groupby(['work_authorization_status', 'length_of_job_search']).size().reset_index(name='count')\n",
        "\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='length_of_job_search',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Length of Job Search',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'length_of_job_search': 'Length of Job Search'},\n",
        "             barmode='group', category_orders={'length_of_job_search': job_search_order},\n",
        "             color_discrete_map=color_map)\n",
        "\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Length of Job Search',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1900, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME63zo061jec"
      },
      "outputs": [],
      "source": [
        "education_order = [\n",
        "    'Doctorate or Professional Degree',\n",
        "    \"Master's Degree\",\n",
        "    \"Bachelor's Degree\",\n",
        "    'Some College, No Degree',\n",
        "    'GED or equivalent',\n",
        "    'High School Graduate',\n",
        "    'Some High School'\n",
        "]\n",
        "\n",
        "df_grouped = df.groupby(['work_authorization_status', 'highest_level_of_education']).size().reset_index(name='count')\n",
        "\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='highest_level_of_education',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Highest Level of Education',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'highest_level_of_education': 'Highest Level of Education'},\n",
        "             barmode='group', category_orders={'highest_level_of_education': education_order},\n",
        "             color_discrete_map=color_map)\n",
        "\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Highest Level of Education',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=2100, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Fd8WP-ptTWI"
      },
      "outputs": [],
      "source": [
        "df_filterd = df[df['placed'] == 1]\n",
        "\n",
        "education_order = [\n",
        "    'Doctorate or Professional Degree',\n",
        "    \"Master's Degree\",\n",
        "    \"Bachelor's Degree\",\n",
        "    'Some College, No Degree',\n",
        "    'GED or equivalent',\n",
        "    'High School Graduate',\n",
        "    'Some High School'\n",
        "]\n",
        "\n",
        "df_grouped = df_filterd.groupby(['work_authorization_status', 'highest_level_of_education']).size().reset_index(name='count')\n",
        "\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df_filterd)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='highest_level_of_education',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Highest Level of Education Among Placed Individuals by Work Authorization Status',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'highest_level_of_education': 'Highest Level of Education'},\n",
        "             barmode='group', category_orders={'highest_level_of_education': education_order},\n",
        "             color_discrete_map=color_map)\n",
        "\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Highest Level of Education',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=2100, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM6fMyHH3j9H"
      },
      "outputs": [],
      "source": [
        "# relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred'])) &\n",
        "#                  (df['starting_year'] != '20') &\n",
        "#                  (df['program_duration_days'] >= 14) &\n",
        "#                  (df['program_duration_days'] <= 365)]\n",
        "\n",
        "relevant_df = df[(df['starting_year'] != '20')]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['starting_year', 'work_authorization_status']).size().reset_index(name='count')\n",
        "\n",
        "# Calculate total counts for each 'employment_status'\n",
        "status_totals = df_grouped.groupby('starting_year')['count'].transform('sum')\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' relative to the total number of entries in the dataset\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "# Calculate the percentage of each 'pathrise_status' within its 'employment_status'\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "# Format the 'percentage_within_status' column for display as text on top of each bar\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Create the bar chart using the 'percentage_of_total' for the y-axis values\n",
        "# and display the formatted 'percentage_within_status' as text on top of each bar\n",
        "fig = px.bar(df_grouped, x='starting_year', y='percentage_of_total', color='work_authorization_status',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Starting Year',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'starting_year': 'Starting Year', 'work_authorization_status': 'Work Authorization Status'},\n",
        "             category_orders={'starting_year': category_order},\n",
        "             barmode='group')  # Use 'group' to place bars side by side\n",
        "\n",
        "# Apply custom formatting for text on bars for better visibility\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "# Update layout for better readability and aesthetics\n",
        "fig.update_layout(\n",
        "    xaxis_title='Starting Year',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Work Authorization Status',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'), title_x=0.5,\n",
        "    width=1900, height=800\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpYAcdWX4DJv"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby(['work_authorization_status', 'primary_track']).size().reset_index(name='count')\n",
        "\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='primary_track',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Primary Track',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'primary_track': 'Primary Track'},\n",
        "             barmode='group')\n",
        "\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Primary Track',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=2100, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9cXrioW5dGY"
      },
      "outputs": [],
      "source": [
        "month_order = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']\n",
        "\n",
        "df_grouped = df.groupby(['employment_status ', 'starting_month']).size().reset_index(name='count')\n",
        "\n",
        "total_counts_per_month = df.groupby('starting_month')['starting_month'].count().rename('month_total')\n",
        "\n",
        "df_grouped = df_grouped.merge(total_counts_per_month, on='starting_month', how='left')\n",
        "\n",
        "df_grouped['status_percentage'] = (df_grouped['count'] / df_grouped['month_total'] * 100).round(2)\n",
        "\n",
        "df_grouped = df.groupby(['work_authorization_status', 'starting_month']).size().reset_index(name='count')\n",
        "\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='starting_month',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Starting Month',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'starting_month': 'Starting Month'},\n",
        "             barmode='group',\n",
        "             category_orders={'starting_month': month_order})  # Ensure month order for legend and columns\n",
        "\n",
        "# Custom formatting for improved visual aesthetics\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Starting Month',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=2900, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ulo_Zcz17A-P"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby(['work_authorization_status', 'gender']).size().reset_index(name='count')\n",
        "\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='gender',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Gender',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'gender': 'Gender'},\n",
        "             barmode='group')\n",
        "\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Gender',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1600, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Darb_3Kn7ijU"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby(['work_authorization_status', 'race']).size().reset_index(name='count')\n",
        "\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='race',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Race',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'race': 'Race'},\n",
        "             barmode='group')\n",
        "\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Race',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=2900, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxbh9KXyEnr_"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby(['work_authorization_status', 'pathrise_status']).size().reset_index(name='count')\n",
        "\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='pathrise_status',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Pathrise Status',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'pathrise_status': 'Pathrise Status'},\n",
        "             barmode='group')\n",
        "\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Pathrise Status',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=2900, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-GVvVI8FkjM"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby(['work_authorization_status', 'biggest_challenge_in_search']).size().reset_index(name='count')\n",
        "\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='biggest_challenge_in_search',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Biggest Challenge in Search',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'biggest_challenge_in_search': 'Biggest Challenge in Search'},\n",
        "             barmode='group')\n",
        "\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Biggest Challenge in Search',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=2900, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcmDzTKyHGQ1"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby(['work_authorization_status', 'professional_experience']).size().reset_index(name='count')\n",
        "\n",
        "status_totals = df_grouped.groupby('work_authorization_status')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage_of_total', color='professional_experience',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Work Authorization Status by Professional Experience',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'work_authorization_status': 'Work Authorization Status', 'professional_experience': 'Professional Experience'},\n",
        "             barmode='group')\n",
        "\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Work Authorization Status',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Professional Experience',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1900, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtsgkyynHfO9"
      },
      "outputs": [],
      "source": [
        "df_grouped = df.groupby(['biggest_challenge_in_search', 'professional_experience']).size().reset_index(name='count')\n",
        "\n",
        "status_totals = df_grouped.groupby('professional_experience')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_status'] = (df_grouped['count'] / status_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_status'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "fig = px.bar(df_grouped, x='professional_experience', y='percentage_of_total', color='biggest_challenge_in_search',\n",
        "             text='percentage_text',\n",
        "             title='Distribution of Professional Experience by Biggest Challenge in Search',\n",
        "             labels={'percentage_of_total': 'Percentage of Total', 'professional_experience': 'Professional Experience', 'biggest_challenge_in_search': 'Biggest Challenge in Search'},\n",
        "             barmode='group')\n",
        "\n",
        "# Update the layout and traces for better readability and visual aesthetics\n",
        "fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
        "fig.update_layout(\n",
        "    xaxis_title='Professional Experience',\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Biggest Challenge in Search',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1900, height=800, title_x=0.5\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8nif6sFJCZR"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['race', 'placed']).size().reset_index(name='count')\n",
        "\n",
        "track_totals = df_grouped.groupby('race')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(relevant_df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_experience_class'] = (df_grouped['count'] / track_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_experience_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "total_counts_per_challenge = df_grouped.groupby('race')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_within_experience_class'] = (df_grouped['count'] / total_counts_per_challenge) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_experience_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Mapping 'placed' status to descriptive names\n",
        "df_grouped['placed'] = df_grouped['placed'].map({0: 'Not Placed', 1: 'Placed'})\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add traces\n",
        "for name, group in df_grouped.groupby('placed'):\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=group['race'],\n",
        "        y=group['percentage_of_total'],\n",
        "        name=str(name),  # This now uses the descriptive names 'Not Placed' and 'Placed'\n",
        "        text=group['percentage_text'],\n",
        "        textposition='outside'\n",
        "    ))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distribution of Getting a Job by Race',\n",
        "    xaxis_title='Race',\n",
        "    xaxis=dict(\n",
        "        categoryorder='array',\n",
        "        categoryarray=category_order  # Ensure the x-axis categories are ordered as desired\n",
        "    ),\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Being Placed',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    title_x=0.5,\n",
        "    barmode='group',\n",
        "    width=1000, height=800\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjaH3KtrJFDD"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(df['pathrise_status'].isin(['Placed'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "relevant_df.dropna(subset=['race'], inplace=True)\n",
        "\n",
        "mean_values = relevant_df.groupby('race')['program_duration_days'].mean().reset_index()\n",
        "\n",
        "\n",
        "fig = px.box(relevant_df, y='race', x='program_duration_days',\n",
        "             color='race',\n",
        "             labels={'program_duration_days': 'Program Duration Days', 'race': 'Race'},\n",
        "             title='Program Duration Days by Race for Placed Individuals',\n",
        "             points=\"all\")\n",
        "\n",
        "fig.add_trace(go.Scatter(y=mean_values['race'], x=mean_values['program_duration_days'],\n",
        "                         mode='markers+text',\n",
        "                         text=[f\"{x:.2f}\" for x in mean_values['program_duration_days']],  # Format text to 2 decimal places\n",
        "                         textposition=\"top center\",\n",
        "                         marker=dict(color='black', size=8, symbol=\"x\"),\n",
        "                         name='Mean'))\n",
        "\n",
        "fig.update_layout(showlegend=True,\n",
        "                  yaxis={'categoryorder':'array', 'categoryarray': category_order},\n",
        "                  xaxis_title='Program Duration Days',\n",
        "                  yaxis_title='Race', title_x=0.5,\n",
        "                  width=1000, height=900)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KaY--hcLR0T"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['gender', 'placed']).size().reset_index(name='count')\n",
        "\n",
        "track_totals = df_grouped.groupby('gender')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_of_total'] = (df_grouped['count'] / len(relevant_df)) * 100\n",
        "\n",
        "df_grouped['percentage_within_experience_class'] = (df_grouped['count'] / track_totals) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_experience_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "total_counts_per_challenge = df_grouped.groupby('gender')['count'].transform('sum')\n",
        "\n",
        "df_grouped['percentage_within_experience_class'] = (df_grouped['count'] / total_counts_per_challenge) * 100\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage_within_experience_class'].apply(lambda x: f\"{x:.1f}%\")\n",
        "\n",
        "# Mapping 'placed' status to descriptive names\n",
        "df_grouped['placed'] = df_grouped['placed'].map({0: 'Not Placed', 1: 'Placed'})\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add traces\n",
        "for name, group in df_grouped.groupby('placed'):\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=group['gender'],\n",
        "        y=group['percentage_of_total'],\n",
        "        name=str(name),  # This now uses the descriptive names 'Not Placed' and 'Placed'\n",
        "        text=group['percentage_text'],\n",
        "        textposition='outside'\n",
        "    ))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distribution of Getting a Job by Gender',\n",
        "    xaxis_title='Gender',\n",
        "    xaxis=dict(\n",
        "        categoryorder='array',\n",
        "        categoryarray=category_order  # Ensure the x-axis categories are ordered as desired\n",
        "    ),\n",
        "    yaxis=dict(title='Percentage of Total', tickformat='.1f'),\n",
        "    legend_title='Being Placed',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    title_x=0.5,\n",
        "    barmode='group',\n",
        "    width=700, height=700\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIUD6W4fL9ZK"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(df['pathrise_status'].isin(['Placed'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "relevant_df.dropna(subset=['gender'], inplace=True)\n",
        "\n",
        "mean_values = relevant_df.groupby('gender')['program_duration_days'].mean().reset_index()\n",
        "\n",
        "\n",
        "fig = px.box(relevant_df, y='gender', x='program_duration_days',\n",
        "             color='gender',\n",
        "             labels={'program_duration_days': 'Program Duration Days', 'gender': 'Gender'},\n",
        "             title='Program Duration Days by Gender for Placed Individuals',\n",
        "             points=\"all\")\n",
        "\n",
        "fig.add_trace(go.Scatter(y=mean_values['gender'], x=mean_values['program_duration_days'],\n",
        "                         mode='markers+text',\n",
        "                         text=[f\"{x:.2f}\" for x in mean_values['program_duration_days']],  # Format text to 2 decimal places\n",
        "                         textposition=\"top center\",\n",
        "                         marker=dict(color='black', size=8, symbol=\"x\"),\n",
        "                         name='Mean'))\n",
        "\n",
        "fig.update_layout(showlegend=True,\n",
        "                  yaxis={'categoryorder':'array', 'categoryarray': category_order},\n",
        "                  xaxis_title='Program Duration Days',\n",
        "                  yaxis_title='Gender', title_x=0.5,\n",
        "                  width=1000, height=600)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOvDWhsEY5Jm"
      },
      "outputs": [],
      "source": [
        "withdrawn_failed_df = df[df['pathrise_status'] == 'Withdrawn (Failed)'].copy()\n",
        "\n",
        "# Create bins for `program_duration_days` and convert intervals to strings for month-long bins\n",
        "max_days = int(withdrawn_failed_df['program_duration_days'].max())\n",
        "bins = range(0, max_days + 5, 5)  # Create month-long bins\n",
        "labels = [f\"{i} - {i + 4}\" for i in range(0, max_days, 5)]  # Generate labels for each bin\n",
        "\n",
        "withdrawn_failed_df['month_bins'] = pd.cut(withdrawn_failed_df['program_duration_days'], bins=bins, labels=labels, right=False)\n",
        "bin_counts = withdrawn_failed_df.groupby('month_bins').size().reset_index(name='counts')\n",
        "\n",
        "# Use px.line to plot\n",
        "fig = px.line(bin_counts, x='month_bins', y='counts',\n",
        "              title='Distribution of Program Duration Days for Withdrawn (Failed) Status',\n",
        "              labels={'month_bins': 'Program Duration Days', 'counts': 'Number of Individuals'},\n",
        "              markers=True)  # Adding markers to make each bin count visible\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(\n",
        "    xaxis_title='Program Duration Days',\n",
        "    yaxis_title='Number of Individuals',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1000, height=600\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3YX3mr1ctKl"
      },
      "outputs": [],
      "source": [
        "withdrawn_failed_df = df[df['pathrise_status'] == 'Placed'].copy()\n",
        "\n",
        "# Create bins for `program_duration_days` and convert intervals to strings for month-long bins\n",
        "max_days = int(withdrawn_failed_df['program_duration_days'].max())\n",
        "bins = range(0, max_days + 5, 5)  # Create month-long bins\n",
        "labels = [f\"{i} - {i + 4}\" for i in range(0, max_days, 5)]  # Generate labels for each bin\n",
        "\n",
        "withdrawn_failed_df['month_bins'] = pd.cut(withdrawn_failed_df['program_duration_days'], bins=bins, labels=labels, right=False)\n",
        "bin_counts = withdrawn_failed_df.groupby('month_bins').size().reset_index(name='counts')\n",
        "\n",
        "# Use px.line to plot\n",
        "fig = px.line(bin_counts, x='month_bins', y='counts',\n",
        "              title='Distribution of Program Duration Days for Placed Status',\n",
        "              labels={'month_bins': 'Program Duration Days', 'counts': 'Number of Individuals'},\n",
        "              markers=True)  # Adding markers to make each bin count visible\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(\n",
        "    xaxis_title='Program Duration Days',\n",
        "    yaxis_title='Number of Individuals',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1000, height=600\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZIlsuAUc9kf"
      },
      "outputs": [],
      "source": [
        "withdrawn_failed_df = df[df['pathrise_status'] == 'Withdrawn'].copy()\n",
        "\n",
        "# Create bins for `program_duration_days` and convert intervals to strings for month-long bins\n",
        "max_days = int(withdrawn_failed_df['program_duration_days'].max())\n",
        "bins = range(0, max_days + 5, 5)  # Create month-long bins\n",
        "labels = [f\"{i} - {i + 4}\" for i in range(0, max_days, 5)]  # Generate labels for each bin\n",
        "\n",
        "withdrawn_failed_df['month_bins'] = pd.cut(withdrawn_failed_df['program_duration_days'], bins=bins, labels=labels, right=False)\n",
        "bin_counts = withdrawn_failed_df.groupby('month_bins').size().reset_index(name='counts')\n",
        "\n",
        "# Use px.line to plot\n",
        "fig = px.line(bin_counts, x='month_bins', y='counts',\n",
        "              title='Distribution of Program Duration Days for Withdrawn Status',\n",
        "              labels={'month_bins': 'Program Duration Days (Binned by Months)', 'counts': 'Number of Individuals'},\n",
        "              markers=True)  # Adding markers to make each bin count visible\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(\n",
        "    xaxis_title='Program Duration Days (Binned by Months)',\n",
        "    yaxis_title='Number of Individuals',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1000, height=600\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpF-or_cdEKX"
      },
      "outputs": [],
      "source": [
        "withdrawn_failed_df = df[df['pathrise_status'] == 'Withdrawn (Trial)'].copy()\n",
        "\n",
        "# Create bins for `program_duration_days` and convert intervals to strings for month-long bins\n",
        "max_days = int(withdrawn_failed_df['program_duration_days'].max())\n",
        "bins = range(0, max_days + 5, 5)  # Create month-long bins\n",
        "labels = [f\"{i} - {i + 4}\" for i in range(0, max_days, 5)]  # Generate labels for each bin\n",
        "\n",
        "withdrawn_failed_df['month_bins'] = pd.cut(withdrawn_failed_df['program_duration_days'], bins=bins, labels=labels, right=False)\n",
        "bin_counts = withdrawn_failed_df.groupby('month_bins').size().reset_index(name='counts')\n",
        "\n",
        "# Use px.line to plot\n",
        "fig = px.line(bin_counts, x='month_bins', y='counts',\n",
        "              title='Distribution of Program Duration Days for Withdrawn Status',\n",
        "              labels={'month_bins': 'Program Duration Days', 'counts': 'Number of Individuals'},\n",
        "              markers=True)  # Adding markers to make each bin count visible\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(\n",
        "    xaxis_title='Program Duration Days',\n",
        "    yaxis_title='Number of Individuals',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1000, height=600\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPeSdoQ-wTfB"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['work_authorization_status', 'employment_status ', 'placed']).size().reset_index(name='count')\n",
        "df_grouped['percentage'] = df_grouped.groupby(['work_authorization_status', 'employment_status '])['count'].transform(lambda x: x / x.sum())\n",
        "\n",
        "# Define a clearer mapping for 'placed' to 'Placement Status'\n",
        "placement_status_map = {1: 'Placed', 0: 'Not Placed'}\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map(placement_status_map)\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage'].round().astype(int).astype(str) + '%'\n",
        "\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map({1: 'Placed', 0: 'Not Placed'})\n",
        "\n",
        "# Create the Plotly Express bar chart using the 'Placement Status' for the color and legend\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage', color='Placement Status',\n",
        "             facet_col='employment_status ',  # Ensure correct column name, removing extra spaces if needed\n",
        "             color_discrete_map={'Placed': '#1f77b4', 'Not Placed': '#d62728'},  # Direct mapping for colors\n",
        "             labels={'percentage': 'Percentage', 'work_authorization_status': 'Work Authorization Status', 'employment_status ': 'Employment Status'},\n",
        "             title='Placement Percentage by Work Authorization and Employment Status',\n",
        "             category_orders={\"Placement Status\": ['Placed', 'Not Placed']})  # Display the rounded percentage without decimal point as the bar label\n",
        "\n",
        "# Customize the layout\n",
        "fig.update_layout(\n",
        "    yaxis_tickformat='%',\n",
        "    xaxis_title=None,\n",
        "    yaxis_title='',  # Removing the y-axis label\n",
        "    legend_title='Placement Status',  # Clear legend title\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=-0.3,  # Adjust the position based on your layout/dimensions\n",
        "        xanchor=\"center\",\n",
        "        x=0.5\n",
        "    ),\n",
        "    paper_bgcolor='white',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',  # Transparent background for the plotting area\n",
        "    font=dict(family='Arial, sans-serif', color='black', size=12),\n",
        "    title_x=0.5\n",
        ")\n",
        "\n",
        "for axis in fig.layout:\n",
        "    if axis.startswith('xaxis'):\n",
        "        fig.layout[axis].title.text = ''\n",
        "\n",
        "for annotation in fig.layout.annotations:\n",
        "    # Replace \"Work Authorization Status =\" with an empty string to remove it\n",
        "    annotation.text = annotation.text.replace(\"Employment Status=\", \"\").strip()\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSqFvt7Z7hdg"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['work_authorization_status', 'highest_level_of_education', 'placed']).size().reset_index(name='count')\n",
        "df_grouped['percentage'] = df_grouped.groupby(['work_authorization_status', 'highest_level_of_education'])['count'].transform(lambda x: x / x.sum())\n",
        "\n",
        "# Define a clearer mapping for 'placed' to 'Placement Status'\n",
        "placement_status_map = {1: 'Placed', 0: 'Not Placed'}\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map(placement_status_map)\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage'].round().astype(int).astype(str) + '%'\n",
        "\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map({1: 'Placed', 0: 'Not Placed'})\n",
        "\n",
        "# Create the Plotly Express bar chart using the 'Placement Status' for the color and legend\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage', color='Placement Status',\n",
        "             facet_col='highest_level_of_education',  # Ensure correct column name, removing extra spaces if needed\n",
        "             color_discrete_map={'Placed': '#1f77b4', 'Not Placed': '#d62728'},  # Direct mapping for colors\n",
        "             labels={'percentage': 'Percentage', 'work_authorization_status': 'Work Authorization Status', 'highest_level_of_education': 'Highest Level of Education'},\n",
        "             title='Placement Percentage by Work Authorization and Highest Level of Education',\n",
        "             category_orders={\"Placement Status\": ['Placed', 'Not Placed']})  # Display the rounded percentage without decimal point as the bar label\n",
        "\n",
        "# Customize the layout\n",
        "fig.update_layout(\n",
        "    yaxis_tickformat='%',\n",
        "    xaxis_title=None,\n",
        "    yaxis_title='',  # Removing the y-axis label\n",
        "    legend_title='Placement Status',  # Clear legend title\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=-0.5,  # Adjust the position based on your layout/dimensions\n",
        "        xanchor=\"center\",\n",
        "        x=0.5\n",
        "    ),\n",
        "    paper_bgcolor='white',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',  # Transparent background for the plotting area\n",
        "    font=dict(family='Arial, sans-serif', color='black', size=12),\n",
        "    title_x=0.5,\n",
        ")\n",
        "\n",
        "for axis in fig.layout:\n",
        "    if axis.startswith('xaxis'):\n",
        "        fig.layout[axis].title.text = ''\n",
        "\n",
        "for annotation in fig.layout.annotations:\n",
        "    # Replace \"Work Authorization Status =\" with an empty string to remove it\n",
        "    annotation.text = annotation.text.replace(\"Highest Level of Education=\", \"\").strip()\n",
        "\n",
        "# Show the updated figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yccdt_YmBfaJ"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['work_authorization_status', 'professional_experience', 'placed']).size().reset_index(name='count')\n",
        "df_grouped['percentage'] = df_grouped.groupby(['work_authorization_status', 'professional_experience'])['count'].transform(lambda x: x / x.sum())\n",
        "\n",
        "# Define a clearer mapping for 'placed' to 'Placement Status'\n",
        "placement_status_map = {1: 'Placed', 0: 'Not Placed'}\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map(placement_status_map)\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage'].round().astype(int).astype(str) + '%'\n",
        "\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map({1: 'Placed', 0: 'Not Placed'})\n",
        "\n",
        "# Create the Plotly Express bar chart using the 'Placement Status' for the color and legend\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage', color='Placement Status',\n",
        "             facet_col='professional_experience',  # Ensure correct column name, removing extra spaces if needed\n",
        "             color_discrete_map={'Placed': '#1f77b4', 'Not Placed': '#d62728'},  # Direct mapping for colors\n",
        "             labels={'percentage': 'Percentage', 'work_authorization_status': 'Work Authorization Status', 'professional_experience': 'Professional Experience'},\n",
        "             title='Placement Percentage by Work Authorization and Professional Experience',\n",
        "             category_orders={\"Placement Status\": ['Placed', 'Not Placed']})  # Display the rounded percentage without decimal point as the bar label\n",
        "\n",
        "# Customize the layout\n",
        "fig.update_layout(\n",
        "    yaxis_tickformat='%',\n",
        "    xaxis_title=None,\n",
        "    yaxis_title='',  # Removing the y-axis label\n",
        "    legend_title='Placement Status',  # Clear legend title\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=-0.5,  # Adjust the position based on your layout/dimensions\n",
        "        xanchor=\"center\",\n",
        "        x=0.5\n",
        "    ),\n",
        "    paper_bgcolor='white',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',  # Transparent background for the plotting area\n",
        "    font=dict(family='Arial, sans-serif', color='black', size=12),\n",
        "    title_x=0.5,\n",
        ")\n",
        "\n",
        "for axis in fig.layout:\n",
        "    if axis.startswith('xaxis'):\n",
        "        fig.layout[axis].title.text = ''\n",
        "\n",
        "for annotation in fig.layout.annotations:\n",
        "    # Replace \"Work Authorization Status =\" with an empty string to remove it\n",
        "    annotation.text = annotation.text.replace(\"Professional Experience=\", \"\").strip()\n",
        "\n",
        "# Show the updated figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6sgPPVb-27f"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['race', 'gender', 'placed']).size().reset_index(name='count')\n",
        "df_grouped['percentage'] = df_grouped.groupby(['race', 'gender'])['count'].transform(lambda x: x / x.sum())\n",
        "\n",
        "# Define a clearer mapping for 'placed' to 'Placement Status'\n",
        "placement_status_map = {1: 'Placed', 0: 'Not Placed'}\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map(placement_status_map)\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage'].round().astype(int).astype(str) + '%'\n",
        "\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map({1: 'Placed', 0: 'Not Placed'})\n",
        "\n",
        "# Create the Plotly Express bar chart using the 'Placement Status' for the color and legend\n",
        "fig = px.bar(df_grouped, x='race', y='percentage', color='Placement Status',\n",
        "             facet_col='gender',  # Ensure correct column name, removing extra spaces if needed\n",
        "             color_discrete_map={'Placed': '#1f77b4', 'Not Placed': '#d62728'},  # Direct mapping for colors\n",
        "             labels={'percentage': 'Percentage', 'race': 'Race', 'gender': 'Gender'},\n",
        "             title='Placement Percentage by Race and Gender',\n",
        "             category_orders={\"Placement Status\": ['Placed', 'Not Placed']})  # Display the rounded percentage without decimal point as the bar label\n",
        "\n",
        "# Customize the layout\n",
        "fig.update_layout(\n",
        "    yaxis_tickformat='%',\n",
        "    xaxis_title=None,\n",
        "    yaxis_title='',  # Removing the y-axis label\n",
        "    legend_title='Placement Status',  # Clear legend title\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=-0.6,  # Adjust the position based on your layout/dimensions\n",
        "        xanchor=\"center\",\n",
        "        x=0.5\n",
        "    ),\n",
        "    paper_bgcolor='white',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',  # Transparent background for the plotting area\n",
        "    font=dict(family='Arial, sans-serif', color='black', size=12),\n",
        "    title_x=0.5,\n",
        ")\n",
        "\n",
        "for axis in fig.layout:\n",
        "    if axis.startswith('xaxis'):\n",
        "        fig.layout[axis].title.text = ''\n",
        "\n",
        "for annotation in fig.layout.annotations:\n",
        "    # Replace \"Work Authorization Status =\" with an empty string to remove it\n",
        "    annotation.text = annotation.text.replace(\"Gender=\", \"\").strip()\n",
        "\n",
        "# Show the updated figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLZKGVHACdb7"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365) & (df['starting_year'] != '20')]\n",
        "\n",
        "df_grouped = relevant_df.groupby(['work_authorization_status', 'starting_year', 'placed']).size().reset_index(name='count')\n",
        "df_grouped['percentage'] = df_grouped.groupby(['work_authorization_status', 'starting_year'])['count'].transform(lambda x: x / x.sum())\n",
        "\n",
        "# Define a clearer mapping for 'placed' to 'Placement Status'\n",
        "placement_status_map = {1: 'Placed', 0: 'Not Placed'}\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map(placement_status_map)\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage'].round().astype(int).astype(str) + '%'\n",
        "\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map({1: 'Placed', 0: 'Not Placed'})\n",
        "\n",
        "# Create the Plotly Express bar chart using the 'Placement Status' for the color and legend\n",
        "fig = px.bar(df_grouped, x='work_authorization_status', y='percentage', color='Placement Status',\n",
        "             facet_col='starting_year',  # Ensure correct column name, removing extra spaces if needed\n",
        "             color_discrete_map={'Placed': '#1f77b4', 'Not Placed': '#d62728'},  # Direct mapping for colors\n",
        "             labels={'percentage': 'Percentage', 'work_authorization_status': 'Work Authorization Status', 'starting_year': 'Starting Year'},\n",
        "             title='Placement Percentage by Work Authorization and Starting Year',\n",
        "             category_orders={\"Placement Status\": ['Placed', 'Not Placed']})  # Display the rounded percentage without decimal point as the bar label\n",
        "\n",
        "# Customize the layout\n",
        "fig.update_layout(\n",
        "    yaxis_tickformat='%',\n",
        "    xaxis_title=None,\n",
        "    yaxis_title='',  # Removing the y-axis label\n",
        "    legend_title='Placement Status',  # Clear legend title\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=-0.5,  # Adjust the position based on your layout/dimensions\n",
        "        xanchor=\"center\",\n",
        "        x=0.5\n",
        "    ),\n",
        "    paper_bgcolor='white',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',  # Transparent background for the plotting area\n",
        "    font=dict(family='Arial, sans-serif', color='black', size=12),\n",
        "    title_x=0.5,\n",
        ")\n",
        "\n",
        "for axis in fig.layout:\n",
        "    if axis.startswith('xaxis'):\n",
        "        fig.layout[axis].title.text = ''\n",
        "\n",
        "for annotation in fig.layout.annotations:\n",
        "    # Replace \"Work Authorization Status =\" with an empty string to remove it\n",
        "    annotation.text = annotation.text.replace(\"Starting Year=\", \"\").strip()\n",
        "\n",
        "# Show the updated figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_kEk5QzBIPM"
      },
      "outputs": [],
      "source": [
        "relevant_df = df[(~df['pathrise_status'].isin(['Active', 'Break', 'Deferred', 'Closed Lost', 'Withdrawn (Trial)'])) &\n",
        "                 (df['program_duration_days'] >= 14) &\n",
        "                 (df['program_duration_days'] <= 365)]\n",
        "\n",
        "month_order = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']\n",
        "\n",
        "\n",
        "df_grouped = relevant_df.groupby(['starting_month', 'work_authorization_status', 'placed']).size().reset_index(name='count')\n",
        "df_grouped['percentage'] = df_grouped.groupby(['starting_month', 'work_authorization_status'])['count'].transform(lambda x: x / x.sum())\n",
        "\n",
        "# Define a clearer mapping for 'placed' to 'Placement Status'\n",
        "placement_status_map = {1: 'Placed', 0: 'Not Placed'}\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map(placement_status_map)\n",
        "\n",
        "df_grouped['percentage_text'] = df_grouped['percentage'].round().astype(int).astype(str) + '%'\n",
        "\n",
        "df_grouped['Placement Status'] = df_grouped['placed'].map({1: 'Placed', 0: 'Not Placed'})\n",
        "\n",
        "fig = px.bar(df_grouped, x='starting_month', y='percentage', color='Placement Status',\n",
        "             facet_col='work_authorization_status',\n",
        "             color_discrete_map={'Placed': '#1f77b4', 'Not Placed': '#d62728'},\n",
        "             labels={'percentage': 'Percentage', 'work_authorization_status': 'Work Authorization Status', 'starting_month': 'Starting Month'},\n",
        "             title='Placement Percentage by Work Authorization and Starting Month',\n",
        "             category_orders={\"Placement Status\": ['Placed', 'Not Placed'], 'starting_month': month_order})  # Apply custom month order\n",
        "\n",
        "# Customize layout\n",
        "fig.update_layout(\n",
        "    yaxis_tickformat='%',\n",
        "    legend_title='Placement Status',\n",
        "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.5, xanchor=\"center\", x=0.5),\n",
        "    paper_bgcolor='white',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',\n",
        "    font=dict(family='Arial, sans-serif', color='black', size=12),\n",
        "    title_x=0.5\n",
        ")\n",
        "\n",
        "for axis in fig.layout:\n",
        "    if axis.startswith('xaxis'):\n",
        "        fig.layout[axis].title.text = ''\n",
        "\n",
        "for annotation in fig.layout.annotations:\n",
        "    # Replace \"Work Authorization Status =\" with an empty string to remove it\n",
        "    annotation.text = annotation.text.replace(\"Work Authorization Status=\", \"\").strip()\n",
        "\n",
        "# Show the updated figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq2aZ9QZeVmT"
      },
      "outputs": [],
      "source": [
        "withdrawn_failed_df = df[df['pathrise_status'] == 'Withdrawn (Trial)'].copy()\n",
        "withdrawn_failed_df['program_duration_days'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3yYs1fneiom"
      },
      "outputs": [],
      "source": [
        "withdrawn_failed_df = df[df['pathrise_status'] == 'Break'].copy()\n",
        "withdrawn_failed_df['program_duration_days'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2ldLSKEesdb"
      },
      "outputs": [],
      "source": [
        "withdrawn_failed_df = df[df['pathrise_status'] == 'Deferred'].copy()\n",
        "withdrawn_failed_df['program_duration_days'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bvh4sM5elyv"
      },
      "outputs": [],
      "source": [
        "withdrawn_failed_df = df[df['pathrise_status'] == 'Closed Lost'].copy()\n",
        "withdrawn_failed_df['program_duration_days'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW4_3a7seosi"
      },
      "outputs": [],
      "source": [
        "withdrawn_failed_df = df[df['pathrise_status'] == 'MIA'].copy()\n",
        "withdrawn_failed_df['program_duration_days'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-1asnOTe0GX"
      },
      "outputs": [],
      "source": [
        "withdrawn_failed_df = df[df['pathrise_status'] == 'Withdrawn (Trial)'].copy()\n",
        "withdrawn_failed_df['program_duration_days'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Kh94zn7seMU"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(df[df['number_of_applications'] <= 250], x='number_of_interviews', y='number_of_applications',\n",
        "                 color='work_authorization_status',\n",
        "                 title='Relationship Between Number of Interviews and Applications by Work Authorization Status',\n",
        "                 labels={'number_of_interviews': 'Number of Interviews', 'number_of_applications': 'Number of Applications'},\n",
        "                 hover_data=['work_authorization_status'])\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Number of Interviews',\n",
        "    yaxis_title='Number of Applications',\n",
        "    legend_title='Work Authorization Status',\n",
        "    paper_bgcolor='white',\n",
        "    font=dict(family='Raleway, sans-serif', color='black'),\n",
        "    width=1000, height=1000,\n",
        "    title_x=0.5\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_A3pyxwIiAN"
      },
      "source": [
        "# Remove rows where 'program_duration_days' is below 14 or over 365"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8037aQ-LCaT9"
      },
      "outputs": [],
      "source": [
        "df_column_filtered = df.drop(['id', 'application_bins', 'interviews_bins', 'placed'], axis='columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgeeuHsaDPn5"
      },
      "outputs": [],
      "source": [
        "for column in df_column_filtered.columns:\n",
        "    unique_values = df_column_filtered[column].unique()\n",
        "    print(f\"Unique values in '{column}': {unique_values}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tpZtmpcLWT_"
      },
      "outputs": [],
      "source": [
        "df_status_column_filtered = df_column_filtered[df_column_filtered['pathrise_status'].isin(['Placed', 'MIA', 'Withdrawn', 'Withdrawn (Failed)'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgdlKHjBNVyC"
      },
      "outputs": [],
      "source": [
        "df_status_column_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh3dG3Fgu19V"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9b_4lAVPr2M"
      },
      "source": [
        "Removing the irrelevant classes in 'pathrise_status' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zer4F_-bOK5y"
      },
      "outputs": [],
      "source": [
        "status_filtered_df = original_df[original_df['pathrise_status'].isin([\"Withdrawn\", \"MIA\", \"Withdrawn (Failed)\", \"Placed\"])]\n",
        "print(len(original_df) - len(status_filtered_df), \"rows were removed out of\", len(original_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNVVu25aRg_O"
      },
      "source": [
        "Filtering out those with the value for 'program_duration_days' less than 14 or over"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgWFLeL5RYxT"
      },
      "outputs": [],
      "source": [
        "len_before_remove = len(status_filtered_df)\n",
        "status_filtered_df = status_filtered_df[(status_filtered_df['program_duration_days'] > 14) & (status_filtered_df['program_duration_days'] <= 365)]\n",
        "print(len_before_remove - len(status_filtered_df), \"rows were affected out of\", len_before_remove)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7VKLw74xyj6"
      },
      "source": [
        "Having a dataframe without any missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhuBYJctxx56"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_no_missing = status_filtered_df.dropna(thresh=status_filtered_df.shape[1])\n",
        "print(len(status_filtered_df) - len(status_filtered_df_no_missing), \"rows were affected out of\", len(status_filtered_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7MxRnMm03nq"
      },
      "source": [
        "Remove the rows with more than 3 missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "652XiEl_01i_"
      },
      "outputs": [],
      "source": [
        "len_before_remove = len(status_filtered_df)\n",
        "status_filtered_df = status_filtered_df.dropna(thresh=status_filtered_df.shape[1] - 3)\n",
        "print(len_before_remove - len(status_filtered_df), \"rows removed out of\", len_before_remove)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwDkiI71tXv1"
      },
      "source": [
        "Copy the dataframe do later only remove the columns with missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpSWbI7os1W-"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = status_filtered_df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tZCqTQVr8mY"
      },
      "source": [
        "Use filling based on the distribution for 'number_of_interviews'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM0sPwqCo3xY"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['number_of_interviews'].isnull().sum()\n",
        "\n",
        "# Step 1: Calculate the distribution of non-null values\n",
        "interviews_distribution = status_filtered_df_missing_filled['number_of_interviews'].value_counts(normalize=True)\n",
        "\n",
        "# Step 2: Fill missing values based on the distribution\n",
        "missing_values_count = status_filtered_df_missing_filled['number_of_interviews'].isnull().sum()\n",
        "filled_values = np.random.choice(interviews_distribution.index, size=missing_values_count, p=interviews_distribution.values)\n",
        "status_filtered_df_missing_filled.loc[status_filtered_df_missing_filled['number_of_interviews'].isnull(), 'number_of_interviews'] = filled_values\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpDj-x72ACcz"
      },
      "outputs": [],
      "source": [
        "print(\"min:\", status_filtered_df_no_missing['number_of_interviews'].min())\n",
        "print(\"max:\", status_filtered_df_no_missing['number_of_interviews'].max())\n",
        "print(\"mean:\", status_filtered_df_no_missing['number_of_interviews'].mean())\n",
        "print(\"mode:\", status_filtered_df_no_missing['number_of_interviews'].mode()[0])\n",
        "print(\"median:\", status_filtered_df_no_missing['number_of_interviews'].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ifEqyTZCKJo"
      },
      "outputs": [],
      "source": [
        "plt.hist(status_filtered_df_no_missing['number_of_interviews'], bins=20, edgecolor='black')  # Adjust the number of bins as needed\n",
        "plt.xlabel('Number of Interviews')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Number of Interviews')\n",
        "plt.xticks(range(21))  # Set x-axis ticks from 0 to 20 with increments of one\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmIum9FgIaH2"
      },
      "outputs": [],
      "source": [
        "def categorize_and_plot_interviews(df):\n",
        "    categories = {\n",
        "        '0': (0.0, 0.0),\n",
        "        '1': (1.0, 2.0),\n",
        "        '2': (3.0, 7.0),\n",
        "        '3': (8.0, 21.0)\n",
        "    }\n",
        "\n",
        "    # Categorize the number_of_interviews column\n",
        "    def categorize_interviews(interviews):\n",
        "        for category, (lower, upper) in categories.items():\n",
        "            if lower <= interviews <= upper:\n",
        "                return category\n",
        "        return 'Others'  # If the value does not fall into any defined category\n",
        "\n",
        "    # Apply the categorization function to create a new column\n",
        "    df['interviews_category'] = df['number_of_interviews'].apply(categorize_interviews)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pBGtY0TImVI"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = categorize_and_plot_interviews(status_filtered_df_missing_filled)\n",
        "status_filtered_df_no_missing = categorize_and_plot_interviews(status_filtered_df_no_missing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoBmuKYHtMAz"
      },
      "source": [
        "Use filling based on the distribution for 'number_of_applications'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDerKu11tJp7"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['number_of_applications'].isnull().sum()\n",
        "\n",
        "# Step 1: Calculate the distribution of non-null values\n",
        "interviews_distribution = status_filtered_df_missing_filled['number_of_applications'].value_counts(normalize=True)\n",
        "\n",
        "# Step 2: Fill missing values based on the distribution\n",
        "missing_values_count = status_filtered_df_missing_filled['number_of_applications'].isnull().sum()\n",
        "filled_values = np.random.choice(interviews_distribution.index, size=missing_values_count, p=interviews_distribution.values)\n",
        "status_filtered_df_missing_filled.loc[status_filtered_df_missing_filled['number_of_applications'].isnull(), 'number_of_applications'] = filled_values\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDonHyO8Mbds"
      },
      "outputs": [],
      "source": [
        "print(\"min:\", status_filtered_df_no_missing['number_of_applications'].min())\n",
        "print(\"max:\", status_filtered_df_no_missing['number_of_applications'].max())\n",
        "print(\"mean:\", status_filtered_df_no_missing['number_of_applications'].mean())\n",
        "print(\"mode:\", status_filtered_df_no_missing['number_of_applications'].mode()[0])\n",
        "print(\"median:\", status_filtered_df_no_missing['number_of_applications'].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wX2pFRxMfq8"
      },
      "outputs": [],
      "source": [
        "plt.hist(status_filtered_df_no_missing['number_of_applications'], bins=40, edgecolor='black')  # Adjust the number of bins as needed\n",
        "plt.xlabel('Number of Applications')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Number of Applications')\n",
        "# plt.xticks(range(41))  # Set x-axis ticks from 0 to 20 with increments of one\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS2WOEk-QJte"
      },
      "outputs": [],
      "source": [
        "def categorize_the_applications(df):\n",
        "    categories = {\n",
        "        '0': (0.0, 20.0),\n",
        "        '1': (21.0, 50.0),\n",
        "        '2': (51.0, 80.0),\n",
        "        '3': (81.0, 110.0),\n",
        "        '4': (111.0, 900.0),\n",
        "    }\n",
        "\n",
        "    # Categorize the number_of_interviews column\n",
        "    def categorize_applications(applications):\n",
        "        for category, (lower, upper) in categories.items():\n",
        "            if lower <= applications <= upper:\n",
        "                return category\n",
        "        return 'Others'  # If the value does not fall into any defined category\n",
        "\n",
        "    # Apply the categorization function to create a new column\n",
        "    df['applications_category'] = df['number_of_applications'].apply(categorize_applications)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9aU8ToRtAR_"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = categorize_the_applications(status_filtered_df_missing_filled)\n",
        "status_filtered_df_no_missing = categorize_the_applications(status_filtered_df_no_missing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DtfB-n-Ude3"
      },
      "source": [
        "Removing the 'id' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJvp9f5NSt6T"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = status_filtered_df_missing_filled.drop(['number_of_interviews', 'number_of_applications', 'id'], axis=1)\n",
        "status_filtered_df_no_missing = status_filtered_df_no_missing.drop(['number_of_interviews', 'number_of_applications', 'id'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxKekv9WkC3"
      },
      "source": [
        "Using mode for the 'race' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1YekVJaVfDW"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['race'].isnull().sum()\n",
        "\n",
        "status_filtered_df_missing_filled['race'] = status_filtered_df_missing_filled['race'].fillna(status_filtered_df_missing_filled['race'].mode()[0])\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4t4H6p8cW590"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrj2o9EYHe6"
      },
      "source": [
        "Since there is no order for the 'race' column we convert into dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn1KS8EKXbRj"
      },
      "outputs": [],
      "source": [
        "def create_race_dummies(df):\n",
        "    # Create dummy variables for the 'race' column\n",
        "    race_dummies = pd.get_dummies(df['race'], prefix='race')\n",
        "\n",
        "    # Concatenate the dummy variables with the original DataFrame\n",
        "    df = pd.concat([df, race_dummies], axis=1)\n",
        "\n",
        "    # Drop the original 'race' column\n",
        "    df.drop('race', axis=1, inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjyMiBXHX6sg"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = create_race_dummies(status_filtered_df_missing_filled)\n",
        "status_filtered_df_no_missing = create_race_dummies(status_filtered_df_no_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVrLP7OZX_1M"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koq7yFSkYc40"
      },
      "source": [
        "Removing the 'pathrise_status' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDmRXSxHYA8g"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = status_filtered_df_missing_filled.drop(['pathrise_status'], axis=1)\n",
        "status_filtered_df_no_missing = status_filtered_df_no_missing.drop(['pathrise_status'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aV1GTlBZ4lL"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpzyG0imaZ3G"
      },
      "source": [
        "Use mode for filling the missing in the 'biggest_challenge_in_search' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYQMzPSsZ8Ak"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['biggest_challenge_in_search'].isnull().sum()\n",
        "\n",
        "status_filtered_df_missing_filled['biggest_challenge_in_search'] = status_filtered_df_missing_filled['biggest_challenge_in_search'].fillna(status_filtered_df_missing_filled['biggest_challenge_in_search'].mode()[0])\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_cMAxCoapiX"
      },
      "outputs": [],
      "source": [
        "def create_biggest_challenge_in_search_dummies(df):\n",
        "    # Create dummy variables for the 'race' column\n",
        "    biggest_challenge_in_search_dummies = pd.get_dummies(df['biggest_challenge_in_search'], prefix='biggest_challenge_in_search')\n",
        "\n",
        "    # Concatenate the dummy variables with the original DataFrame\n",
        "    df = pd.concat([df, biggest_challenge_in_search_dummies], axis=1)\n",
        "\n",
        "    # Drop the original 'race' column\n",
        "    df.drop('biggest_challenge_in_search', axis=1, inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFh1UV_pawIc"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = create_biggest_challenge_in_search_dummies(status_filtered_df_missing_filled)\n",
        "status_filtered_df_no_missing = create_biggest_challenge_in_search_dummies(status_filtered_df_no_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdvFZ3tVbAPT"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['highest_level_of_education'].isnull().sum()\n",
        "\n",
        "status_filtered_df_missing_filled['highest_level_of_education'] = status_filtered_df_missing_filled['highest_level_of_education'].fillna(status_filtered_df_missing_filled['highest_level_of_education'].mode()[0])\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qaKtTkadeQA"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['cohort_tag'].isnull().sum()\n",
        "\n",
        "status_filtered_df_missing_filled['cohort_tag'] = status_filtered_df_missing_filled['cohort_tag'].fillna(status_filtered_df_missing_filled['cohort_tag'].mode()[0])\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv6jy4b6eMnD"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['gender'].isnull().sum()\n",
        "\n",
        "# Step 1: Calculate the distribution of non-null values\n",
        "interviews_distribution = status_filtered_df_missing_filled['gender'].value_counts(normalize=True)\n",
        "\n",
        "# Step 2: Fill missing values based on the distribution\n",
        "missing_values_count = status_filtered_df_missing_filled['gender'].isnull().sum()\n",
        "filled_values = np.random.choice(interviews_distribution.index, size=missing_values_count, p=interviews_distribution.values)\n",
        "status_filtered_df_missing_filled.loc[status_filtered_df_missing_filled['gender'].isnull(), 'gender'] = filled_values\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_zd4-rGeRK8"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5CIc_lee3Tu"
      },
      "outputs": [],
      "source": [
        "def create_gender_dummies(df):\n",
        "    # Create dummy variables for the 'gender' column\n",
        "    gender_dummies = pd.get_dummies(df['gender'], prefix='gender')\n",
        "\n",
        "    # Concatenate the dummy variables with the original DataFrame\n",
        "    df = pd.concat([df, gender_dummies], axis=1)\n",
        "\n",
        "    # Drop the original 'gender' column\n",
        "    df.drop('gender', axis=1, inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvNJx0RSfAXP"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = create_gender_dummies(status_filtered_df_missing_filled)\n",
        "status_filtered_df_no_missing = create_gender_dummies(status_filtered_df_no_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YhXcwk_fHbV"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpiPSYRL8sbQ"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled_test = original_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwamvqwy6MGg"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled_test['cohort_tag'] = status_filtered_df_missing_filled_test['cohort_tag'].str[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpUlQetC_N0v"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled_test['cohort_tag'].isnull().sum()\n",
        "\n",
        "status_filtered_df_missing_filled_test['cohort_tag'] = status_filtered_df_missing_filled_test['cohort_tag'].fillna(status_filtered_df_missing_filled_test['cohort_tag'].mode()[0])\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Tk5_d9L63et"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled_test['cohort_date'] = pd.to_datetime(status_filtered_df_missing_filled_test['cohort_tag'], format='%b%y')\n",
        "\n",
        "# Group by the new 'cohort_date', counting the number of rows in each group\n",
        "grouped_df = status_filtered_df_missing_filled_test.groupby('cohort_date').size().reset_index(name='count')\n",
        "\n",
        "# Convert 'cohort_date' back to 'MMMYY' format for display, removing '-01'\n",
        "grouped_df['cohort_tag'] = grouped_df['cohort_date'].dt.strftime('%b%y').str.upper()\n",
        "\n",
        "# Sort the DataFrame by 'cohort_date'\n",
        "grouped_df_sorted = grouped_df.sort_values('cohort_date')\n",
        "\n",
        "# Plot using Plotly, using the formatted 'cohort_tag' for the x-axis and 'count' for the y-axis\n",
        "fig = px.bar(grouped_df_sorted, x='cohort_tag', y='count', labels={'cohort_tag': 'Cohort Tag', 'count': 'Count'})\n",
        "fig.update_layout(title='Count by Cohort Tag', xaxis_title='Cohort Tag', yaxis_title='Count', title_x=0.5)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI02vzLh6dX-"
      },
      "outputs": [],
      "source": [
        "covid_start = pd.to_datetime('2020-03-01')\n",
        "covid_end = pd.to_datetime('2021-09-30')\n",
        "\n",
        "# Use a boolean condition to check if 'cohort_date' falls within the COVID period\n",
        "status_filtered_df_missing_filled_test['is_covid'] = ((status_filtered_df_missing_filled_test['cohort_date'] >= covid_start) & (status_filtered_df_missing_filled_test['cohort_date'] <= covid_end)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSDpCcUxO4RX"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled_test[\"starting_month\"] = status_filtered_df_missing_filled_test['cohort_tag'].str.slice(0, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gogb5iLMO6J_"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled_test[\"starting_month\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1JXpB0yfJD8"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled_test[\"starting_month\"] = status_filtered_df_missing_filled_test['cohort_tag'].str.slice(0, 3)\n",
        "# df[\"starting_year\"] = df['cohort_tag'].apply(lambda x: '20' + str(x)[3:5])\n",
        "df[\"cohort_tag_new\"] = df['cohort_tag'].apply(lambda x: '20' + str(x)[3:5])\n",
        "df.drop(columns=['cohort_tag'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCq6p3POPHnJ"
      },
      "source": [
        "Fill the missing values for 'cohort_tag' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gq9b2SeDkEF"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['cohort_tag'].isnull().sum()\n",
        "status_filtered_df_missing_filled['cohort_tag'] = status_filtered_df_missing_filled['cohort_tag'].fillna(status_filtered_df_missing_filled['cohort_tag'].mode()[0])\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNFtfQB8SRro"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled['cohort_tag'] = status_filtered_df_missing_filled['cohort_tag'].str[:-1]\n",
        "status_filtered_df_no_missing['cohort_tag'] = status_filtered_df_no_missing['cohort_tag'].str[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzJtnXGoWJwQ"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled[\"starting_month\"] = status_filtered_df_missing_filled['cohort_tag'].str.slice(0, 3)\n",
        "status_filtered_df_no_missing[\"starting_month\"] = status_filtered_df_no_missing['cohort_tag'].str.slice(0, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErXfleOZWzI2"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled['cohort_date'] = pd.to_datetime(status_filtered_df_missing_filled['cohort_tag'], format='%b%y')\n",
        "status_filtered_df_no_missing['cohort_date'] = pd.to_datetime(status_filtered_df_no_missing['cohort_tag'], format='%b%y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkqHT0D5W7Dt"
      },
      "outputs": [],
      "source": [
        "covid_start = pd.to_datetime('2020-03-01')\n",
        "covid_end = pd.to_datetime('2021-09-30')\n",
        "\n",
        "# Use a boolean condition to check if 'cohort_date' falls within the COVID period\n",
        "status_filtered_df_missing_filled['is_covid'] = ((status_filtered_df_missing_filled['cohort_date'] >= covid_start) & (status_filtered_df_missing_filled['cohort_date'] <= covid_end)).astype(int)\n",
        "status_filtered_df_no_missing['is_covid'] = ((status_filtered_df_no_missing['cohort_date'] >= covid_start) & (status_filtered_df_no_missing['cohort_date'] <= covid_end)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slzwz7xRXH_6"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.drop(columns=['cohort_tag', 'cohort_date'], inplace=True)\n",
        "status_filtered_df_no_missing.drop(columns=['cohort_tag', 'cohort_date'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_TxwUrnXMAX"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpFmk-JoYY6F"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['length_of_job_search'].isnull().sum()\n",
        "\n",
        "# Step 1: Calculate the distribution of non-null values\n",
        "interviews_distribution = status_filtered_df_missing_filled['length_of_job_search'].value_counts(normalize=True)\n",
        "\n",
        "# Step 2: Fill missing values based on the distribution\n",
        "missing_values_count = status_filtered_df_missing_filled['length_of_job_search'].isnull().sum()\n",
        "filled_values = np.random.choice(interviews_distribution.index, size=missing_values_count, p=interviews_distribution.values)\n",
        "status_filtered_df_missing_filled.loc[status_filtered_df_missing_filled['length_of_job_search'].isnull(), 'length_of_job_search'] = filled_values\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t16zirckdKqc"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['professional_experience'].isnull().sum()\n",
        "\n",
        "# Step 1: Calculate the distribution of non-null values\n",
        "interviews_distribution = status_filtered_df_missing_filled['professional_experience'].value_counts(normalize=True)\n",
        "\n",
        "# Step 2: Fill missing values based on the distribution\n",
        "missing_values_count = status_filtered_df_missing_filled['professional_experience'].isnull().sum()\n",
        "filled_values = np.random.choice(interviews_distribution.index, size=missing_values_count, p=interviews_distribution.values)\n",
        "status_filtered_df_missing_filled.loc[status_filtered_df_missing_filled['professional_experience'].isnull(), 'professional_experience'] = filled_values\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFbbS47DgClm"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHCJSyBhdjPz"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGZfPM9RhaQu"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['employment_status '].isnull().sum()\n",
        "\n",
        "# Step 1: Calculate the distribution of non-null values\n",
        "interviews_distribution = status_filtered_df_missing_filled['employment_status '].value_counts(normalize=True)\n",
        "\n",
        "# Step 2: Fill missing values based on the distribution\n",
        "missing_values_count = status_filtered_df_missing_filled['employment_status '].isnull().sum()\n",
        "filled_values = np.random.choice(interviews_distribution.index, size=missing_values_count, p=interviews_distribution.values)\n",
        "status_filtered_df_missing_filled.loc[status_filtered_df_missing_filled['employment_status '].isnull(), 'employment_status '] = filled_values\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amNhSkUmnUF9"
      },
      "outputs": [],
      "source": [
        "num_rows = status_filtered_df_missing_filled['work_authorization_status'].isnull().sum()\n",
        "\n",
        "# Step 1: Calculate the distribution of non-null values\n",
        "interviews_distribution = status_filtered_df_missing_filled['work_authorization_status'].value_counts(normalize=True)\n",
        "\n",
        "# Step 2: Fill missing values based on the distribution\n",
        "missing_values_count = status_filtered_df_missing_filled['work_authorization_status'].isnull().sum()\n",
        "filled_values = np.random.choice(interviews_distribution.index, size=missing_values_count, p=interviews_distribution.values)\n",
        "status_filtered_df_missing_filled.loc[status_filtered_df_missing_filled['work_authorization_status'].isnull(), 'work_authorization_status'] = filled_values\n",
        "\n",
        "print(num_rows, \"rows affected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW38lcQznd_5"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwxSbfOVnlqa"
      },
      "outputs": [],
      "source": [
        "def create_employment_status_dummies(df):\n",
        "    # Create dummy variables for the 'professional_experience' column\n",
        "    employment_status_dummies = pd.get_dummies(df['employment_status '], prefix='employment_status ')\n",
        "\n",
        "    # Concatenate the dummy variables with the original DataFrame\n",
        "    df = pd.concat([df, employment_status_dummies], axis=1)\n",
        "\n",
        "    # Drop the original 'employment_status' column\n",
        "    df.drop('employment_status ', axis=1, inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0Rh3tN9ntpf"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = create_employment_status_dummies(status_filtered_df_missing_filled)\n",
        "status_filtered_df_no_missing = create_employment_status_dummies(status_filtered_df_no_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XsiDGMZn34W"
      },
      "outputs": [],
      "source": [
        "def create_work_authorization_status_dummies(df):\n",
        "    # Create dummy variables for the 'professional_experience' column\n",
        "    work_authorization_status_dummies = pd.get_dummies(df['work_authorization_status'], prefix='work_authorization_status')\n",
        "\n",
        "    # Concatenate the dummy variables with the original DataFrame\n",
        "    df = pd.concat([df, work_authorization_status_dummies], axis=1)\n",
        "\n",
        "    # Drop the original 'work_authorization_status' column\n",
        "    df.drop('work_authorization_status', axis=1, inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU24C9OKoDlP"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = create_work_authorization_status_dummies(status_filtered_df_missing_filled)\n",
        "status_filtered_df_no_missing = create_work_authorization_status_dummies(status_filtered_df_no_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3-7kFHToIw3"
      },
      "outputs": [],
      "source": [
        "def create_primary_track_dummies(df):\n",
        "    # Create dummy variables for the 'professional_experience' column\n",
        "    primary_track_dummies = pd.get_dummies(df['primary_track'], prefix='primary_track')\n",
        "\n",
        "    # Concatenate the dummy variables with the original DataFrame\n",
        "    df = pd.concat([df, primary_track_dummies], axis=1)\n",
        "\n",
        "    # Drop the original 'primary_track' column\n",
        "    df.drop('primary_track', axis=1, inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhcGxoxqoKv1"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = create_primary_track_dummies(status_filtered_df_missing_filled)\n",
        "status_filtered_df_no_missing = create_primary_track_dummies(status_filtered_df_no_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJm1wfcEobi0"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndIGUYWeohI6"
      },
      "outputs": [],
      "source": [
        "# Assuming 'df' is your DataFrame\n",
        "df = status_filtered_df_missing_filled.copy()\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# List of columns to encode\n",
        "columns_to_encode = ['highest_level_of_education', 'length_of_job_search',\n",
        "                     'professional_experience', 'interviews_category',\n",
        "                     'starting_month', 'applications_category']\n",
        "\n",
        "# Apply LabelEncoder to each column\n",
        "for column in columns_to_encode:\n",
        "    # Fit label encoder and return encoded labels\n",
        "    df[column] = le.fit_transform(df[column])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE-VT0aEqZ3M"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled[['highest_level_of_education', 'length_of_job_search',\n",
        "                     'professional_experience', 'interviews_category',\n",
        "                     'starting_month', 'applications_category']] = df[['highest_level_of_education', 'length_of_job_search',\n",
        "                     'professional_experience', 'interviews_category',\n",
        "                     'starting_month', 'applications_category']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_DLt_9Lqzns"
      },
      "outputs": [],
      "source": [
        "# Assuming 'df' is your DataFrame\n",
        "df = status_filtered_df_no_missing.copy()\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# List of columns to encode\n",
        "columns_to_encode = ['highest_level_of_education', 'length_of_job_search',\n",
        "                     'professional_experience', 'interviews_category',\n",
        "                     'starting_month', 'applications_category']\n",
        "\n",
        "# Apply LabelEncoder to each column\n",
        "for column in columns_to_encode:\n",
        "    # Fit label encoder and return encoded labels\n",
        "    df[column] = le.fit_transform(df[column])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZEioW7wq4yx"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_no_missing[['highest_level_of_education', 'length_of_job_search',\n",
        "                     'professional_experience', 'interviews_category',\n",
        "                     'starting_month', 'applications_category']] = df[['highest_level_of_education', 'length_of_job_search',\n",
        "                     'professional_experience', 'interviews_category',\n",
        "                     'starting_month', 'applications_category']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfQIs4We-KRz"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled.to_csv('/content/drive/MyDrive/Dataroadmap/status_filtered_df_missing_filled.csv', index=False)\n",
        "status_filtered_df_no_missing.to_csv('/content/drive/MyDrive/Dataroadmap/status_filtered_df_no_missing.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrjYLj4n-MHf"
      },
      "outputs": [],
      "source": [
        "status_filtered_df_missing_filled = pd.read_csv('/content/drive/MyDrive/Dataroadmap/status_filtered_df_missing_filled.csv')\n",
        "status_filtered_df_no_missing = pd.read_csv('/content/drive/MyDrive/Dataroadmap/status_filtered_df_no_missing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvsMP7Musqm_"
      },
      "outputs": [],
      "source": [
        "# Assuming df is your preprocessed DataFrame\n",
        "df = status_filtered_df_missing_filled.copy()\n",
        "\n",
        "# Typically, you might want to encode categorical variables here if not already done\n",
        "# Encoding can be done using LabelEncoder or pd.get_dummies as previously discussed\n",
        "\n",
        "# Define your features and targets\n",
        "X_missing_filled = df.drop(['program_duration_days', 'placed'], axis=1)  # all columns except the targets\n",
        "y_missing_filled_regression = df['program_duration_days']  # target for regression\n",
        "y_missing_filled_classification = df['placed']  # target for classification\n",
        "\n",
        "# Split the data for regression\n",
        "X_missing_filled_train_reg, X_missing_filled_test_reg, y_missing_filled_train_reg, y_missing_filled_test_reg = train_test_split(\n",
        "    X_missing_filled, y_missing_filled_regression, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Split the data for classification\n",
        "X_missing_filled_train_class, X_missing_filled_test_class, y_missing_filled_train_class, y_missing_filled_test_class = train_test_split(\n",
        "    X_missing_filled, y_missing_filled_classification, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20XBwondq7tc"
      },
      "outputs": [],
      "source": [
        "# Assuming df is your preprocessed DataFrame\n",
        "df = status_filtered_df_missing_filled.copy()\n",
        "\n",
        "# Define your features and targets\n",
        "X = df.drop(['program_duration_days', 'placed'], axis=1)  # all columns except the targets\n",
        "y_regression = df['program_duration_days']  # target for regression\n",
        "y_classification = df['placed']  # target for classification\n",
        "\n",
        "# Split the data for regression, using stratified split based on quartiles or another method if needed\n",
        "# First, you might need to categorize 'program_duration_days' if it is not categorical\n",
        "y_regression_categorical = pd.qcut(y_regression, 4, labels=False)  # dividing into quartiles\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X, y_regression, test_size=0.2, stratify=y_regression_categorical, random_state=42\n",
        ")\n",
        "\n",
        "# Split the data for classification, using stratified split to evenly distribute classes\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
        "    X, y_classification, test_size=0.2, stratify=y_classification, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkNmCPu5LknE"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = X_missing_filled_train_class, X_missing_filled_test_class, y_missing_filled_train_class, y_missing_filled_test_class\n",
        "X_train.columns = [re.sub(r'[^\\w]', '_', col) for col in X_train.columns]\n",
        "X_test.columns = [re.sub(r'[^\\w]', '_', col) for col in X_test.columns]\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
        "    \"Logistic Regression (D=3)\": make_pipeline(PolynomialFeatures(degree=3), LogisticRegression(max_iter=2000)),\n",
        "    \"SVM (Linear)\": SVC(kernel='linear'),\n",
        "    \"SVM (Polynomial)\": SVC(kernel='poly', degree=3),  # degree can be adjusted\n",
        "    \"SVM (RBF)\": SVC(kernel='rbf'),\n",
        "    \"SVM (Sigmoid)\": SVC(kernel='sigmoid'),\n",
        "    \"Decision Tree (Gini)\": DecisionTreeClassifier(criterion='gini'),\n",
        "    \"Decision Tree (Entropy)\": DecisionTreeClassifier(criterion='entropy'),\n",
        "    \"Random Forest (Gini)\": RandomForestClassifier(criterion='gini'),\n",
        "    \"Random Forest (Entropy)\": RandomForestClassifier(criterion='entropy'),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"LightGBM\": lgb.LGBMClassifier(),\n",
        "    # \"Neural Network\": MLPClassifier(max_iter=1000)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model, storing results for both train and test sets\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # For ROC AUC, we need probability scores of the positive class\n",
        "    if 'SVM' in name:  # SVM does not support predict_proba by default\n",
        "        y_test_proba = model.decision_function(X_test)\n",
        "    else:\n",
        "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    results[name] = {\n",
        "        \"Train Accuracy\": np.round(accuracy_score(y_train, y_train_pred), 2),\n",
        "        \"Test Accuracy\": np.round(accuracy_score(y_test, y_test_pred), 2),\n",
        "        \"Test Precision\": np.round(precision_score(y_test, y_test_pred,), 2),\n",
        "        \"Test Recall\": np.round(recall_score(y_test, y_test_pred), 2),\n",
        "        \"Test F1\": np.round(f1_score(y_test, y_test_pred), 2),\n",
        "        \"Test Macro F1\": np.round(f1_score(y_test, y_test_pred, average='macro'), 2),\n",
        "        \"Test ROC AUC\": np.round(roc_auc_score(y_test, y_test_proba), 2)\n",
        "    }\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results).T\n",
        "\n",
        "# Creating the Plotly Table\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(values=['Model', 'Train Accuracy', 'Test Accuracy', 'Test Precision',\n",
        "                        'Test Recall', 'Test F1', \"Test Macro F1\", \"Test ROC AUC\"],\n",
        "                fill_color='#4A5ED7',  # A nicer, more bluish purple color for the header\n",
        "                font=dict(color='white', size=12),\n",
        "                align=['left', 'center']),\n",
        "    cells=dict(values=[results_df.index, results_df['Train Accuracy'], results_df['Test Accuracy'],\n",
        "                       results_df['Test Precision'], results_df['Test Recall'],\n",
        "                       results_df['Test F1'], results_df['Test Macro F1'], results_df[\"Test ROC AUC\"]],\n",
        "               fill=dict(color=[['#222222', '#222222'], ['#404040', '#404040'], ['#404040', '#404040'],\n",
        "                                ['#404040', '#404040'], ['#404040', '#404040'], ['#404040', '#404040'],\n",
        "                                ['#404040', '#404040'], ['#404040', '#404040']]),  # First column darker\n",
        "               font=dict(color='white', size=11),\n",
        "               align=['left', 'center'],  # Align model names to the left and metrics to the center\n",
        "               height=30))\n",
        "])\n",
        "\n",
        "# Adjust column widths and title settings\n",
        "fig.update_layout(\n",
        "    title='Classification Model\\'s Performance on Training and Testing Sets',\n",
        "    title_x=0.5,\n",
        "    width=1200,  # Adjusted for better fit\n",
        "    height=900,\n",
        "    paper_bgcolor='#333333',  # Setting the background of the chart to dark gray\n",
        "    plot_bgcolor='#333333',  # Setting the plotting area background to the same dark gray\n",
        "    font=dict(color='white')  # Ensuring all text is white for contrast\n",
        ")\n",
        "\n",
        "fig.update_traces(columnwidth=[1, 1, 1, 1, 1, 1, 1, 1])  # Equal width for all columns\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtrLJQHlyiY1"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "X_missing_filled.columns = [re.sub(r'[^\\w]', '_', col) for col in X_missing_filled.columns]\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
        "    \"Logistic Regression (D=3)\": make_pipeline(PolynomialFeatures(degree=3), LogisticRegression(max_iter=2000)),\n",
        "    \"SVM (Linear)\": SVC(kernel='linear'),\n",
        "    \"SVM (Polynomial)\": SVC(kernel='poly', degree=3),  # degree can be adjusted\n",
        "    \"SVM (RBF)\": SVC(kernel='rbf'),\n",
        "    \"SVM (Sigmoid)\": SVC(kernel='sigmoid'),\n",
        "    \"Decision Tree (Gini)\": DecisionTreeClassifier(criterion='gini'),\n",
        "    \"Decision Tree (Entropy)\": DecisionTreeClassifier(criterion='entropy'),\n",
        "    \"Random Forest (Gini)\": RandomForestClassifier(criterion='gini'),\n",
        "    \"Random Forest (Entropy)\": RandomForestClassifier(criterion='entropy'),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"LightGBM\": lgb.LGBMClassifier(verbose=-1),\n",
        "    # \"Neural Network\": MLPClassifier(max_iter=1000)\n",
        "}\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'f1': 'f1',\n",
        "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
        "    'roc_auc': 'roc_auc'\n",
        "}\n",
        "\n",
        "# Perform cross-validation and store results, including both train and test set metrics\n",
        "results = {}\n",
        "\n",
        "\n",
        "for name, model in models.items():\n",
        "    cv_results = cross_validate(model, X_missing_filled, y_missing_filled_classification, cv=10, scoring=scoring, return_train_score=True)\n",
        "    y_pred = cross_val_predict(model, X_missing_filled, y_missing_filled_classification, cv=10)\n",
        "    # train_accuracy = accuracy_score(y_missing_filled_classification, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        # \"Train Accuracy\": np.round(train_accuracy, 2),\n",
        "        \"Accuracy\": np.round(np.mean(cv_results['test_accuracy']), 2),\n",
        "        \"Precision\": np.round(np.mean(cv_results['test_precision']), 2),\n",
        "        \"Recall\": np.round(np.mean(cv_results['test_recall']), 2),\n",
        "        \"F1\": np.round(np.mean(cv_results['test_f1']), 2),\n",
        "        \"Macro F1\": np.round(np.mean(cv_results['test_f1_macro']), 2),\n",
        "        \"ROC AUC\": np.round(np.mean(cv_results['test_roc_auc']), 2)\n",
        "    }\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results).T\n",
        "\n",
        "# Visualization (adjust headers and cell values to match cross-validation results)\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(values=['Model', 'Accuracy', 'Precision', 'Recall', 'F1', 'Macro F1', 'ROC AUC'],\n",
        "                fill_color='#4A5ED7',\n",
        "                font=dict(color='white', size=12),\n",
        "                align=['left', 'center']),\n",
        "    cells=dict(values=[results_df.index, results_df['Accuracy'],\n",
        "                       results_df['Precision'], results_df['Recall'], results_df['F1'], results_df['Macro F1'], results_df['ROC AUC']],\n",
        "               fill_color=[['#222222', '#333333']*len(results_df)],  # Alternating row colors\n",
        "               font=dict(color='white', size=11),\n",
        "               align=['left', 'center'],\n",
        "               height=30))\n",
        "])\n",
        "\n",
        "# Adjust column widths and title settings\n",
        "fig.update_layout(\n",
        "    title='Classification Model\\'s Cross-Validated Performance',\n",
        "    title_x=0.5,\n",
        "    width=1200,\n",
        "    height=900,\n",
        "    paper_bgcolor='#333333',\n",
        "    plot_bgcolor='#333333',\n",
        "    font=dict(color='white')\n",
        ")\n",
        "\n",
        "fig.update_traces(columnwidth=[1, 1, 1, 1, 1, 1])\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8Vmf_5nSmWP"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "X_missing_filled.columns = [re.sub(r'[^\\w]', '_', col) for col in X_missing_filled.columns]\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
        "    \"Logistic Regression (D=3)\": make_pipeline(PolynomialFeatures(degree=3), LogisticRegression(max_iter=2000)),\n",
        "    \"SVM (Linear)\": SVC(kernel='linear'),\n",
        "    \"SVM (Polynomial)\": SVC(kernel='poly', degree=3),  # degree can be adjusted\n",
        "    \"SVM (RBF)\": SVC(kernel='rbf'),\n",
        "    \"SVM (Sigmoid)\": SVC(kernel='sigmoid'),\n",
        "    \"Decision Tree (Gini)\": DecisionTreeClassifier(criterion='gini'),\n",
        "    \"Decision Tree (Entropy)\": DecisionTreeClassifier(criterion='entropy'),\n",
        "    \"Random Forest (Gini)\": RandomForestClassifier(criterion='gini'),\n",
        "    \"Random Forest (Entropy)\": RandomForestClassifier(criterion='entropy'),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"LightGBM\": lgb.LGBMClassifier(verbose=-1),\n",
        "    # \"Neural Network\": MLPClassifier(max_iter=1000)\n",
        "}\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'f1': 'f1',\n",
        "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
        "    'roc_auc': 'roc_auc'\n",
        "}\n",
        "\n",
        "# Perform cross-validation and store results, including both train and test set metrics\n",
        "results = {}\n",
        "\n",
        "\n",
        "for name, model in models.items():\n",
        "    cv_results = cross_validate(model, X_missing_filled, y_missing_filled_classification, cv=10, scoring=scoring, return_train_score=True)\n",
        "    y_pred = cross_val_predict(model, X_missing_filled, y_missing_filled_classification, cv=10)\n",
        "    # train_accuracy = accuracy_score(y_missing_filled_classification, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        # \"Train Accuracy\": np.round(train_accuracy, 2),\n",
        "        \"Accuracy\": np.round(np.mean(cv_results['test_accuracy']), 2),\n",
        "        \"Precision\": np.round(np.mean(cv_results['test_precision']), 2),\n",
        "        \"Recall\": np.round(np.mean(cv_results['test_recall']), 2),\n",
        "        \"F1\": np.round(np.mean(cv_results['test_f1']), 2),\n",
        "        \"Macro F1\": np.round(np.mean(cv_results['test_f1_macro']), 2),\n",
        "        \"ROC AUC\": np.round(np.mean(cv_results['test_roc_auc']), 2)\n",
        "    }\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results).T\n",
        "\n",
        "# Visualization (adjust headers and cell values to match cross-validation results)\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(values=['Model', 'Accuracy', 'Precision', 'Recall', 'F1', 'Macro F1', 'ROC AUC'],\n",
        "                fill_color='#4A5ED7',\n",
        "                font=dict(color='white', size=12),\n",
        "                align=['left', 'center']),\n",
        "    cells=dict(values=[results_df.index, results_df['Accuracy'],\n",
        "                       results_df['Precision'], results_df['Recall'], results_df['F1'], results_df['Macro F1'], results_df['ROC AUC']],\n",
        "               fill_color=[['#222222', '#333333']*len(results_df)],  # Alternating row colors\n",
        "               font=dict(color='white', size=11),\n",
        "               align=['left', 'center'],\n",
        "               height=30))\n",
        "])\n",
        "\n",
        "# Adjust column widths and title settings\n",
        "fig.update_layout(\n",
        "    title='Classification Model\\'s Cross-Validated Performance',\n",
        "    title_x=0.5,\n",
        "    width=1200,\n",
        "    height=900,\n",
        "    paper_bgcolor='#333333',\n",
        "    plot_bgcolor='#333333',\n",
        "    font=dict(color='white')\n",
        ")\n",
        "\n",
        "fig.update_traces(columnwidth=[1, 1, 1, 1, 1, 1])\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtuZorHu-6EY"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"SVM (RBF)\": {'C': [0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 1, 10, 'scale']},\n",
        "    \"SVM (Polynomial)\": {'C': [0.1, 1, 10, 100], 'degree': [2, 3, 4], 'gamma': [0.01, 0.1, 1, 'scale']}\n",
        "}\n",
        "\n",
        "models = {\n",
        "    \"SVM (RBF)\": SVC(kernel='rbf'),\n",
        "    \"SVM (Polynomial)\": SVC(kernel='poly')\n",
        "}\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'f1': 'f1',\n",
        "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
        "    'roc_auc': 'roc_auc'\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid[name], cv=10, scoring=scoring, refit='f1_macro', return_train_score=True, verbose=1)\n",
        "    grid_search.fit(X_missing_filled, y_missing_filled_classification)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    cv_results = cross_validate(best_model, X_missing_filled, y_missing_filled_classification, cv=10, scoring=scoring, return_train_score=True)\n",
        "\n",
        "    results[name] = {\n",
        "        \"Accuracy\": np.round(np.mean(cv_results['test_accuracy']), 2),\n",
        "        \"Precision\": np.round(np.mean(cv_results['test_precision']), 2),\n",
        "        \"Recall\": np.round(np.mean(cv_results['test_recall']), 2),\n",
        "        \"F1\": np.round(np.mean(cv_results['test_f1']), 2),\n",
        "        \"Macro F1\": np.round(np.mean(cv_results['test_f1_macro']), 2),\n",
        "        \"ROC AUC\": np.round(np.mean(cv_results['test_roc_auc']), 2),\n",
        "        \"Best Parameters\": grid_search.best_params_\n",
        "    }\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results).T\n",
        "\n",
        "# Display results\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vejGvoI_CoID"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(values=['Model', 'Accuracy', 'Precision', 'Recall', 'F1', 'Macro F1', 'ROC AUC'],\n",
        "                fill_color='#4A5ED7',\n",
        "                font=dict(color='white', size=12),\n",
        "                align=['left', 'center']),\n",
        "    cells=dict(values=[results_df.index, results_df['Accuracy'],\n",
        "                       results_df['Precision'], results_df['Recall'], results_df['F1'], results_df['Macro F1'], results_df['ROC AUC']],\n",
        "               fill_color=[['#222222', '#333333']*len(results_df)],  # Alternating row colors\n",
        "               font=dict(color='white', size=11),\n",
        "               align=['left', 'center'],\n",
        "               height=30))\n",
        "])\n",
        "\n",
        "# Adjust column widths and title settings\n",
        "fig.update_layout(\n",
        "    title='Classification Model\\'s Cross-Validated Performance',\n",
        "    title_x=0.5,\n",
        "    width=1200,\n",
        "    height=900,\n",
        "    paper_bgcolor='#333333',\n",
        "    plot_bgcolor='#333333',\n",
        "    font=dict(color='white')\n",
        ")\n",
        "\n",
        "fig.update_traces(columnwidth=[1, 1, 1, 1, 1, 1])\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAxdlEhm8kfE"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Predict using cross-validated setup\n",
        "    y_pred = cross_val_predict(model, X_missing_filled, y_missing_filled_classification, cv=10)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_missing_filled_classification, y_pred)\n",
        "\n",
        "    # Get basic performance metrics\n",
        "    accuracy = accuracy_score(y_missing_filled_classification, y_pred)\n",
        "    precision = np.mean(np.diag(conf_matrix) / np.sum(conf_matrix, axis=0))\n",
        "    recall = np.mean(np.diag(conf_matrix) / np.sum(conf_matrix, axis=1))\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    # Store metrics and confusion matrix in the results dictionary\n",
        "    results[name] = {\n",
        "        \"Accuracy\": np.round(accuracy, 2),\n",
        "        \"Precision\": np.round(precision, 2),\n",
        "        \"Recall\": np.round(recall, 2),\n",
        "        \"F1\": np.round(f1, 2),\n",
        "        \"Confusion Matrix\": conf_matrix\n",
        "    }\n",
        "\n",
        "# Convert results to DataFrame for easy viewing\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKoozqsLEK4W"
      },
      "outputs": [],
      "source": [
        "# Function to create a heatmap for a given confusion matrix and model name\n",
        "def create_heatmap(matrix, model_name):\n",
        "    fig = go.Figure(data=go.Heatmap(\n",
        "        z=matrix,\n",
        "        x=['Predicted Negative', 'Predicted Positive'],\n",
        "        y=['Actual Negative', 'Actual Positive'],\n",
        "        showscale=True,\n",
        "        text=matrix,\n",
        "        texttemplate=\"%{text}\",\n",
        "        textfont={\"size\": 12}\n",
        "    ))\n",
        "\n",
        "    # Update layout with centered title\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            'text': f'Confusion Matrix for {model_name}',\n",
        "            'y': 0.9,  # Adjusting y position to provide some padding from the top of the figure\n",
        "            'x': 0.5,  # Centering the title\n",
        "            'xanchor': 'center',\n",
        "            'font': {'size': 14},\n",
        "            'yanchor': 'top'\n",
        "        },\n",
        "        height=400,\n",
        "        width=400,\n",
        "        margin=dict(l=60, r=60, t=60, b=60),  # Increased top margin to accommodate title\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Generate and display each confusion matrix as a separate image\n",
        "for name, data in results.items():\n",
        "    fig = create_heatmap(data['Confusion Matrix'], name)\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNu2Uo_LG6jd"
      },
      "outputs": [],
      "source": [
        "def create_heatmap(matrix, model_name, color_scale=\"Viridis\"):\n",
        "    \"\"\"\n",
        "    Creates and returns a heatmap figure from a confusion matrix for a given model with a customizable color scale.\n",
        "\n",
        "    Parameters:\n",
        "    - matrix (list of lists): Confusion matrix data.\n",
        "    - model_name (str): Name of the model.\n",
        "    - color_scale (str or list of tuples): Color scale for the heatmap.\n",
        "\n",
        "    Returns:\n",
        "    - plotly.graph_objects.Figure: Heatmap figure of the confusion matrix.\n",
        "    \"\"\"\n",
        "    # Create a heatmap using Plotly\n",
        "    heatmap = go.Heatmap(\n",
        "        z=matrix,\n",
        "        x=['Predicted Negative', 'Predicted Positive'],\n",
        "        y=['Actual Negative', 'Actual Positive'],\n",
        "        showscale=True,\n",
        "        text=matrix,\n",
        "        texttemplate=\"%{text}\",\n",
        "        textfont={\"size\": 12},\n",
        "        colorscale=color_scale\n",
        "    )\n",
        "\n",
        "    # Create a figure and add the heatmap\n",
        "    fig = go.Figure(data=heatmap)\n",
        "\n",
        "    # Update layout with a centered title and appropriate margins\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            'text': f'Confusion Matrix for {model_name}',\n",
        "            'y': 0.9,\n",
        "            'x': 0.5,\n",
        "            'xanchor': 'center',\n",
        "            'font': {'size': 14},\n",
        "            'yanchor': 'top'\n",
        "        },\n",
        "        height=400,\n",
        "        width=400,\n",
        "        margin=dict(l=60, r=60, t=80, b=40)\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "# Generate and display each confusion matrix with an attractive color scale\n",
        "for name, data in results.items():\n",
        "    fig = create_heatmap(data['Confusion Matrix'], name, color_scale=\"rdpu\") # agsunset, rdpu, spectral\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOdM-kVMRbtC"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = X_missing_filled_train_reg, X_missing_filled_test_reg, y_missing_filled_train_reg, y_missing_filled_test_reg\n",
        "\n",
        "# Define the models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"Lasso\": Lasso(),\n",
        "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
        "    \"SGD Regressor\": SGDRegressor(max_iter=1000, tol=1e-3),\n",
        "    \"XGBoost\": XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3),\n",
        "    # \"LightGBM\": LGBMRegressor(num_leaves=31, learning_rate=0.1, n_estimators=100),\n",
        "    \"CatBoost\": CatBoostRegressor(iterations=100, learning_rate=0.1, depth=3, silent=True),\n",
        "    \"SVR (RBF)\": SVR(kernel='rbf'),  # Default kernel is RBF\n",
        "    \"SVR (RBF)\": SVR(kernel='linear'),  # Default kernel is RBF\n",
        "    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n",
        "    \"Decision Tree (MSE)\": DecisionTreeRegressor(criterion='squared_error'),\n",
        "    \"Decision Tree (Friedman)\": DecisionTreeRegressor(criterion='friedman_mse'),\n",
        "    \"Decision Tree (Poisson)\": DecisionTreeRegressor(criterion='poisson'),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100),\n",
        "    \"Extra Trees\": ExtraTreesRegressor(n_estimators=100),\n",
        "    \"Gradient Boosting (Huber)\": GradientBoostingRegressor(loss='huber', n_estimators=100),\n",
        "    \"Gradient Boosting (MAE)\": GradientBoostingRegressor(loss='absolute_error', n_estimators=100),\n",
        "    \"Gradient Boosting (Quantile)\": GradientBoostingRegressor(loss='quantile', n_estimators=100),\n",
        "    \"Gradient Boosting (MSE)\": GradientBoostingRegressor(loss='squared_error', n_estimators=100),\n",
        "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100),\n",
        "    \"Bagging\": BaggingRegressor(n_estimators=100)\n",
        "}\n",
        "\n",
        "# Metrics storage\n",
        "metrics = {\n",
        "    'MAE': [],\n",
        "    'RMSE': [],\n",
        "    'MSE': [],\n",
        "    'Median AE': [],\n",
        "    'R^2': []\n",
        "}\n",
        "\n",
        "# Dictionary to store the results\n",
        "results = {}\n",
        "results_precision = {\n",
        "    \"MAE\": \".1f\",\n",
        "    \"RMSE\": \".1f\",\n",
        "    \"MSE\": \".0f\",\n",
        "    \"Median AE\": \".1f\",\n",
        "    \"R^2\": \".3f\"\n",
        "}\n",
        "\n",
        "\n",
        "# Evaluate each model\n",
        "for name, model in models.items():\n",
        "    # Fit model on training data\n",
        "    model.fit(X_train, y_train)\n",
        "    # Predict on testing data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    median_ae = np.median(np.abs(y_test - y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Store metrics in the dictionary\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'MSE': mse,\n",
        "        'Median AE': median_ae,\n",
        "        'R^2': r2\n",
        "    }\n",
        "\n",
        "# # Colors for the bar charts\n",
        "# colors = [\n",
        "#     'rgba(255, 99, 132, 0.8)', 'rgba(54, 162, 235, 0.8)', 'rgba(255, 206, 86, 0.8)',\n",
        "#     'rgba(75, 192, 192, 0.8)', 'rgba(153, 102, 255, 0.8)', 'rgba(255, 159, 64, 0.8)',\n",
        "#     'rgba(199, 199, 199, 0.8)', 'rgba(164, 194, 244, 0.8)', 'rgba(255, 218, 128, 0.8)',\n",
        "#     'rgba(255, 178, 102, 0.8)', 'rgba(179, 181, 198, 0.8)', 'rgba(77, 166, 255, 0.8)',\n",
        "#     'rgba(148, 103, 189, 0.8)'\n",
        "# ]\n",
        "\n",
        "# colors = [\n",
        "#     'rgba(255, 99, 132, 0.8)', 'rgba(54, 162, 235, 0.8)', 'rgba(255, 206, 86, 0.8)',\n",
        "#     'rgba(75, 192, 192, 0.8)', 'rgba(153, 102, 255, 0.8)', 'rgba(255, 159, 64, 0.8)',\n",
        "#     'rgba(199, 199, 199, 0.8)', 'rgba(164, 194, 244, 0.8)', 'rgba(255, 218, 128, 0.8)',\n",
        "#     'rgba(255, 178, 102, 0.8)', 'rgba(179, 181, 198, 0.8)', 'rgba(77, 166, 255, 0.8)',\n",
        "#     'rgba(148, 103, 189, 0.8)'\n",
        "# ]\n",
        "\n",
        "colors = [\n",
        "    # 'rgba(102, 194, 165, 0.8)',  # Greenish\n",
        "    'rgba(54, 162, 235, 0.8)',\n",
        "    'rgba(252, 141, 98, 0.8)',   # Orangish\n",
        "    'rgba(141, 160, 203, 0.8)',  # Blueish\n",
        "    'rgba(231, 138, 195, 0.8)',  # Pinkish\n",
        "    'rgba(166, 216, 84, 0.8)',   # Lime green\n",
        "    'rgba(255, 217, 47, 0.8)',   # Yellow\n",
        "    'rgba(77, 166, 255, 0.8)',\n",
        "    # 'rgba(229, 196, 148, 0.8)',  # Beige\n",
        "    'rgba(255, 178, 102, 0.8)',\n",
        "    # 'rgba(179, 179, 179, 0.8)',  # Gray\n",
        "    'rgba(217, 239, 139, 0.8)',  # Light green\n",
        "    'rgba(241, 182, 218, 0.8)',  # Soft pink\n",
        "    'rgba(188, 128, 189, 0.8)',  # Purple\n",
        "    'rgba(255, 99, 132, 0.8)',\n",
        "    # 'rgba(204, 235, 197, 0.8)',  # Pale green\n",
        "    'rgba(255, 188, 121, 0.8)'   # Peach\n",
        "]\n",
        "\n",
        "# Create a separate figure for each metric\n",
        "for metric in metrics.keys():\n",
        "    fig = go.Figure()\n",
        "    for i, (model, color) in enumerate(zip(results.keys(), colors)):\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=[model],\n",
        "            y=[results[model][metric]],\n",
        "            name=model,\n",
        "            marker_color=color,\n",
        "            text=[f\"{results[model][metric]:{results_precision[metric]}}\"],\n",
        "            textposition='outside'\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f'{metric} of Regression Models',\n",
        "        xaxis_title='Model',\n",
        "        yaxis_title=metric,\n",
        "        template='plotly_white',\n",
        "        barmode='group',\n",
        "        height=600,\n",
        "        width=900,\n",
        "        title_x=0.5,\n",
        "        showlegend=False  # This removes the legend\n",
        "    )\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRYhdQV6ibyx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# models = {\n",
        "#     \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
        "#     \"Logistic Regression (D=3)\": make_pipeline(PolynomialFeatures(degree=3), LogisticRegression(max_iter=2000)),\n",
        "#     \"SVM (Linear)\": SVC(kernel='linear'),\n",
        "#     \"SVM (Polynomial)\": SVC(kernel='poly', degree=3),  # degree can be adjusted\n",
        "#     \"SVM (RBF)\": SVC(kernel='rbf'),\n",
        "#     \"SVM (Sigmoid)\": SVC(kernel='sigmoid'),\n",
        "#     \"Decision Tree (Gini)\": DecisionTreeClassifier(criterion='gini'),\n",
        "#     \"Decision Tree (Entropy)\": DecisionTreeClassifier(criterion='entropy'),\n",
        "#     \"Random Forest (Gini)\": RandomForestClassifier(criterion='gini'),\n",
        "#     \"Random Forest (Entropy)\": RandomForestClassifier(criterion='entropy'),\n",
        "#     \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "#     \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "#     \"Naive Bayes\": GaussianNB(),\n",
        "#     \"AdaBoost\": AdaBoostClassifier(),\n",
        "#     \"Extra Trees\": ExtraTreesClassifier(n_estimators=100),\n",
        "#     \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "#     \"LightGBM\": lgb.LGBMClassifier(),\n",
        "#     # \"Neural Network\": MLPClassifier(max_iter=1000)\n",
        "# }\n",
        "\n",
        "# Assuming DecisionTreeRegressor\n",
        "model_to_explain = models['XGBoost']\n",
        "explainer = shap.TreeExplainer(model_to_explain)\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "# Calculate SHAP values for the training set\n",
        "# For regression, no need to index shap_values with [1]\n",
        "shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "\n",
        "# Sort the features by importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'SHAP Importance': shap_sum\n",
        "})\n",
        "feature_importance = feature_importance.sort_values(by='SHAP Importance', ascending=False)\n",
        "\n",
        "# Create a Plotly bar chart\n",
        "fig = go.Figure([go.Bar(x=feature_importance['SHAP Importance'], y=feature_importance['Feature'],\n",
        "                        orientation='h')])\n",
        "fig.update_layout(\n",
        "    title='Global Feature Importance using SHAP Values',\n",
        "    xaxis_title='Mean Absolute SHAP Value',\n",
        "    yaxis_title='Feature',\n",
        "    yaxis={'categoryorder': 'total ascending'},\n",
        "    template='plotly_white',\n",
        "    height=1600,\n",
        "    width=1200,\n",
        "    title_x=0.5,\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1EBcgJpP9KV"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "# Sample data loading and preprocessing\n",
        "# X_train and y_train should be your training dataset\n",
        "# Make sure to define or load X_train and y_train appropriately\n",
        "\n",
        "# Initialize and train an XGBoost model\n",
        "model_to_explain = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model_to_explain.fit(X_train, y_train)\n",
        "\n",
        "# Explain the model's predictions using SHAP\n",
        "explainer = shap.Explainer(model_to_explain)\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "# Calculate the mean SHAP values for each feature\n",
        "shap_sum = shap_values.values.mean(axis=0)\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Mean SHAP Value': shap_sum\n",
        "})\n",
        "feature_importance = feature_importance.sort_values(by='Mean SHAP Value', ascending=True)\n",
        "\n",
        "# Set colors conditionally\n",
        "colors = ['mediumvioletred' if x < 0 else 'royalblue' for x in feature_importance['Mean SHAP Value']]\n",
        "\n",
        "# Create a Plotly bar chart to visualize the mean SHAP values with color coding\n",
        "fig = go.Figure([go.Bar(x=feature_importance['Mean SHAP Value'], y=feature_importance['Feature'],\n",
        "                        orientation='h', marker_color=colors)])\n",
        "fig.update_layout(\n",
        "    title='Global Feature Importance using Mean SHAP Values',\n",
        "    xaxis_title='Mean SHAP Value',\n",
        "    yaxis_title='Feature',\n",
        "    yaxis={'categoryorder': 'total ascending'},\n",
        "    template='plotly_white',\n",
        "    height=1600,\n",
        "    width=1200,\n",
        "    title_x=0.5,\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmpcZzU2PEpZ"
      },
      "outputs": [],
      "source": [
        "# Sample data loading and preprocessing\n",
        "# X_train and y_train should be your training dataset\n",
        "# Make sure to define or load X_train and y_train appropriately\n",
        "\n",
        "# Initialize and train an XGBoost model\n",
        "model_to_explain = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model_to_explain.fit(X_train, y_train)\n",
        "\n",
        "# Explain the model's predictions using SHAP\n",
        "explainer = shap.Explainer(model_to_explain)\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "# Convert SHAP values to a DataFrame for easier manipulation\n",
        "shap_df = pd.DataFrame(shap_values.values, columns=X_train.columns)\n",
        "\n",
        "# Prepare Plotly figure\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a box plot for each feature\n",
        "for col in shap_df.columns:\n",
        "    fig.add_trace(go.Box(y=shap_df[col], name=col))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='SHAP Value Distribution for Each Feature',\n",
        "    yaxis_title='SHAP Value',\n",
        "    xaxis={'title': 'Feature'},\n",
        "    xaxis_tickangle=-45,\n",
        "    template='plotly_white',\n",
        "    height=800,\n",
        "    width=1200,\n",
        "    title_x=0.5,\n",
        "    showlegend=False  # This will hide the legend\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxwFGWYvyU8L"
      },
      "outputs": [],
      "source": [
        "# Initialize and train an SVM model with a sigmoid kernel\n",
        "svm_model = SVC(kernel='sigmoid', probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Create a Lime Explainer\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=np.array(X_train),\n",
        "    feature_names=X_train.columns.tolist(),\n",
        "    class_names=['class1', 'class0'],  # Adjust based on your actual classes\n",
        "    mode='classification',\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Choose an instance to explain\n",
        "instance_index = 0\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=np.array(X_train.iloc[instance_index]),\n",
        "    predict_fn=svm_model.predict_proba,\n",
        "    num_features=len(X_train.columns)\n",
        ")\n",
        "\n",
        "# Extract the feature names and their corresponding weights from the explanation\n",
        "feature_names, weights = zip(*exp.as_list(label=exp.available_labels()[0]))\n",
        "\n",
        "# Convert weights to a list of positive and negative values for coloring\n",
        "weights = list(weights)\n",
        "colors = ['royalblue' if x > 0 else 'mediumvioletred' for x in weights]\n",
        "\n",
        "# Create a Plotly bar chart to visualize the explanation\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(\n",
        "        x=weights,\n",
        "        y=list(feature_names),\n",
        "        orientation='h',\n",
        "        marker_color=colors\n",
        "    )\n",
        "])\n",
        "\n",
        "# Update the layout of the figure\n",
        "fig.update_layout(\n",
        "    title=f'LIME Explanation for Being Placed',\n",
        "    xaxis_title='Weight',\n",
        "    yaxis_title='Feature',\n",
        "    template='plotly_white',\n",
        "    height=1200,\n",
        "    width=1200,\n",
        "    title_x=0.5\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQEhlYDG8_iT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# models = {\n",
        "#     \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
        "#     \"Logistic Regression (D=3)\": make_pipeline(PolynomialFeatures(degree=3), LogisticRegression(max_iter=2000)),\n",
        "#     \"SVM (Linear)\": SVC(kernel='linear'),\n",
        "#     \"SVM (Polynomial)\": SVC(kernel='poly', degree=3),  # degree can be adjusted\n",
        "#     \"SVM (RBF)\": SVC(kernel='rbf'),\n",
        "#     \"SVM (Sigmoid)\": SVC(kernel='sigmoid'),\n",
        "#     \"Decision Tree (Gini)\": DecisionTreeClassifier(criterion='gini'),\n",
        "#     \"Decision Tree (Entropy)\": DecisionTreeClassifier(criterion='entropy'),\n",
        "#     \"Random Forest (Gini)\": RandomForestClassifier(criterion='gini'),\n",
        "#     \"Random Forest (Entropy)\": RandomForestClassifier(criterion='entropy'),\n",
        "#     \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "#     \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "#     \"Naive Bayes\": GaussianNB(),\n",
        "#     \"AdaBoost\": AdaBoostClassifier(),\n",
        "#     \"Extra Trees\": ExtraTreesClassifier(n_estimators=100),\n",
        "#     \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "#     \"LightGBM\": lgb.LGBMClassifier(),\n",
        "#     # \"Neural Network\": MLPClassifier(max_iter=1000)\n",
        "# }\n",
        "\n",
        "# Assuming DecisionTreeRegressor\n",
        "model_to_explain = models['XGBoost']\n",
        "explainer = shap.TreeExplainer(model_to_explain)\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "# Create a DataFrame from SHAP values for easier manipulation\n",
        "shap_values_df = pd.DataFrame(shap_values, columns=X_train.columns)\n",
        "\n",
        "# Initialize a dictionary to hold the aggregated SHAP values\n",
        "aggregated_shap_values = {}\n",
        "\n",
        "# Aggregate SHAP values\n",
        "for column in shap_values_df.columns:\n",
        "    # The base feature is the part before the first underscore\n",
        "    base_feature = column.split('_', 1)[0]\n",
        "    if base_feature not in aggregated_shap_values:\n",
        "        aggregated_shap_values[base_feature] = shap_values_df[column].abs().mean()\n",
        "    else:\n",
        "        aggregated_shap_values[base_feature] += shap_values_df[column].abs().mean()\n",
        "\n",
        "# Convert the aggregated SHAP values into a DataFrame\n",
        "feature_importance = pd.DataFrame(list(aggregated_shap_values.items()), columns=['Feature', 'SHAP Importance'])\n",
        "feature_importance.sort_values(by='SHAP Importance', ascending=False, inplace=True)\n",
        "\n",
        "feature_importance['Feature'] = ['Race', 'Biggest Challenge in Search', 'Primary Track', 'Starting Month',\n",
        "                                 'Work Authorization Status', 'Employment Status', 'Number of Interviews',\n",
        "                                 'Professional Experience', 'Length of Job Search', 'Gender', 'Highest Level of Education',\n",
        "                                 'Number of Applications', 'Is Covid']\n",
        "\n",
        "# Plot the aggregated SHAP values using Plotly\n",
        "fig = go.Figure([go.Bar(x=feature_importance['SHAP Importance'], y=feature_importance['Feature'], orientation='h')])\n",
        "fig.update_layout(\n",
        "    title='Aggregated Global Feature Importance using SHAP Values',\n",
        "    xaxis_title='Mean Absolute SHAP Value',\n",
        "    yaxis_title='Feature',\n",
        "    yaxis={'categoryorder': 'total ascending'},\n",
        "    template='plotly_white'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyhZBkBi3OYz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# models = {\n",
        "#     \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
        "#     \"Logistic Regression (D=3)\": make_pipeline(PolynomialFeatures(degree=3), LogisticRegression(max_iter=2000)),\n",
        "#     \"SVM (Linear)\": SVC(kernel='linear'),\n",
        "#     \"SVM (Polynomial)\": SVC(kernel='poly', degree=3),  # degree can be adjusted\n",
        "#     \"SVM (RBF)\": SVC(kernel='rbf'),\n",
        "#     \"SVM (Sigmoid)\": SVC(kernel='sigmoid'),\n",
        "#     \"Decision Tree (Gini)\": DecisionTreeClassifier(criterion='gini'),\n",
        "#     \"Decision Tree (Entropy)\": DecisionTreeClassifier(criterion='entropy'),\n",
        "#     \"Random Forest (Gini)\": RandomForestClassifier(criterion='gini'),\n",
        "#     \"Random Forest (Entropy)\": RandomForestClassifier(criterion='entropy'),\n",
        "#     \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "#     \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "#     \"Naive Bayes\": GaussianNB(),\n",
        "#     \"AdaBoost\": AdaBoostClassifier(),\n",
        "#     \"Extra Trees\": ExtraTreesClassifier(n_estimators=100),\n",
        "#     \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "#     \"LightGBM\": lgb.LGBMClassifier(),\n",
        "#     # \"Neural Network\": MLPClassifier(max_iter=1000)\n",
        "# }\n",
        "\n",
        "# Assuming DecisionTreeRegressor\n",
        "model_to_explain = models['XGBoost']\n",
        "explainer = shap.TreeExplainer(model_to_explain)\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "# Create a DataFrame from SHAP values for easier manipulation\n",
        "shap_values_df = pd.DataFrame(shap_values, columns=X_train.columns)\n",
        "\n",
        "# Initialize a dictionary to hold the mean SHAP values\n",
        "mean_shap_values = {}\n",
        "\n",
        "# Compute mean SHAP values\n",
        "for column in shap_values_df.columns:\n",
        "    # Aggregate SHAP values by the base feature, assuming features are possibly prefixed or modified\n",
        "    base_feature = column.split('_', 1)[0]\n",
        "    if base_feature not in mean_shap_values:\n",
        "        mean_shap_values[base_feature] = shap_values_df[column].mean()\n",
        "    else:\n",
        "        mean_shap_values[base_feature] += shap_values_df[column].mean()\n",
        "\n",
        "# Convert the mean SHAP values into a DataFrame and sort by their absolute values for visualization clarity\n",
        "feature_importance = pd.DataFrame(list(mean_shap_values.items()), columns=['Feature', 'Mean SHAP Value'])\n",
        "feature_importance.sort_values(by='Mean SHAP Value', key=abs, ascending=False, inplace=True)\n",
        "\n",
        "# Explicitly naming features after aggregation for clearer understanding in the plot\n",
        "# Ensure this mapping matches the features after any aggregation or transformation\n",
        "feature_importance['Feature'] = ['Race', 'Biggest Challenge in Search', 'Primary Track', 'Starting Month',\n",
        "                                 'Work Authorization Status', 'Employment Status', 'Number of Interviews',\n",
        "                                 'Professional Experience', 'Length of Job Search', 'Gender', 'Highest Level of Education',\n",
        "                                 'Number of Applications', 'Is Covid']\n",
        "\n",
        "# Plot the mean SHAP values using Plotly\n",
        "fig = go.Figure([go.Bar(x=feature_importance['Mean SHAP Value'], y=feature_importance['Feature'], orientation='h')])\n",
        "fig.update_layout(\n",
        "    title='Mean SHAP Value per Feature',\n",
        "    xaxis_title='Mean SHAP Value',\n",
        "    yaxis_title='Feature',\n",
        "    yaxis={'categoryorder': 'total ascending'},\n",
        "    template='plotly_white'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEfcbkhUtF5P"
      },
      "outputs": [],
      "source": [
        " # Assuming df is your preprocessed DataFrame\n",
        "df = status_filtered_df_no_missing.copy()\n",
        "\n",
        "# Typically, you might want to encode categorical variables here if not already done\n",
        "# Encoding can be done using LabelEncoder or pd.get_dummies as previously discussed\n",
        "\n",
        "# Define your features and targets\n",
        "X_no_missing = df.drop(['program_duration_days', 'placed'], axis=1)  # all columns except the targets\n",
        "y_no_missing_regression = df['program_duration_days']  # target for regression\n",
        "y_no_missing_classification = df['placed']  # target for classification\n",
        "\n",
        "# Split the data for regression\n",
        "X_no_missing_train_reg, X_no_missing_test_reg, y_no_missing_train_reg, y_no_missing_test_reg = train_test_split(\n",
        "    X_no_missing, y_no_missing_regression, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Split the data for classification\n",
        "X_no_missing_train_class, X_no_missing_test_class, y_no_missing_train_class, y_no_missing_test_class = train_test_split(\n",
        "    X_no_missing, y_no_missing_classification, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPO_mywJ3otz"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "X_no_missing.columns = [re.sub(r'[^\\w]', '_', col) for col in X_no_missing.columns]\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
        "    \"Logistic Regression (D=3)\": make_pipeline(PolynomialFeatures(degree=3), LogisticRegression(max_iter=2000)),\n",
        "    \"SVM (Linear)\": SVC(kernel='linear'),\n",
        "    \"SVM (Polynomial)\": SVC(kernel='poly', degree=3),  # degree can be adjusted\n",
        "    \"SVM (RBF)\": SVC(kernel='rbf'),\n",
        "    \"SVM (Sigmoid)\": SVC(kernel='sigmoid'),\n",
        "    \"Decision Tree (Gini)\": DecisionTreeClassifier(criterion='gini'),\n",
        "    \"Decision Tree (Entropy)\": DecisionTreeClassifier(criterion='entropy'),\n",
        "    \"Random Forest (Gini)\": RandomForestClassifier(criterion='gini'),\n",
        "    \"Random Forest (Entropy)\": RandomForestClassifier(criterion='entropy'),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"LightGBM\": lgb.LGBMClassifier(verbose=-1),\n",
        "    # \"Neural Network\": MLPClassifier(max_iter=1000)\n",
        "}\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'f1': 'f1',\n",
        "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
        "    'roc_auc': 'roc_auc'\n",
        "}\n",
        "\n",
        "# Perform cross-validation and store results, including both train and test set metrics\n",
        "results = {}\n",
        "\n",
        "\n",
        "for name, model in models.items():\n",
        "    cv_results = cross_validate(model, X_no_missing, y_no_missing_classification, cv=10, scoring=scoring, return_train_score=True)\n",
        "    y_pred = cross_val_predict(model, X_no_missing, y_no_missing_classification, cv=10)\n",
        "    # train_accuracy = accuracy_score(y_missing_filled_classification, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        # \"Train Accuracy\": np.round(train_accuracy, 2),\n",
        "        \"Accuracy\": np.round(np.mean(cv_results['test_accuracy']), 2),\n",
        "        \"Precision\": np.round(np.mean(cv_results['test_precision']), 2),\n",
        "        \"Recall\": np.round(np.mean(cv_results['test_recall']), 2),\n",
        "        \"F1\": np.round(np.mean(cv_results['test_f1']), 2),\n",
        "        \"Macro F1\": np.round(np.mean(cv_results['test_f1_macro']), 2),\n",
        "        \"ROC AUC\": np.round(np.mean(cv_results['test_roc_auc']), 2)\n",
        "    }\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results).T\n",
        "\n",
        "# Visualization (adjust headers and cell values to match cross-validation results)\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(values=['Model', 'Accuracy', 'Precision', 'Recall', 'F1', 'Macro F1', 'ROC AUC'],\n",
        "                fill_color='#4A5ED7',\n",
        "                font=dict(color='white', size=12),\n",
        "                align=['left', 'center']),\n",
        "    cells=dict(values=[results_df.index, results_df['Accuracy'],\n",
        "                       results_df['Precision'], results_df['Recall'], results_df['F1'], results_df['Macro F1'], results_df['ROC AUC']],\n",
        "               fill_color=[['#222222', '#333333']*len(results_df)],  # Alternating row colors\n",
        "               font=dict(color='white', size=11),\n",
        "               align=['left', 'center'],\n",
        "               height=30))\n",
        "])\n",
        "\n",
        "# Adjust column widths and title settings\n",
        "fig.update_layout(\n",
        "    title='Classification Model\\'s Cross-Validated Performance',\n",
        "    title_x=0.5,\n",
        "    width=1200,\n",
        "    height=900,\n",
        "    paper_bgcolor='#333333',\n",
        "    plot_bgcolor='#333333',\n",
        "    font=dict(color='white')\n",
        ")\n",
        "\n",
        "fig.update_traces(columnwidth=[1, 1, 1, 1, 1, 1])\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jELPgwmsFh-6"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Predict using cross-validated setup\n",
        "    y_pred = cross_val_predict(model, X_no_missing, y_no_missing_classification, cv=10)\n",
        "    threshold = 0.5  # This is a common threshold for binary classification\n",
        "    y_pred_binary = (y_pred > threshold).astype(int)  # Convert probabilities to 0 or 1\n",
        "    conf_matrix = confusion_matrix(y_no_missing_classification, y_pred_binary)\n",
        "    # Calculate confusion matrix\n",
        "    # conf_matrix = confusion_matrix(y_no_missing_classification, y_pred)\n",
        "\n",
        "    # Get basic performance metrics\n",
        "    accuracy = accuracy_score(y_no_missing_classification, y_pred_binary)\n",
        "    precision = np.mean(np.diag(conf_matrix) / np.sum(conf_matrix, axis=0))\n",
        "    recall = np.mean(np.diag(conf_matrix) / np.sum(conf_matrix, axis=1))\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    # Store metrics and confusion matrix in the results dictionary\n",
        "    results[name] = {\n",
        "        \"Accuracy\": np.round(accuracy, 2),\n",
        "        \"Precision\": np.round(precision, 2),\n",
        "        \"Recall\": np.round(recall, 2),\n",
        "        \"F1\": np.round(f1, 2),\n",
        "        \"Confusion Matrix\": conf_matrix\n",
        "    }\n",
        "\n",
        "# Convert results to DataFrame for easy viewing\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f86CL1dZFaVp"
      },
      "outputs": [],
      "source": [
        "def create_heatmap(matrix, model_name, color_scale=\"Viridis\"):\n",
        "    \"\"\"\n",
        "    Creates and returns a heatmap figure from a confusion matrix for a given model with a customizable color scale.\n",
        "\n",
        "    Parameters:\n",
        "    - matrix (list of lists): Confusion matrix data.\n",
        "    - model_name (str): Name of the model.\n",
        "    - color_scale (str or list of tuples): Color scale for the heatmap.\n",
        "\n",
        "    Returns:\n",
        "    - plotly.graph_objects.Figure: Heatmap figure of the confusion matrix.\n",
        "    \"\"\"\n",
        "    # Create a heatmap using Plotly\n",
        "    heatmap = go.Heatmap(\n",
        "        z=matrix,\n",
        "        x=['Predicted Negative', 'Predicted Positive'],\n",
        "        y=['Actual Negative', 'Actual Positive'],\n",
        "        showscale=True,\n",
        "        text=matrix,\n",
        "        texttemplate=\"%{text}\",\n",
        "        textfont={\"size\": 12},\n",
        "        colorscale=color_scale\n",
        "    )\n",
        "\n",
        "    # Create a figure and add the heatmap\n",
        "    fig = go.Figure(data=heatmap)\n",
        "\n",
        "    # Update layout with a centered title and appropriate margins\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            'text': f'Confusion Matrix for {model_name}',\n",
        "            'y': 0.9,\n",
        "            'x': 0.5,\n",
        "            'xanchor': 'center',\n",
        "            'font': {'size': 14},\n",
        "            'yanchor': 'top'\n",
        "        },\n",
        "        height=400,\n",
        "        width=400,\n",
        "        margin=dict(l=60, r=60, t=80, b=40)\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "# Generate and display each confusion matrix with an attractive color scale\n",
        "for name, data in results.items():\n",
        "    fig = create_heatmap(data['Confusion Matrix'], name, color_scale=\"rdpu\") # agsunset, rdpu, spectral\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKLJWeVtCSLQ"
      },
      "outputs": [],
      "source": [
        "# models = {\n",
        "#     \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
        "#     \"Logistic Regression (D=3)\": make_pipeline(PolynomialFeatures(degree=3), LogisticRegression(max_iter=2000)),\n",
        "#     \"SVM (Linear)\": SVC(kernel='linear'),\n",
        "#     \"SVM (Polynomial)\": SVC(kernel='poly', degree=3),  # degree can be adjusted\n",
        "#     \"SVM (RBF)\": SVC(kernel='rbf'),\n",
        "#     \"SVM (Sigmoid)\": SVC(kernel='sigmoid'),\n",
        "#     \"Decision Tree (Gini)\": DecisionTreeClassifier(criterion='gini'),\n",
        "#     \"Decision Tree (Entropy)\": DecisionTreeClassifier(criterion='entropy'),\n",
        "#     \"Random Forest (Gini)\": RandomForestClassifier(criterion='gini'),\n",
        "#     \"Random Forest (Entropy)\": RandomForestClassifier(criterion='entropy'),\n",
        "#     \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "#     \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "#     \"Naive Bayes\": GaussianNB(),\n",
        "#     \"AdaBoost\": AdaBoostClassifier(),\n",
        "#     \"Extra Trees\": ExtraTreesClassifier(n_estimators=100),\n",
        "#     \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "#     \"LightGBM\": lgb.LGBMClassifier(),\n",
        "#     # \"Neural Network\": MLPClassifier(max_iter=1000)\n",
        "# }\n",
        "\n",
        "# Assuming DecisionTreeRegressor\n",
        "model_to_explain = models['XGBoost']\n",
        "explainer = shap.TreeExplainer(model_to_explain)\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "# Calculate SHAP values for the training set\n",
        "# For regression, no need to index shap_values with [1]\n",
        "shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "\n",
        "# Sort the features by importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'SHAP Importance': shap_sum\n",
        "})\n",
        "feature_importance = feature_importance.sort_values(by='SHAP Importance', ascending=False)\n",
        "\n",
        "# Create a Plotly bar chart\n",
        "fig = go.Figure([go.Bar(x=feature_importance['SHAP Importance'], y=feature_importance['Feature'],\n",
        "                        orientation='h')])\n",
        "fig.update_layout(\n",
        "    title='Global Feature Importance using SHAP Values',\n",
        "    xaxis_title='Mean Absolute SHAP Value',\n",
        "    yaxis_title='Feature',\n",
        "    yaxis={'categoryorder': 'total ascending'},\n",
        "    template='plotly_white',\n",
        "    height=1600,\n",
        "    width=1200,\n",
        "    title_x=0.5,\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRW4HXpYI2kh"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "# Sample data loading and preprocessing\n",
        "# X_train and y_train should be your training dataset\n",
        "# Make sure to define or load X_train and y_train appropriately\n",
        "\n",
        "# Initialize and train an XGBoost model\n",
        "model_to_explain = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model_to_explain.fit(X_no_missing, y_no_missing_classification)\n",
        "\n",
        "# Explain the model's predictions using SHAP\n",
        "explainer = shap.Explainer(model_to_explain)\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "# Calculate the mean SHAP values for each feature\n",
        "shap_sum = shap_values.values.mean(axis=0)\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Mean SHAP Value': shap_sum\n",
        "})\n",
        "feature_importance = feature_importance.sort_values(by='Mean SHAP Value', ascending=True)\n",
        "\n",
        "# Set colors conditionally\n",
        "colors = ['mediumvioletred' if x < 0 else 'royalblue' for x in feature_importance['Mean SHAP Value']]\n",
        "\n",
        "# Create a Plotly bar chart to visualize the mean SHAP values with color coding\n",
        "fig = go.Figure([go.Bar(x=feature_importance['Mean SHAP Value'], y=feature_importance['Feature'],\n",
        "                        orientation='h', marker_color=colors)])\n",
        "fig.update_layout(\n",
        "    title='Global Feature Importance using Mean SHAP Values',\n",
        "    xaxis_title='Mean SHAP Value',\n",
        "    yaxis_title='Feature',\n",
        "    yaxis={'categoryorder': 'total ascending'},\n",
        "    template='plotly_white',\n",
        "    height=1600,\n",
        "    width=1200,\n",
        "    title_x=0.5,\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAHUF1mnCdWX"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "# Sample data loading and preprocessing\n",
        "# X_train and y_train should be your training dataset\n",
        "# Make sure to define or load X_train and y_train appropriately\n",
        "\n",
        "# Initialize and train an XGBoost model\n",
        "# model_to_explain = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "# model_to_explain.fit(X_train, y_train)\n",
        "\n",
        "model_to_explain = models['XGBoost']\n",
        "explainer = shap.TreeExplainer(model_to_explain)\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "# Calculate SHAP values for the training set\n",
        "# For regression, no need to index shap_values with [1]\n",
        "shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Mean SHAP Value': shap_sum\n",
        "})\n",
        "feature_importance = feature_importance.sort_values(by='Mean SHAP Value', ascending=True)\n",
        "\n",
        "# Set colors conditionally\n",
        "colors = ['mediumvioletred' if x < 0 else 'royalblue' for x in feature_importance['Mean SHAP Value']]\n",
        "\n",
        "# Create a Plotly bar chart to visualize the mean SHAP values with color coding\n",
        "fig = go.Figure([go.Bar(x=feature_importance['Mean SHAP Value'], y=feature_importance['Feature'],\n",
        "                        orientation='h', marker_color=colors)])\n",
        "fig.update_layout(\n",
        "    title='Global Feature Importance using Mean SHAP Values',\n",
        "    xaxis_title='Mean SHAP Value',\n",
        "    yaxis_title='Feature',\n",
        "    yaxis={'categoryorder': 'total ascending'},\n",
        "    template='plotly_white',\n",
        "    height=1600,\n",
        "    width=1200,\n",
        "    title_x=0.5,\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKfCs6VjCiyR"
      },
      "outputs": [],
      "source": [
        "# model_to_explain = models['XGBoost']\n",
        "# explainer = shap.TreeExplainer(model_to_explain)\n",
        "# shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "# # Calculate SHAP values for the training set\n",
        "# # For regression, no need to index shap_values with [1]\n",
        "# shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "\n",
        "# Sample data loading and preprocessing\n",
        "# X_train and y_train should be your training dataset\n",
        "# Make sure to define or load X_train and y_train appropriately\n",
        "\n",
        "# Initialize and train an XGBoost model\n",
        "model_to_explain = models['XGBoost']\n",
        "model_to_explain.fit(X_train, y_train)\n",
        "\n",
        "# Explain the model's predictions using SHAP\n",
        "explainer = shap.Explainer(model_to_explain)\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "\n",
        "\n",
        "# Convert SHAP values to a DataFrame for easier manipulation\n",
        "shap_df = pd.DataFrame(shap_values.values, columns=X_train.columns)\n",
        "\n",
        "# Prepare Plotly figure\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a box plot for each feature\n",
        "for col in shap_df.columns:\n",
        "    fig.add_trace(go.Box(y=shap_df[col], name=col))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='SHAP Value Distribution for Each Feature',\n",
        "    yaxis_title='SHAP Value',\n",
        "    xaxis={'title': 'Feature'},\n",
        "    xaxis_tickangle=-45,\n",
        "    template='plotly_white',\n",
        "    height=800,\n",
        "    width=1200,\n",
        "    title_x=0.5,\n",
        "    showlegend=False  # This will hide the legend\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VdzkxTOCnob"
      },
      "outputs": [],
      "source": [
        "# Initialize and train an SVM model with a sigmoid kernel\n",
        "svm_model = SVC(kernel='sigmoid', probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Create a Lime Explainer\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=np.array(X_train),\n",
        "    feature_names=X_train.columns.tolist(),\n",
        "    class_names=['class1', 'class0'],  # Adjust based on your actual classes\n",
        "    mode='classification',\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Choose an instance to explain\n",
        "instance_index = 0\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=np.array(X_train.iloc[instance_index]),\n",
        "    predict_fn=svm_model.predict_proba,\n",
        "    num_features=len(X_train.columns)\n",
        ")\n",
        "\n",
        "# Extract the feature names and their corresponding weights from the explanation\n",
        "feature_names, weights = zip(*exp.as_list(label=exp.available_labels()[0]))\n",
        "\n",
        "# Convert weights to a list of positive and negative values for coloring\n",
        "weights = list(weights)\n",
        "colors = ['royalblue' if x > 0 else 'mediumvioletred' for x in weights]\n",
        "\n",
        "# Create a Plotly bar chart to visualize the explanation\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(\n",
        "        x=weights,\n",
        "        y=list(feature_names),\n",
        "        orientation='h',\n",
        "        marker_color=colors\n",
        "    )\n",
        "])\n",
        "\n",
        "# Update the layout of the figure\n",
        "fig.update_layout(\n",
        "    title=f'LIME Explanation for Being Placed',\n",
        "    xaxis_title='Weight',\n",
        "    yaxis_title='Feature',\n",
        "    template='plotly_white',\n",
        "    height=1200,\n",
        "    width=1200,\n",
        "    title_x=0.5\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2_rvY0KOfeR"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = X_no_missing_train_class, X_no_missing_test_class, y_no_missing_train_class, y_no_missing_test_class\n",
        "\n",
        "# Assuming X_train and X_test are already defined\n",
        "# Initialize and fit the decision tree model\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict classes on the test data\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Apply t-SNE only to the test set\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "X_test_tsne = tsne.fit_transform(X_test)\n",
        "\n",
        "# Calculate TP, FP, TN, FN on the test set\n",
        "# Assuming binary classification, 1 as positive and 0 as negative\n",
        "tp_mask = (y_test_pred == 1) & (y_test == 1)\n",
        "fp_mask = (y_test_pred == 1) & (y_test == 0)\n",
        "tn_mask = (y_test_pred == 0) & (y_test == 0)\n",
        "fn_mask = (y_test_pred == 0) & (y_test == 1)\n",
        "\n",
        "# Prepare a color array for the plot\n",
        "colors = np.array([''] * len(y_test), dtype=object)\n",
        "colors[tp_mask] = 'True Positive'\n",
        "colors[fp_mask] = 'False Positive'\n",
        "colors[tn_mask] = 'True Negative'\n",
        "colors[fn_mask] = 'False Negative'\n",
        "\n",
        "# Function to plot the data using Plotly\n",
        "def plotly_tsne_classification_results(X, colors):\n",
        "    fig = px.scatter(x=X[:, 0], y=X[:, 1], color=colors,\n",
        "                     title='t-SNE Visualization of Classification Results on Test Data',\n",
        "                     labels={'color': 'Classification Result'},\n",
        "                     color_discrete_sequence=px.colors.qualitative.Set1,\n",
        "                     width=800, height=800)\n",
        "    fig.update_layout(title={'text': 't-SNE Visualization of Classification Results on Test Data',\n",
        "                            'y': 0.95, 'x': 0.5, 'xanchor': 'center', 'yanchor': 'top'})\n",
        "    fig.update_traces(marker=dict(size=9),)\n",
        "    fig.show()\n",
        "\n",
        "# Plot the classification results on test data\n",
        "plotly_tsne_classification_results(X_test_tsne, colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjMntUqEDomZ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = X_no_missing_train_reg, X_no_missing_test_reg, y_no_missing_train_reg, y_no_missing_test_reg\n",
        "\n",
        "# Define the models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"Lasso\": Lasso(),\n",
        "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
        "    \"SGD Regressor\": SGDRegressor(max_iter=1000, tol=1e-3),\n",
        "    \"XGBoost\": XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3),\n",
        "    # \"LightGBM\": LGBMRegressor(num_leaves=31, learning_rate=0.1, n_estimators=100),\n",
        "    \"CatBoost\": CatBoostRegressor(iterations=100, learning_rate=0.1, depth=3, silent=True),\n",
        "    \"SVR (RBF)\": SVR(kernel='rbf'),  # Default kernel is RBF\n",
        "    \"SVR (RBF)\": SVR(kernel='linear'),  # Default kernel is RBF\n",
        "    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n",
        "    \"Decision Tree (MSE)\": DecisionTreeRegressor(criterion='squared_error'),\n",
        "    \"Decision Tree (Friedman)\": DecisionTreeRegressor(criterion='friedman_mse'),\n",
        "    \"Decision Tree (Poisson)\": DecisionTreeRegressor(criterion='poisson'),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100),\n",
        "    \"Extra Trees\": ExtraTreesRegressor(n_estimators=100),\n",
        "    \"Gradient Boosting (Huber)\": GradientBoostingRegressor(loss='huber', n_estimators=100),\n",
        "    \"Gradient Boosting (MAE)\": GradientBoostingRegressor(loss='absolute_error', n_estimators=100),\n",
        "    \"Gradient Boosting (Quantile)\": GradientBoostingRegressor(loss='quantile', n_estimators=100),\n",
        "    \"Gradient Boosting (MSE)\": GradientBoostingRegressor(loss='squared_error', n_estimators=100),\n",
        "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100),\n",
        "    \"Bagging\": BaggingRegressor(n_estimators=100)\n",
        "}\n",
        "\n",
        "# Metrics storage\n",
        "metrics = {\n",
        "    'MAE': [],\n",
        "    'RMSE': [],\n",
        "    'MSE': [],\n",
        "    'Median AE': [],\n",
        "    'R^2': []\n",
        "}\n",
        "\n",
        "# Dictionary to store the results\n",
        "results = {}\n",
        "results_precision = {\n",
        "    \"MAE\": \".1f\",\n",
        "    \"RMSE\": \".1f\",\n",
        "    \"MSE\": \".0f\",\n",
        "    \"Median AE\": \".1f\",\n",
        "    \"R^2\": \".3f\"\n",
        "}\n",
        "\n",
        "\n",
        "# Evaluate each model\n",
        "for name, model in models.items():\n",
        "    # Fit model on training data\n",
        "    model.fit(X_train, y_train)\n",
        "    # Predict on testing data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    median_ae = np.median(np.abs(y_test - y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Store metrics in the dictionary\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'MSE': mse,\n",
        "        'Median AE': median_ae,\n",
        "        'R^2': r2\n",
        "    }\n",
        "\n",
        "# # Colors for the bar charts\n",
        "# colors = [\n",
        "#     'rgba(255, 99, 132, 0.8)', 'rgba(54, 162, 235, 0.8)', 'rgba(255, 206, 86, 0.8)',\n",
        "#     'rgba(75, 192, 192, 0.8)', 'rgba(153, 102, 255, 0.8)', 'rgba(255, 159, 64, 0.8)',\n",
        "#     'rgba(199, 199, 199, 0.8)', 'rgba(164, 194, 244, 0.8)', 'rgba(255, 218, 128, 0.8)',\n",
        "#     'rgba(255, 178, 102, 0.8)', 'rgba(179, 181, 198, 0.8)', 'rgba(77, 166, 255, 0.8)',\n",
        "#     'rgba(148, 103, 189, 0.8)'\n",
        "# ]\n",
        "\n",
        "# colors = [\n",
        "#     'rgba(255, 99, 132, 0.8)', 'rgba(54, 162, 235, 0.8)', 'rgba(255, 206, 86, 0.8)',\n",
        "#     'rgba(75, 192, 192, 0.8)', 'rgba(153, 102, 255, 0.8)', 'rgba(255, 159, 64, 0.8)',\n",
        "#     'rgba(199, 199, 199, 0.8)', 'rgba(164, 194, 244, 0.8)', 'rgba(255, 218, 128, 0.8)',\n",
        "#     'rgba(255, 178, 102, 0.8)', 'rgba(179, 181, 198, 0.8)', 'rgba(77, 166, 255, 0.8)',\n",
        "#     'rgba(148, 103, 189, 0.8)'\n",
        "# ]\n",
        "\n",
        "colors = [\n",
        "    # 'rgba(102, 194, 165, 0.8)',  # Greenish\n",
        "    'rgba(54, 162, 235, 0.8)',\n",
        "    'rgba(252, 141, 98, 0.8)',   # Orangish\n",
        "    'rgba(141, 160, 203, 0.8)',  # Blueish\n",
        "    'rgba(231, 138, 195, 0.8)',  # Pinkish\n",
        "    'rgba(166, 216, 84, 0.8)',   # Lime green\n",
        "    'rgba(255, 217, 47, 0.8)',   # Yellow\n",
        "    'rgba(77, 166, 255, 0.8)',\n",
        "    # 'rgba(229, 196, 148, 0.8)',  # Beige\n",
        "    'rgba(255, 178, 102, 0.8)',\n",
        "    # 'rgba(179, 179, 179, 0.8)',  # Gray\n",
        "    'rgba(217, 239, 139, 0.8)',  # Light green\n",
        "    'rgba(241, 182, 218, 0.8)',  # Soft pink\n",
        "    'rgba(188, 128, 189, 0.8)',  # Purple\n",
        "    'rgba(255, 99, 132, 0.8)',\n",
        "    # 'rgba(204, 235, 197, 0.8)',  # Pale green\n",
        "    'rgba(255, 188, 121, 0.8)'   # Peach\n",
        "]\n",
        "\n",
        "# Create a separate figure for each metric\n",
        "for metric in metrics.keys():\n",
        "    fig = go.Figure()\n",
        "    for i, (model, color) in enumerate(zip(results.keys(), colors)):\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=[model],\n",
        "            y=[results[model][metric]],\n",
        "            name=model,\n",
        "            marker_color=color,\n",
        "            text=[f\"{results[model][metric]:{results_precision[metric]}}\"],\n",
        "            textposition='outside'\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f'{metric} of Regression Models',\n",
        "        xaxis_title='Model',\n",
        "        yaxis_title=metric,\n",
        "        template='plotly_white',\n",
        "        barmode='group',\n",
        "        height=600,\n",
        "        width=900,\n",
        "        title_x=0.5,\n",
        "        showlegend=False  # This removes the legend\n",
        "    )\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6hXPEQVaDI5"
      },
      "outputs": [],
      "source": [
        "model = models['XGBoost']\n",
        "X_train = X_no_missing_train_reg\n",
        "\n",
        "# Create the SHAP Explainer\n",
        "explainer = shap.Explainer(model)\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "# Calculate mean absolute SHAP values for each feature\n",
        "shap_sum = np.abs(shap_values.values).mean(axis=0)\n",
        "\n",
        "# Create a Plotly bar plot\n",
        "fig = go.Figure([go.Bar(x=shap_sum, y=X_train.columns, orientation='h')])\n",
        "fig.update_layout(title='Global Feature Importance Using SHAP Values',\n",
        "                  xaxis_title='Mean Absolute SHAP Value',\n",
        "                  yaxis_title='Features',\n",
        "                  height=1200,\n",
        "                  width=1000,\n",
        "                  title_x=0.5,\n",
        "                  yaxis=dict(autorange=\"reversed\"))  # Display the highest importance at the top\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wnAjISac2Q8"
      },
      "outputs": [],
      "source": [
        "# Assuming your model and X_train are already defined and the model is trained\n",
        "model = models['XGBoost']\n",
        "X_train = X_no_missing_train_reg\n",
        "\n",
        "# Create the SHAP Explainer and calculate SHAP values\n",
        "explainer = shap.Explainer(model)\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "# Calculate the mean SHAP values for each feature\n",
        "mean_shap_values = shap_values.values.mean(axis=0)\n",
        "\n",
        "# Create a Plotly bar plot with both positive and negative values displayed on the same axis\n",
        "fig = go.Figure([go.Bar(\n",
        "    x=mean_shap_values,\n",
        "    y=X_train.columns,\n",
        "    orientation='h',\n",
        "    marker_color=np.where(mean_shap_values >= 0, 'rgba(76, 175, 80, 0.6)', 'rgba(244, 67, 54, 0.6)')  # Green for positive, red for negative\n",
        ")])\n",
        "\n",
        "# Update the layout\n",
        "fig.update_layout(\n",
        "    title='Average SHAP Values (Positive & Negative Impact)',\n",
        "    xaxis_title='Average SHAP Value',\n",
        "    yaxis_title='Features',\n",
        "    height=1200,\n",
        "    width=1000,\n",
        "    title_x=0.5,\n",
        "    yaxis=dict(autorange=\"reversed\")  # Display the highest importance at the top\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOHSawlkdRqy"
      },
      "outputs": [],
      "source": [
        "original_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fDWo82XtmxO"
      },
      "outputs": [],
      "source": [
        "!pip install networkx\n",
        "!pip install torch\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFF9JivXtqLd"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import GINConv, Sequential\n",
        "from torch_geometric.nn import MLP\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
        "from torch_geometric.nn import GINConv, Sequential, Linear\n",
        "from tqdm import tqdm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA2RZrFHhjKc"
      },
      "source": [
        "# Data cleaning and preparation for the deep model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ--wuxVf9mX"
      },
      "outputs": [],
      "source": [
        "deep_df_no_missing = status_filtered_df.dropna(thresh=status_filtered_df.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_jsQ3m6gwp9"
      },
      "outputs": [],
      "source": [
        "deep_df_no_missing['cohort_tag'] = deep_df_no_missing['cohort_tag'].str[:-1]\n",
        "deep_df_no_missing['cohort_date'] = pd.to_datetime(deep_df_no_missing['cohort_tag'], format='%b%y')\n",
        "covid_start = pd.to_datetime('2020-03-01')\n",
        "covid_end = pd.to_datetime('2021-09-30')\n",
        "deep_df_no_missing['is_covid'] = ((deep_df_no_missing['cohort_date'] >= covid_start) & (deep_df_no_missing['cohort_date'] <= covid_end)).astype(int)\n",
        "deep_df_no_missing[\"starting_month\"] = deep_df_no_missing['cohort_tag'].str.slice(0, 3)\n",
        "deep_df_no_missing.drop(columns=['cohort_tag', 'cohort_date', 'id', 'pathrise_status'], inplace=True)\n",
        "y_deep_df_no_missing_regression = deep_df_no_missing['program_duration_days']  # target for regression\n",
        "y_deep_df_no_missing_classification = deep_df_no_missing['placed']  # target for classification\n",
        "x_deep_df_no_missing = deep_df_no_missing.drop(columns=['program_duration_days', 'placed'], inplace=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJxBSOnmqjuJ"
      },
      "source": [
        "# Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G72XwDkxhh0r"
      },
      "outputs": [],
      "source": [
        "categorical_columns = [\n",
        "    'primary_track', 'employment_status ', 'highest_level_of_education',\n",
        "    'length_of_job_search', 'biggest_challenge_in_search', 'professional_experience',\n",
        "    'work_authorization_status', 'gender', 'race', 'starting_month'\n",
        "]\n",
        "\n",
        "# Create a copy of the DataFrame to apply label encoding\n",
        "encoded_df = x_deep_df_no_missing.copy()\n",
        "\n",
        "# Apply Label Encoding to each categorical column\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    encoded_df[column] = le.fit_transform(x_deep_df_no_missing[column])\n",
        "    label_encoders[column] = le  # Store encoder to inverse transform or for further reference\n",
        "\n",
        "x_deep_df_encoded_no_missing = encoded_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw94x3CvrNbG"
      },
      "outputs": [],
      "source": [
        "df = x_deep_df_encoded_no_missing[['number_of_interviews', 'number_of_applications']]\n",
        "\n",
        "# Create a graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes\n",
        "for index in df.index:\n",
        "    G.add_node(index, interviews=df.loc[index, 'number_of_interviews'], applications=df.loc[index, 'number_of_applications'])\n",
        "\n",
        "# Add edges based on the conditions specified\n",
        "for i in df.index:\n",
        "    for j in df.index:\n",
        "        if i != j:\n",
        "            diff_interviews = abs(df.loc[i, 'number_of_interviews'] - df.loc[j, 'number_of_interviews'])\n",
        "            diff_applications = abs(df.loc[i, 'number_of_applications'] - df.loc[j, 'number_of_applications'])\n",
        "            if diff_interviews <= 1 and diff_applications <= 10:\n",
        "                G.add_edge(i, j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zv8uwD1Ru17v"
      },
      "outputs": [],
      "source": [
        "x_deep_df_encoded_no_missing_graphed = x_deep_df_encoded_no_missing.drop(columns=['number_of_interviews', 'number_of_applications'], inplace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrN3OMSM4xtS"
      },
      "outputs": [],
      "source": [
        "# Convert DataFrame to tensor\n",
        "x_deep_df_encoded_no_missing_graphed = x_deep_df_encoded_no_missing_graphed.apply(pd.to_numeric, errors='coerce')\n",
        "x_tensor = torch.tensor(x_deep_df_encoded_no_missing_graphed.values, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_deep_df_no_missing_classification.values, dtype=torch.long)  # Adjust if 'placed' is not the correct column\n",
        "\n",
        "# Create the graph data object\n",
        "pyg_graph = Data(x=x_tensor, y=y_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkJpNjhl8NYj"
      },
      "outputs": [],
      "source": [
        "unique_labels, label_counts = pyg_graph.y.unique(return_counts=True)\n",
        "label_to_indices = {label.item(): (pyg_graph.y == label).nonzero().view(-1) for label in unique_labels}\n",
        "\n",
        "train_indices = []\n",
        "test_indices = []\n",
        "\n",
        "test_ratio = 0.2\n",
        "\n",
        "for label, indices in label_to_indices.items():\n",
        "    # Shuffle indices\n",
        "    permuted_indices = indices[torch.randperm(indices.size(0))]\n",
        "    test_size = int(len(permuted_indices) * test_ratio)\n",
        "\n",
        "    test_indices.append(permuted_indices[:test_size])\n",
        "    train_indices.append(permuted_indices[test_size:])\n",
        "\n",
        "train_indices = torch.cat(train_indices)\n",
        "test_indices = torch.cat(test_indices)\n",
        "\n",
        "# Create train_mask and test_mask\n",
        "train_mask = torch.zeros(pyg_graph.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(pyg_graph.num_nodes, dtype=torch.bool)\n",
        "\n",
        "train_mask[train_indices] = True\n",
        "test_mask[test_indices] = True\n",
        "\n",
        "# Assign masks to the graph data\n",
        "pyg_graph.train_mask = train_mask\n",
        "pyg_graph.test_mask = test_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjboTr8U8dHJ"
      },
      "outputs": [],
      "source": [
        "pyg_graph = from_networkx(G)\n",
        "edge_index = pyg_graph.edge_index\n",
        "pyg_graph = Data(x=x_tensor, y=y_tensor, edge_index=edge_index, train_mask=train_mask, test_mask=test_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAPDRNdF990v"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 16)\n",
        "        self.conv2 = GCNConv(16, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # First GCN layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        # Second GCN layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pu_-ioXI3mt"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 16)\n",
        "        # self.conv2 = GCNConv(16, 16)  # Now both layers output 16 features\n",
        "        self.classifier = torch.nn.Linear(16, num_classes)  # Reduce dimension to number of classes\n",
        "        # self.dropout = torch.nn.Dropout(0.4)  # Define dropout layer\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # First GCN layer\n",
        "        x1 = self.conv1(x, edge_index)\n",
        "        x1 = F.relu(x1)\n",
        "        # x1 = self.dropout(x1)\n",
        "\n",
        "        # Second GCN layer with a skip connection\n",
        "        # x2 = self.conv2(x1, edge_index)\n",
        "        # x_out = x1 + x2  # Skip connection (now valid as dimensions match)\n",
        "        x_out = x1\n",
        "        x_out = F.relu(x_out)\n",
        "        # x_out = self.dropout(x_out)\n",
        "\n",
        "        # Final classification layer\n",
        "        x_out = self.classifier(x_out)\n",
        "        return F.log_softmax(x_out, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvbHZSy8qr3g"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 64)\n",
        "        self.conv2 = GCNConv(64, 64)\n",
        "        self.lin = torch.nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.lin(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFxttb-CDE7x"
      },
      "outputs": [],
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GAT, self).__init__()\n",
        "        # First GAT layer\n",
        "        self.conv1 = GATConv(num_features, 8, heads=8, dropout=0.6)\n",
        "        # On the first layer we use multi-head attention; 8 heads, each head adds 8 output features\n",
        "        # Resulting in 8*8 = 64 features per node\n",
        "\n",
        "        # Second GAT layer, multi-class classification\n",
        "        self.conv2 = GATConv(8*8, num_classes, heads=1, concat=False, dropout=0.6)\n",
        "        # The second layer has a single attention head and does not concatenate the output from different heads,\n",
        "        # Hence we map directly to the number of classes.\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Input features passed through the first GAT layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)  # ELU activation\n",
        "        x = F.dropout(x, p=0.6, training=self.training)  # Dropout for regularization\n",
        "\n",
        "        # Output from first layer passed through the second GAT layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)  # Softmax used for multi-class classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXBrznSP-C0m"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN(num_features=pyg_graph.num_node_features, num_classes=len(pyg_graph.y.unique())).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "pyg_graph = pyg_graph.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV81LoDT-Fks"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "for epoch in range(500):  # Number of epochs\n",
        "    optimizer.zero_grad()\n",
        "    out = model(pyg_graph)\n",
        "    loss = F.nll_loss(out[pyg_graph.train_mask], pyg_graph.y[pyg_graph.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FM3fIba-Hil"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "_, pred = model(pyg_graph).max(dim=1)\n",
        "correct = int((pred[pyg_graph.test_mask] == pyg_graph.y[pyg_graph.test_mask]).sum())\n",
        "accuracy = correct / int(pyg_graph.test_mask.sum())\n",
        "\n",
        "\n",
        "def evaluate_model(model, data, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)  # Get the model's logit outputs\n",
        "        preds = logits[mask].max(1)[1]  # Extract the predicted class labels based on the logits\n",
        "        labels = data.y[mask]  # Get the actual labels\n",
        "        return preds, labels, logits[mask]  # Return predictions, actual labels, and logits for the specified mask\n",
        "\n",
        "\n",
        "def calculate_metrics(preds, labels, logits):\n",
        "    accuracy = accuracy_score(labels.cpu(), preds.cpu())\n",
        "    precision = precision_score(labels.cpu(), preds.cpu(), average='binary')\n",
        "    recall = recall_score(labels.cpu(), preds.cpu(), average='binary')\n",
        "    f1 = f1_score(labels.cpu(), preds.cpu(), average='binary')\n",
        "    macro_f1 = f1_score(labels.cpu(), preds.cpu(), average='macro')\n",
        "\n",
        "    # Calculating ROC AUC only if binary classification and there are positive class probabilities\n",
        "    if len(torch.unique(labels)) == 2:  # Only compute ROC AUC if binary classification\n",
        "        roc_auc = roc_auc_score(labels.cpu(), torch.softmax(logits, dim=1)[:, 1].cpu())\n",
        "    else:\n",
        "        roc_auc = None\n",
        "\n",
        "    return accuracy, precision, recall, f1, macro_f1, roc_auc\n",
        "\n",
        "# Calculate Training Metrics\n",
        "train_preds, train_labels, train_logits = evaluate_model(model, pyg_graph, pyg_graph.train_mask)\n",
        "train_accuracy, _, _, _, _, _ = calculate_metrics(train_preds, train_labels, train_logits)\n",
        "\n",
        "# Calculate Testing Metrics\n",
        "test_preds, test_labels, test_logits = evaluate_model(model, pyg_graph, pyg_graph.test_mask)\n",
        "test_accuracy, test_precision, test_recall, test_f1, test_macro_f1, test_roc_auc = calculate_metrics(test_preds, test_labels, test_logits)\n",
        "\n",
        "# Output the results\n",
        "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "print(f'Test Precision: {test_precision:.4f}')\n",
        "print(f'Test Recall: {test_recall:.4f}')\n",
        "print(f'Test F1: {test_f1:.4f}')\n",
        "print(f'Test Macro F1: {test_macro_f1:.4f}')\n",
        "if test_roc_auc:\n",
        "    print(f'Test ROC AUC: {test_roc_auc:.4f}')\n",
        "else:\n",
        "    print(\"ROC AUC not applicable.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIg1KpaqCzG4"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GAT(num_features=pyg_graph.num_node_features, num_classes=len(pyg_graph.y.unique())).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "pyg_graph = pyg_graph.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgzQeL6xDNZ9"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(pyg_graph)\n",
        "    loss = F.nll_loss(out[pyg_graph.train_mask], pyg_graph.y[pyg_graph.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch+1}: Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSIZBU9uDPli"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits[mask].max(1)[1]\n",
        "        labels = data.y[mask]\n",
        "        return preds, labels, logits[mask]  # Return predictions, actual labels, and logits for the specified mask\n",
        "\n",
        "def calculate_metrics(preds, labels, logits):\n",
        "    accuracy = accuracy_score(labels.cpu(), preds.cpu())\n",
        "    precision = precision_score(labels.cpu(), preds.cpu(), average='binary')\n",
        "    recall = recall_score(labels.cpu(), preds.cpu(), average='binary')\n",
        "    f1 = f1_score(labels.cpu(), preds.cpu(), average='binary')\n",
        "    macro_f1 = f1_score(labels.cpu(), preds.cpu(), average='macro')\n",
        "\n",
        "    # Calculating ROC AUC only if binary classification\n",
        "    if len(torch.unique(labels)) == 2:  # Only compute ROC AUC if binary classification\n",
        "        roc_auc = roc_auc_score(labels.cpu(), torch.softmax(logits, dim=1)[:, 1].cpu())\n",
        "    else:\n",
        "        roc_auc = None\n",
        "\n",
        "    return accuracy, precision, recall, f1, macro_f1, roc_auc\n",
        "\n",
        "# Example usage after the model has been trained\n",
        "# Evaluate on training data\n",
        "train_preds, train_labels, train_logits = evaluate_model(model, pyg_graph, pyg_graph.train_mask)\n",
        "train_accuracy, _, _, _, _, _ = calculate_metrics(train_preds, train_labels, train_logits)\n",
        "\n",
        "# Evaluate on testing data\n",
        "test_preds, test_labels, test_logits = evaluate_model(model, pyg_graph, pyg_graph.test_mask)\n",
        "test_accuracy, test_precision, test_recall, test_f1, test_macro_f1, test_roc_auc = calculate_metrics(test_preds, test_labels, test_logits)\n",
        "\n",
        "# Print results\n",
        "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "print(f'Test Precision: {test_precision:.4f}')\n",
        "print(f'Test Recall: {test_recall:.4f}')\n",
        "print(f'Test F1: {test_f1:.4f}')\n",
        "print(f'Test Macro F1: {test_macro_f1:.4f}')\n",
        "if test_roc_auc:\n",
        "    print(f'Test ROC AUC: {test_roc_auc:.4f}')\n",
        "else:\n",
        "    print(\"ROC AUC not applicable.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XUn8R9XMpqQ"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(num_features, 16, normalize=True, aggr='mean')  # Use mean aggregation\n",
        "        self.conv2 = SAGEConv(16, num_classes, normalize=True, aggr='mean')\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # First GraphSAGE layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        # Second GraphSAGE layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBfPQtHFrLY2"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(num_features, 64)\n",
        "        self.conv2 = SAGEConv(64, 64)\n",
        "        self.lin = torch.nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.lin(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FdmtbRoPoBi"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GraphSAGE(num_features=pyg_graph.num_node_features, num_classes=len(pyg_graph.y.unique())).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "pyg_graph = pyg_graph.to(device)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(700):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(pyg_graph)\n",
        "    loss = F.nll_loss(out[pyg_graph.train_mask], pyg_graph.y[pyg_graph.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}: Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IECojVkYPsZF"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits[mask].max(1)[1]\n",
        "        labels = data.y[mask]\n",
        "        return preds, labels, logits[mask]  # Return predictions, actual labels, and logits for the specified mask\n",
        "\n",
        "def calculate_metrics(preds, labels, logits):\n",
        "    accuracy = accuracy_score(labels.cpu(), preds.cpu())\n",
        "    precision = precision_score(labels.cpu(), preds.cpu(), average='binary')\n",
        "    recall = recall_score(labels.cpu(), preds.cpu(), average='binary')\n",
        "    f1 = f1_score(labels.cpu(), preds.cpu(), average='binary')\n",
        "    macro_f1 = f1_score(labels.cpu(), preds.cpu(), average='macro')\n",
        "\n",
        "    # Calculating ROC AUC only if binary classification and if there are positive class probabilities\n",
        "    if len(torch.unique(labels)) == 2:  # Only compute ROC AUC if binary classification\n",
        "        roc_auc = roc_auc_score(labels.cpu(), torch.softmax(logits, dim=1)[:, 1].cpu())\n",
        "    else:\n",
        "        roc_auc = None\n",
        "\n",
        "    return accuracy, precision, recall, f1, macro_f1, roc_auc\n",
        "\n",
        "train_preds, train_labels, train_logits = evaluate_model(model, pyg_graph, pyg_graph.train_mask)\n",
        "train_accuracy, _, _, _, _, _ = calculate_metrics(train_preds, train_labels, train_logits)\n",
        "\n",
        "# Evaluate on testing data\n",
        "test_preds, test_labels, test_logits = evaluate_model(model, pyg_graph, pyg_graph.test_mask)\n",
        "test_accuracy, test_precision, test_recall, test_f1, test_macro_f1, test_roc_auc = calculate_metrics(test_preds, test_labels, test_logits)\n",
        "\n",
        "# Output the results\n",
        "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "print(f'Test Precision: {test_precision:.4f}')\n",
        "print(f'Test Recall: {test_recall:.4f}')\n",
        "print(f'Test F1: {test_f1:.4f}')\n",
        "print(f'Test Macro F1: {test_macro_f1:.4f}')\n",
        "if test_roc_auc:\n",
        "    print(f'Test ROC AUC: {test_roc_auc:.4f}')\n",
        "else:\n",
        "    print(\"ROC AUC not applicable.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ-SSmsrQYwT"
      },
      "outputs": [],
      "source": [
        "class DiffGCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(DiffGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 64, improved=True)\n",
        "        self.conv2 = GCNConv(64, 64, improved=True)\n",
        "        self.lin = torch.nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.lin(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuPYII6mRhys"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = DiffGCN(num_features=pyg_graph.num_node_features, num_classes=len(pyg_graph.y.unique())).to(device)\n",
        "pyg_graph = pyg_graph.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.NLLLoss()\n",
        "\n",
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate_model(model, data, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits[mask].max(1)[1]\n",
        "        labels = data.y[mask]\n",
        "\n",
        "        # Calculating metrics\n",
        "        accuracy = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n",
        "        precision = precision_score(labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
        "        recall = recall_score(labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
        "        f1 = f1_score(labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
        "        macro_f1 = f1_score(labels.cpu().numpy(), preds.cpu().numpy(), average='macro')\n",
        "\n",
        "        # Calculate ROC AUC if binary classification\n",
        "        roc_auc = None\n",
        "        if len(labels.unique()) == 2:\n",
        "            roc_auc = roc_auc_score(labels.cpu().numpy(), F.softmax(logits[mask], dim=1).cpu().numpy()[:, 1])\n",
        "\n",
        "        return accuracy, precision, recall, f1, macro_f1, roc_auc\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(600):\n",
        "    loss = train(model, pyg_graph, optimizer, criterion)\n",
        "    if epoch % 10 == 0:\n",
        "        train_acc = evaluate_model(model, pyg_graph, pyg_graph.train_mask)\n",
        "        test_acc = evaluate_model(model, pyg_graph, pyg_graph.test_mask)\n",
        "        print(f'Epoch: {epoch}, Loss: {loss:.4f}')\n",
        "\n",
        "# Assuming your model and data are setup and this function is called after model training\n",
        "train_accuracy, train_precision, train_recall, train_f1, train_macro_f1, train_roc_auc = evaluate_model(model, pyg_graph, pyg_graph.train_mask)\n",
        "test_accuracy, test_precision, test_recall, test_f1, test_macro_f1, test_roc_auc = evaluate_model(model, pyg_graph, pyg_graph.test_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qSIrJzSRkQ4"
      },
      "outputs": [],
      "source": [
        "# Output the results\n",
        "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "print(f'Test Precision: {test_precision:.4f}')\n",
        "print(f'Test Recall: {test_recall:.4f}')\n",
        "print(f'Test F1: {test_f1:.4f}')\n",
        "print(f'Test Macro F1: {test_macro_f1:.4f}')\n",
        "if test_roc_auc:\n",
        "    print(f'Test ROC AUC: {test_roc_auc:.4f}')\n",
        "else:\n",
        "    print(\"ROC AUC not applicable.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqttRm94S5i-"
      },
      "outputs": [],
      "source": [
        "class GIN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GIN, self).__init__()\n",
        "        nn1 = MLP([num_features, 64, 64])\n",
        "        self.conv1 = GINConv(nn1, train_eps=True)\n",
        "        nn2 = MLP([64, 64, 64])\n",
        "        self.conv2 = GINConv(nn2, train_eps=True)\n",
        "        self.lin = torch.nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, data, return_embed=False):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        if return_embed:\n",
        "            return x  # Return embeddings before the classifier\n",
        "        x = self.lin(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmcgtCQZh0OT"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate_model(model, data, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)  # Get logits from the model\n",
        "        preds = logits[mask].max(1)[1]  # Get the predicted classes\n",
        "        labels = data.y[mask]  # Actual labels\n",
        "        return preds, labels, logits[mask]  # Ensure to return exactly these three items\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GIN(num_features=pyg_graph.num_node_features, num_classes=len(pyg_graph.y.unique())).to(device)\n",
        "pyg_graph  = pyg_graph.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.NLLLoss()\n",
        "\n",
        "num_epochs = 600\n",
        "for epoch in range(num_epochs):\n",
        "    loss = train(model, optimizer, criterion, pyg_graph)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}: Loss {loss:.4f}')\n",
        "\n",
        "# Evaluate after training\n",
        "train_preds, train_labels, train_logits = evaluate_model(model, pyg_graph, pyg_graph.train_mask)\n",
        "train_accuracy, _, _, _, _, _ = calculate_metrics(train_preds, train_labels, train_logits)\n",
        "\n",
        "test_preds, test_labels, test_logits = evaluate_model(model, pyg_graph, pyg_graph.test_mask)\n",
        "test_accuracy, test_precision, test_recall, test_f1, test_macro_f1, test_roc_auc = calculate_metrics(test_preds, test_labels, test_logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAkq4OJ2jAA0"
      },
      "outputs": [],
      "source": [
        "# Print results\n",
        "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "print(f'Test Precision: {test_precision:.4f}')\n",
        "print(f'Test Recall: {test_recall:.4f}')\n",
        "print(f'Test F1: {test_f1:.4f}')\n",
        "print(f'Test Macro F1: {test_macro_f1:.4f}')\n",
        "if test_roc_auc:\n",
        "    print(f'Test ROC AUC: {test_roc_auc:.4f}')\n",
        "else:\n",
        "    print(\"ROC AUC not applicable.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Aog6up9Amzw"
      },
      "outputs": [],
      "source": [
        "# Print results\n",
        "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "print(f'Test Precision: {test_precision:.4f}')\n",
        "print(f'Test Recall: {test_recall:.4f}')\n",
        "print(f'Test F1: {test_f1:.4f}')\n",
        "print(f'Test Macro F1: {test_macro_f1:.4f}')\n",
        "if test_roc_auc:\n",
        "    print(f'Test ROC AUC: {test_roc_auc:.4f}')\n",
        "else:\n",
        "    print(\"ROC AUC not applicable.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD0KY-tpAlFO"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = model(pyg_graph, return_embed=True).detach().cpu().numpy()\n",
        "\n",
        "# Apply t-SNE to reduce dimensionality of embeddings\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=300, n_iter=3000)\n",
        "tsne_results = tsne.fit_transform(embeddings)\n",
        "\n",
        "# Prepare labels and their corresponding names\n",
        "labels = pyg_graph.y.cpu().numpy()\n",
        "category_names = ['Not Placed', 'Placed']\n",
        "\n",
        "# Create a DataFrame to hold the t-SNE results and labels\n",
        "df = pd.DataFrame({\n",
        "    'TSNE-1': tsne_results[:, 0],\n",
        "    'TSNE-2': tsne_results[:, 1],\n",
        "    'Status': [category_names[label] for label in labels]\n",
        "})\n",
        "\n",
        "# Generate the scatter plot using Plotly\n",
        "fig = px.scatter(\n",
        "    df, x='TSNE-1', y='TSNE-2', color='Status',\n",
        "    title='t-SNE Visualization of GIN Embeddings',\n",
        "    labels={'TSNE-1': 't-SNE Dimension 1', 'TSNE-2': 't-SNE Dimension 2'},\n",
        "    color_discrete_sequence=px.colors.qualitative.D3  # Adjust the color scale as needed\n",
        ")\n",
        "\n",
        "# Update plot settings to enhance appearance\n",
        "fig.update_traces(marker=dict(size=8, line=dict(width=0, color='DarkSlateGrey')),\n",
        "                  selector=dict(mode='markers'))\n",
        "fig.update_layout(\n",
        "    height=800,\n",
        "    width=800,\n",
        "    title_x=0.5\n",
        ")\n",
        "\n",
        "# Display the plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P2s9c9QC-Cc"
      },
      "outputs": [],
      "source": [
        "# Assuming model and pyg_graph are properly defined and loaded\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = model(pyg_graph, return_embed=True).detach().cpu().numpy()\n",
        "    input_features = pyg_graph.x.detach().cpu().numpy()  # Assuming pyg_graph.x are the input features\n",
        "\n",
        "# Apply t-SNE to the model embeddings\n",
        "tsne_model = TSNE(n_components=2, random_state=42, perplexity=300, n_iter=3000)\n",
        "tsne_results_model = tsne_model.fit_transform(embeddings)\n",
        "\n",
        "# Apply t-SNE to the original input features\n",
        "tsne_input = TSNE(n_components=2, random_state=42, perplexity=300, n_iter=3000)\n",
        "tsne_results_input = tsne_input.fit_transform(input_features)\n",
        "\n",
        "# Creating a contrasting color scheme for binary categories\n",
        "colors = ['rgba(255, 22, 84, 0.8)', 'rgba(34, 150, 243, 0.8)']  # Pink and Blue RGBA colors\n",
        "color_map = {0: colors[0], 1: colors[1]}  # Mapping labels to colors\n",
        "\n",
        "# Create subplot layout\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"t-SNE of Model Embeddings\", \"t-SNE of Original Features\"))\n",
        "\n",
        "# Add scatter plot for model embeddings\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=tsne_results_model[:, 0], y=tsne_results_model[:, 1], mode='markers',\n",
        "               marker=dict(color=[color_map[label] for label in labels], size=8, line=dict(width=0, color='DarkSlateGrey')),\n",
        "               name='Embeddings', showlegend=False),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Add scatter plot for original input features\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=tsne_results_input[:, 0], y=tsne_results_input[:, 1], mode='markers',\n",
        "               marker=dict(color=[color_map[label] for label in labels], size=8, line=dict(width=0, color='DarkSlateGrey')),\n",
        "               name='Input Features', showlegend=False),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Update layout to enhance aesthetics\n",
        "fig.update_layout(\n",
        "    height=600, width=1200,\n",
        "    title_text=\"Comparison of t-SNE Projections\",\n",
        "    title_x=0.5,  # Center the main title\n",
        "    plot_bgcolor='white',  # Set background color to white\n",
        "    showlegend=False  # Ensure legend is not shown\n",
        ")\n",
        "\n",
        "# Update axes properties\n",
        "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', gridcolor='lightgrey')\n",
        "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', gridcolor='lightgrey')\n",
        "\n",
        "# Display the plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtYHfZQb4O5j"
      },
      "outputs": [],
      "source": [
        "def feature_importance(model, data):\n",
        "    model.eval()\n",
        "    data = data.clone()  # Clone data to avoid changes to the original data\n",
        "    data.x.requires_grad = True  # Enable gradient computation for input features\n",
        "\n",
        "    logits = model(data)  # Forward pass\n",
        "    pred_class = logits.argmax(dim=-1)\n",
        "    one_hot = torch.zeros_like(logits).scatter(1, pred_class.view(-1, 1), 1)\n",
        "    logits.backward(one_hot)  # Compute gradients with respect to predicted class\n",
        "\n",
        "    grads = data.x.grad  # Extract gradients\n",
        "    feature_importances = grads.abs().mean(dim=0)  # Average gradient magnitude across all examples\n",
        "    return feature_importances\n",
        "\n",
        "importance = feature_importance(model, pyg_graph)\n",
        "print(\"Feature Importance:\", importance)\n",
        "feature_names = x_deep_df_no_missing.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v9tdoDw5l9V"
      },
      "outputs": [],
      "source": [
        "importance_numpy = importance.detach().cpu().numpy() if isinstance(importance, torch.Tensor) else importance\n",
        "\n",
        "# Ensure the number of feature names matches the number of importance scores\n",
        "feature_names = x_deep_df_encoded_no_missing_graphed.columns.tolist()\n",
        "assert len(feature_names) == len(importance_numpy), \"The number of features must match the number of importance scores.\"\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importance_numpy\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance for better visualization\n",
        "importance_df.sort_values('Importance', ascending=True, inplace=True)\n",
        "\n",
        "# Create a bar chart with color scale\n",
        "fig = px.bar(importance_df, x='Importance', y='Feature', orientation='h',\n",
        "             title='Feature Importance from GIN Model',\n",
        "             labels={'Importance': 'Importance', 'Feature': 'Features'},\n",
        "             width=800, height=600,  # Adjust size as needed\n",
        "             color='Importance'  # Color the bars by their importance value\n",
        "\n",
        ")  # Use a color scale, can be adjusted\n",
        "\n",
        "# Show color scale\n",
        "fig.update_layout(coloraxis_showscale=True, title_x=0.5)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Rq1WeO2cBQ"
      },
      "source": [
        "# Data Preparation for the Regression Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PPDQ9B1sygE"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchinfo imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj4CuNOZs11e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.tensorflow import balanced_batch_generator\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9L8QRWS_Kzg"
      },
      "outputs": [],
      "source": [
        "# Convert DataFrame to tensor\n",
        "x_deep_df_encoded_no_missing_graphed = x_deep_df_encoded_no_missing_graphed.apply(pd.to_numeric, errors='coerce')\n",
        "x_tensor = torch.tensor(x_deep_df_encoded_no_missing_graphed.values, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_deep_df_no_missing_regression.values, dtype=torch.float32).squeeze()\n",
        "\n",
        "# Create the graph data object\n",
        "pyg_graph = Data(x=x_tensor, y=y_tensor)\n",
        "\n",
        "unique_labels, label_counts = pyg_graph.y.unique(return_counts=True)\n",
        "label_to_indices = {label.item(): (pyg_graph.y == label).nonzero().view(-1) for label in unique_labels}\n",
        "\n",
        "train_indices = []\n",
        "test_indices = []\n",
        "\n",
        "test_ratio = 0.2\n",
        "\n",
        "for label, indices in label_to_indices.items():\n",
        "    # Shuffle indices\n",
        "    permuted_indices = indices[torch.randperm(indices.size(0))]\n",
        "    test_size = int(len(permuted_indices) * test_ratio)\n",
        "\n",
        "    test_indices.append(permuted_indices[:test_size])\n",
        "    train_indices.append(permuted_indices[test_size:])\n",
        "\n",
        "train_indices = torch.cat(train_indices)\n",
        "test_indices = torch.cat(test_indices)\n",
        "\n",
        "# Create train_mask and test_mask\n",
        "train_mask = torch.zeros(pyg_graph.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(pyg_graph.num_nodes, dtype=torch.bool)\n",
        "\n",
        "train_mask[train_indices] = True\n",
        "test_mask[test_indices] = True\n",
        "\n",
        "# Assign masks to the graph data\n",
        "pyg_graph.train_mask = train_mask\n",
        "pyg_graph.test_mask = test_mask\n",
        "\n",
        "pyg_graph = from_networkx(G)\n",
        "edge_index = pyg_graph.edge_index\n",
        "pyg_graph = Data(x=x_tensor, y=y_tensor, edge_index=edge_index, train_mask=train_mask, test_mask=test_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqWLC94M4SOM"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, output_features):\n",
        "        super(GCN, self).__init__()\n",
        "        # MLP-like structure before the first GCN layer\n",
        "        self.pre_mlp = Sequential('x, edge_index', [\n",
        "            (Linear(num_features, 64), 'x -> x'),\n",
        "            (Linear(64, 64), 'x -> x')\n",
        "        ])\n",
        "\n",
        "        # First GCN layer\n",
        "        self.conv1 = GCNConv(64, 64)\n",
        "\n",
        "        # MLP-like structure after the first GCN layer\n",
        "        self.post_mlp = Sequential('x, edge_index', [\n",
        "            (Linear(64, 64), 'x -> x'),\n",
        "            (Linear(64, 64), 'x -> x')\n",
        "        ])\n",
        "\n",
        "        # Second GCN layer\n",
        "        self.conv2 = GCNConv(64, output_features)\n",
        "\n",
        "    def forward(self, data, return_embed=False):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Apply MLP before the first GCN layer\n",
        "        x = F.relu(self.pre_mlp(x, edge_index))\n",
        "\n",
        "        # Apply the first GCN layer\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Apply MLP after the first GCN layer\n",
        "        x = F.relu(self.post_mlp(x, edge_index))\n",
        "\n",
        "        # Apply the second GCN layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        if return_embed:\n",
        "            return x.squeeze()  # Optionally return embeddings before the final transformation\n",
        "        return x.squeeze()  # For regression, remove any softmax or log_softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2wLh_H_8GKK"
      },
      "outputs": [],
      "source": [
        "# class GIN(torch.nn.Module):\n",
        "#     def __init__(self, num_features, output_features):\n",
        "#         super(GIN, self).__init__()\n",
        "#         # Define MLP for the first GIN convolution layer\n",
        "#         self.mlp1 = Sequential('x, edge_index', [\n",
        "#             (Linear(num_features, 64), 'x -> x'),\n",
        "#             (Linear(64, 64), 'x -> x')\n",
        "#         ])\n",
        "#         self.conv1 = GINConv(self.mlp1, train_eps=True)\n",
        "\n",
        "#         # Define MLP for the second GIN convolution layer\n",
        "#         self.mlp2 = Sequential('x, edge_index', [\n",
        "#             (Linear(64, 64), 'x -> x'),\n",
        "#             (Linear(64, 64), 'x -> x')\n",
        "#         ])\n",
        "#         self.conv2 = GINConv(self.mlp2, train_eps=True)\n",
        "\n",
        "#         # Output linear layer\n",
        "#         self.lin = Linear(64, output_features)\n",
        "\n",
        "#     def forward(self, data, return_embed=False):\n",
        "#         x, edge_index = data.x, data.edge_index\n",
        "#         x = F.relu(self.conv1(x, edge_index))\n",
        "#         x = F.dropout(x, p=0.5, training=self.training)\n",
        "#         x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "#         if return_embed:\n",
        "#             return x  # Optionally return embeddings before the final linear layer\n",
        "#         x = self.lin(x)\n",
        "#         return x.squeeze()  # Directly return output for regression, no softmax\n",
        "\n",
        "class GIN(torch.nn.Module):\n",
        "    def __init__(self, num_features, output_features):\n",
        "        super(GIN, self).__init__()\n",
        "\n",
        "        # Define the MLP that will be used in the first GINConv layer\n",
        "        self.mlp1 = MLP([num_features, 64, 64])\n",
        "        # The first GIN convolution layer, using the MLP defined above\n",
        "        self.conv1 = GINConv(self.mlp1, train_eps=True)\n",
        "\n",
        "        # Define the MLP for the second GINConv layer\n",
        "        self.mlp2 = MLP([64, 64, 64])\n",
        "        # The second GIN convolution layer, using the second MLP\n",
        "        self.conv2 = GINConv(self.mlp2, train_eps=True)\n",
        "\n",
        "        # Final linear layer for regression\n",
        "        self.lin = torch.nn.Linear(64, output_features)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.lin(x)  # No activation function here since it's a regression task\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps_M-M4X8vVV"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, num_features, output_features):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "\n",
        "        # MLP before the first GraphSAGE convolution layer\n",
        "        self.pre_mlp = Sequential('x, edge_index', [\n",
        "            (Linear(num_features, 64), 'x -> x'),\n",
        "            (Linear(64, 64), 'x -> x')\n",
        "        ])\n",
        "\n",
        "        # First GraphSAGE convolution layer\n",
        "        self.conv1 = SAGEConv(64, 64)\n",
        "\n",
        "        # MLP after the first GraphSAGE convolution layer and before the second\n",
        "        self.post_mlp1 = Sequential('x, edge_index', [\n",
        "            (Linear(64, 64), 'x -> x'),\n",
        "            (Linear(64, 64), 'x -> x')\n",
        "        ])\n",
        "\n",
        "        # Second GraphSAGE convolution layer\n",
        "        self.conv2 = SAGEConv(64, 64)\n",
        "\n",
        "        # MLP after the second GraphSAGE convolution layer\n",
        "        self.post_mlp2 = Sequential('x, edge_index', [\n",
        "            (Linear(64, 64), 'x -> x'),\n",
        "            (Linear(64, output_features), 'x -> x')\n",
        "        ])\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Process through the first MLP and GraphSAGE layer\n",
        "        x = F.relu(self.pre_mlp(x, edge_index))\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Process through the second MLP and GraphSAGE layer\n",
        "        x = F.relu(self.post_mlp1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Final MLP processing\n",
        "        x = self.post_mlp2(x, edge_index)\n",
        "        return x.squeeze()  # Output for regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxfG3V-S9Gw3"
      },
      "outputs": [],
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, num_features, output_features):\n",
        "        super(GAT, self).__init__()\n",
        "\n",
        "        # MLP before the first GAT convolution layer\n",
        "        self.pre_mlp = Sequential('x, edge_index', [\n",
        "            (Linear(num_features, 64), 'x -> x'),\n",
        "            (Linear(64, 64), 'x -> x')\n",
        "        ])\n",
        "\n",
        "        # First GAT convolution layer\n",
        "        self.conv1 = GATConv(64, 64, heads=4, concat=True)\n",
        "\n",
        "        # MLP after the first GAT convolution layer and before the second\n",
        "        self.post_mlp1 = Sequential('x, edge_index', [\n",
        "            (Linear(64*4, 64), 'x -> x'),  # Multiply by number of heads if concat is True\n",
        "            (Linear(64, 64), 'x -> x')\n",
        "        ])\n",
        "\n",
        "        # Second GAT convolution layer\n",
        "        self.conv2 = GATConv(64, 64, heads=4, concat=False)  # Use concat=False for the last layer to match output_features\n",
        "\n",
        "        # MLP after the second GAT convolution layer\n",
        "        self.post_mlp2 = Sequential('x, edge_index', [\n",
        "            (Linear(64, 64), 'x -> x'),\n",
        "            (Linear(64, output_features), 'x -> x')\n",
        "        ])\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Process through the first MLP and GAT layer\n",
        "        x = F.relu(self.pre_mlp(x, edge_index))\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Process through the second MLP and GAT layer\n",
        "        x = F.relu(self.post_mlp1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Final MLP processing\n",
        "        x = self.post_mlp2(x, edge_index)\n",
        "        return x.squeeze()  # Output for regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8cibctG9otJ"
      },
      "outputs": [],
      "source": [
        "class DiffGCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, output_features):\n",
        "        super(DiffGCN, self).__init__()\n",
        "\n",
        "        # MLP before the first DiffGCN convolution layer\n",
        "        self.pre_mlp = Sequential('x, edge_index', [\n",
        "            (Linear(num_features, 64), 'x -> x'),\n",
        "            (Linear(64, 64), 'x -> x')\n",
        "        ])\n",
        "\n",
        "        # First DiffGCN convolution layer\n",
        "        self.conv1 = GCNConv(64, 64)\n",
        "\n",
        "        # MLP after the first DiffGCN convolution layer and before the second\n",
        "        self.post_mlp1 = Sequential('x, edge_index', [\n",
        "            (Linear(64, 64), 'x -> x'),\n",
        "            (Linear(64, 64), 'x -> x')\n",
        "        ])\n",
        "\n",
        "        # Second DiffGCN convolution layer\n",
        "        self.conv2 = GCNConv(64, 64)\n",
        "\n",
        "        # Additional diffusion step\n",
        "        self.diffusion_conv = GCNConv(64, 64)\n",
        "\n",
        "        # MLP after the second DiffGCN convolution layer\n",
        "        self.post_mlp2 = Sequential('x, edge_index', [\n",
        "            (Linear(64, 64), 'x -> x'),\n",
        "            (Linear(64, output_features), 'x -> x')\n",
        "        ])\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Process through the first MLP and DiffGCN layer\n",
        "        x = F.relu(self.pre_mlp(x, edge_index))\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Process through the second MLP and DiffGCN layer\n",
        "        x = F.relu(self.post_mlp1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.diffusion_conv(x, edge_index)  # Additional diffusion step\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Final MLP processing\n",
        "        x = self.post_mlp2(x, edge_index)\n",
        "        return x.squeeze()  # Output for regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqYjYPQ35Ls4"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()  # Reset gradients of optimizer\n",
        "    output = model(data)  # Forward pass\n",
        "    loss = criterion(output, data.y.view_as(output))  # Compute loss, ensuring correct shape\n",
        "    loss.backward()  # Backward pass\n",
        "    optimizer.step()  # Update model parameters\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pp73al163k5"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = model(data).detach()\n",
        "    mae = mean_absolute_error(data.y.cpu(), preds.cpu())\n",
        "    mse = mean_squared_error(data.y.cpu(), preds.cpu())\n",
        "    rmse = mean_squared_error(data.y.cpu(), preds.cpu(), squared=False)\n",
        "    median_ae = median_absolute_error(data.y.cpu(), preds.cpu())\n",
        "    r2 = r2_score(data.y.cpu(), preds.cpu())\n",
        "\n",
        "    return {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'MSE': mse,\n",
        "        'Median AE': median_ae,\n",
        "        'R^2': r2\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT8ZBB5364Wf"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'GCN': GCN(num_features=x_tensor.size(1), output_features=1),\n",
        "    # 'GIN': GIN(num_features=x_tensor.size(1), output_features=1),\n",
        "    'GraphSAGE': GraphSAGE(num_features=x_tensor.size(1), output_features=1),\n",
        "    'GAT': GAT(num_features=x_tensor.size(1), output_features=1),\n",
        "    'DiffGCN': DiffGCN(num_features=x_tensor.size(1), output_features=1)\n",
        "    # Define other models similarly: GIN, GAT, GraphSAGE, DiffGCN\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Optimizer\n",
        "    criterion = torch.nn.MSELoss()  # Loss function for regression\n",
        "\n",
        "    # Training loop, for example 100 epochs\n",
        "    for epoch in range(500):\n",
        "        loss = train(model, optimizer, criterion, pyg_graph)\n",
        "\n",
        "    # Evaluate\n",
        "    results[name] = evaluate_model(model, pyg_graph)\n",
        "\n",
        "# Print results\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name} Results:\", metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeeuCGg6_XcQ"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'GCN': GCN(num_features=x_tensor.size(1), output_features=1),\n",
        "    'GIN': GIN(num_features=x_tensor.size(1), output_features=1),\n",
        "    'GraphSAGE': GraphSAGE(num_features=x_tensor.size(1), output_features=1),\n",
        "    'GAT': GAT(num_features=x_tensor.size(1), output_features=1),\n",
        "    'DiffGCN': DiffGCN(num_features=x_tensor.size(1), output_features=1)\n",
        "    # Define other models similarly: GIN, GAT, GraphSAGE, DiffGCN\n",
        "}\n",
        "\n",
        "results = {}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Assuming you have a GPU available\n",
        "\n",
        "for name, model in models.items():\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Optimizer\n",
        "    criterion = torch.nn.MSELoss()  # Loss function for regression\n",
        "\n",
        "    # Training loop, for example 500 epochs\n",
        "    print(f\"Training {name}...\")\n",
        "    for epoch in tqdm(range(500), desc=f\"Epochs ({name})\"):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(pyg_graph)\n",
        "        loss = criterion(output, pyg_graph.y)  # Ensure pyg_graph.y is correctly shaped for regression\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    results[name] = evaluate_model(model, pyg_graph)\n",
        "\n",
        "# Print results\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name} Results:\", metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJhYtoX2C-oy"
      },
      "outputs": [],
      "source": [
        "# Define the metrics and updated colors for visualization\n",
        "metrics = ['MAE', 'RMSE', 'MSE', 'Median AE', 'R^2']\n",
        "colors = [\n",
        "    'rgba(102, 194, 165, 0.8)',  # Soft Green\n",
        "    'rgba(252, 141, 98, 0.8)',   # Soft Orange\n",
        "    'rgba(141, 160, 203, 0.8)',  # Soft Blue\n",
        "    'rgba(231, 138, 195, 0.8)',  # Soft Pink\n",
        "    'rgba(166, 216, 84, 0.8)'    # Lime Green\n",
        "]\n",
        "\n",
        "# Generate plots for each metric\n",
        "for metric in metrics:\n",
        "    fig = go.Figure()\n",
        "    for i, (model_name, model_results) in enumerate(results.items()):\n",
        "        value = model_results.get(metric, None)  # Ensure the metric is available\n",
        "        if value is not None:\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=[model_name],\n",
        "                y=[value],\n",
        "                name=model_name,\n",
        "                marker_color=colors[i % len(colors)],  # Cycle through colors for aesthetics\n",
        "                text=f\"{value:.2f}\",  # Adjusted formatting for numerical precision\n",
        "                textposition='outside'  # Positioning the text outside the bar\n",
        "            ))\n",
        "\n",
        "    # Update the layout for a cleaner look\n",
        "    fig.update_layout(\n",
        "        title=f'{metric} Comparison Across Models',\n",
        "        xaxis_title='Model',\n",
        "        yaxis_title=metric,\n",
        "        template='plotly_white',  # Light theme for a cleaner appearance\n",
        "        barmode='group',\n",
        "        height=400,\n",
        "        width=700,\n",
        "        title_x=0.5,\n",
        "        plot_bgcolor='rgba(255, 255, 255, 0.9)'  # Light background inside the plot area\n",
        "    )\n",
        "\n",
        "    # Display the figure\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsBJjhnKE2tC"
      },
      "outputs": [],
      "source": [
        "model_names = list(results.keys())\n",
        "MAE = [f\"{results[model]['MAE']:.4f}\" for model in model_names]  # Format MAE values to four decimal places\n",
        "RMSE = [f\"{results[model]['RMSE']:.4f}\" for model in model_names]  # Consistent formatting for RMSE\n",
        "MSE = [f\"{results[model]['MSE']:.4f}\" for model in model_names]  # Consistent formatting for MSE\n",
        "Median_AE = [f\"{results[model]['Median AE']:.4f}\" for model in model_names]  # Consistent formatting for Median AE\n",
        "r2 = [f\"{results[model]['R^2']:.4f}\" for model in model_names]  # Consistent formatting for R^2\n",
        "\n",
        "# Creating the table with Plotly\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(values=['Model', 'MAE', 'RMSE', 'MSE', 'Median AE', 'R^2'],\n",
        "        fill_color='#4A5ED7',  # Dark blue header\n",
        "        font=dict(color='white', size=12),\n",
        "        align='left'\n",
        "    ),\n",
        "    cells=dict(\n",
        "        values=[model_names, MAE, RMSE, MSE, Median_AE, r2],\n",
        "        fill_color=[['#222222', '#333333'] * len(results)],  # Alternating dark gray colors for rows\n",
        "        font=dict(color='white', size=11),\n",
        "        align='left',\n",
        "        height=30\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Customize the figure layout\n",
        "fig.update_layout(\n",
        "    title=\"Deep GNN Regression Models' Performance\",\n",
        "    title_x=0.5,\n",
        "    width=1200,\n",
        "    height=900,\n",
        "    paper_bgcolor='#333333',  # Dark background for the entire figure\n",
        "    plot_bgcolor='#333333',  # Dark background for the plot area\n",
        "    font=dict(color='white')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X07dvd9IAVy4"
      },
      "outputs": [],
      "source": [
        "def feature_importance(model, data):\n",
        "    model.eval()\n",
        "    data = data.clone()  # Clone data to avoid changes to the original data\n",
        "    data.x.requires_grad = True  # Enable gradient computation for input features\n",
        "\n",
        "    logits = model(data)  # Forward pass\n",
        "    # Check if logits are already in the correct shape or need reshaping\n",
        "    if logits.dim() == 1:\n",
        "        logits = logits.unsqueeze(1)  # Reshape for binary classification\n",
        "\n",
        "    pred_class = logits.argmax(dim=-1)\n",
        "    # Create a one-hot encoding of the predicted class\n",
        "    one_hot = torch.zeros_like(logits).scatter_(1, pred_class.unsqueeze(1), 1)\n",
        "    logits.backward(one_hot)  # Compute gradients with respect to predicted class\n",
        "\n",
        "    grads = data.x.grad  # Extract gradients\n",
        "    feature_importances = grads.abs().mean(dim=0)  # Average gradient magnitude across all examples\n",
        "    return feature_importances\n",
        "\n",
        "importance = feature_importance(models['GraphSAGE'], pyg_graph)\n",
        "print(\"Feature Importance:\", importance)\n",
        "feature_names = x_deep_df_no_missing.columns.tolist()\n",
        "\n",
        "importance_numpy = importance.detach().cpu().numpy() if isinstance(importance, torch.Tensor) else importance\n",
        "\n",
        "# Ensure the number of feature names matches the number of importance scores\n",
        "feature_names = x_deep_df_encoded_no_missing_graphed.columns.tolist()\n",
        "assert len(feature_names) == len(importance_numpy), \"The number of features must match the number of importance scores.\"\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importance_numpy\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance for better visualization\n",
        "importance_df.sort_values('Importance', ascending=True, inplace=True)\n",
        "\n",
        "# Create a bar chart with color scale\n",
        "fig = px.bar(importance_df, x='Importance', y='Feature', orientation='h',\n",
        "             title='Feature Importance from GIN Model',\n",
        "             labels={'Importance': 'Importance', 'Feature': 'Features'},\n",
        "             width=800, height=600,  # Adjust size as needed\n",
        "             color='Importance'  # Color the bars by their importance value\n",
        "\n",
        ")  # Use a color scale, can be adjusted\n",
        "\n",
        "# Show color scale\n",
        "fig.update_layout(coloraxis_showscale=True, title_x=0.5)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naYtjhoyI5PF"
      },
      "outputs": [],
      "source": [
        "# Convert DataFrame to tensor\n",
        "x_deep_df_encoded_no_missing_graphed = x_deep_df_encoded_no_missing_graphed.apply(pd.to_numeric, errors='coerce')\n",
        "x_tensor = torch.tensor(x_deep_df_encoded_no_missing_graphed.values, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_deep_df_no_missing_classification.values, dtype=torch.long).squeeze()\n",
        "\n",
        "# Create the graph data object\n",
        "pyg_graph = Data(x=x_tensor, y=y_tensor)\n",
        "\n",
        "unique_labels, label_counts = pyg_graph.y.unique(return_counts=True)\n",
        "label_to_indices = {label.item(): (pyg_graph.y == label).nonzero().view(-1) for label in unique_labels}\n",
        "\n",
        "train_indices = []\n",
        "test_indices = []\n",
        "\n",
        "test_ratio = 0.2\n",
        "\n",
        "for label, indices in label_to_indices.items():\n",
        "    # Shuffle indices\n",
        "    permuted_indices = indices[torch.randperm(indices.size(0))]\n",
        "    test_size = int(len(permuted_indices) * test_ratio)\n",
        "\n",
        "    test_indices.append(permuted_indices[:test_size])\n",
        "    train_indices.append(permuted_indices[test_size:])\n",
        "\n",
        "train_indices = torch.cat(train_indices)\n",
        "test_indices = torch.cat(test_indices)\n",
        "\n",
        "# Create train_mask and test_mask\n",
        "train_mask = torch.zeros(pyg_graph.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(pyg_graph.num_nodes, dtype=torch.bool)\n",
        "\n",
        "train_mask[train_indices] = True\n",
        "test_mask[test_indices] = True\n",
        "\n",
        "# Assign masks to the graph data\n",
        "pyg_graph.train_mask = train_mask\n",
        "pyg_graph.test_mask = test_mask\n",
        "\n",
        "pyg_graph = from_networkx(G)\n",
        "edge_index = pyg_graph.edge_index\n",
        "pyg_graph = Data(x=x_tensor, y=y_tensor, edge_index=edge_index, train_mask=train_mask, test_mask=test_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P6V4HLGIBVs"
      },
      "outputs": [],
      "source": [
        "class GIN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GIN, self).__init__()\n",
        "        self.mlp1 = MLP([num_features, 64, 64], norm='batch', dropout=0.5, relu_first=False)\n",
        "        self.conv1 = GINConv(self.mlp1, train_eps=True)\n",
        "        self.mlp2 = MLP([64, 64, 64], norm='batch', dropout=0.5, relu_first=False)\n",
        "        self.conv2 = GINConv(self.mlp2, train_eps=True)\n",
        "        self.lin = torch.nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, data, return_embed=False):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        if return_embed:\n",
        "            return x  # Return embeddings before the classifier\n",
        "        x = self.lin(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDllcBc8Nal7"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        # First MLP applied before the first GCN layer\n",
        "        self.mlp1 = MLP([num_features, 64, 64], norm='batch', dropout=0.5, relu_first=False)\n",
        "\n",
        "        # First GCN layer\n",
        "        self.conv1 = GCNConv(64, 64)\n",
        "\n",
        "        # Second MLP applied after the first GCN layer and before the second GCN layer\n",
        "        self.mlp2 = MLP([64, 64, 64], norm='batch', dropout=0.5, relu_first=False)\n",
        "\n",
        "        # Second GCN layer\n",
        "        self.conv2 = GCNConv(64, 64)\n",
        "\n",
        "        # Final linear layer for classification\n",
        "        self.lin = Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, data, return_embed=False):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Apply first MLP and then the first GCN layer\n",
        "        x = self.mlp1(x)\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        # Apply second MLP and then the second GCN layer\n",
        "        x = self.mlp2(x)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        if return_embed:\n",
        "            return x  # Return embeddings before the classifier\n",
        "        # Apply final linear layer\n",
        "        x = self.lin(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xZu-GrVOJq2"
      },
      "outputs": [],
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GAT, self).__init__()\n",
        "        # First MLP applied before the first GAT layer\n",
        "        self.mlp1 = MLP([num_features, 64, 64], norm='batch', dropout=0.5, relu_first=False)\n",
        "\n",
        "        # First GAT layer with multi-head attention\n",
        "        self.conv1 = GATConv(64, 64, heads=8, dropout=0.6)\n",
        "\n",
        "        # Second MLP applied after the first GAT layer and before the second GAT layer\n",
        "        self.mlp2 = MLP([64 * 8, 64, 64], norm='batch', dropout=0.5, relu_first=False)\n",
        "\n",
        "        # Second GAT layer to consolidate features from the first layer\n",
        "        self.conv2 = GATConv(64, 64, heads=1, concat=True, dropout=0.6)\n",
        "\n",
        "        # Final linear layer for classification\n",
        "        self.lin = Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, data, return_embed=False):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Apply first MLP and then the first GAT layer\n",
        "        x = self.mlp1(x)\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        # Apply second MLP and then the second GAT layer\n",
        "        x = self.mlp2(x)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        if return_embed:\n",
        "            return x  # Return embeddings before the classifier\n",
        "        # Apply final linear layer\n",
        "        x = self.lin(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEDEjIGIIDz3"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output[data.train_mask], data.y[data.train_mask])  # Assuming data.y and data.train_mask are properly set\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate_model(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits.argmax(dim=-1)\n",
        "    correct = (preds[data.test_mask] == data.y[data.test_mask]).sum()\n",
        "    accuracy = int(correct) / int(data.test_mask.sum())\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjsJpSvbR5GK"
      },
      "outputs": [],
      "source": [
        "class DiffGCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):  # Use output_features instead of num_classes\n",
        "        super(DiffGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 64)\n",
        "        self.conv2 = GCNConv(64, 64)\n",
        "        self.conv3 = GCNConv(64, 64)\n",
        "        self.lin = torch.nn.Linear(64, num_classes)  # Adjusted for regression\n",
        "\n",
        "    def forward(self, data, return_embed=False):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Apply GCN layers\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        if return_embed:\n",
        "            return x\n",
        "        # Assuming a single graph, remove global pooling unless necessary\n",
        "        # x = global_mean_pool(x, data.batch)  # Comment this if not needed\n",
        "\n",
        "        # Output layer for regression\n",
        "        x = self.lin(x)\n",
        "        return x  # Return the output directly for regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXroQCV6STxR"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        # First MLP applied before the first GraphSAGE layer\n",
        "        self.mlp1 = MLP([num_features, 64, 64], norm='batch', dropout=0.5, relu_first=False)\n",
        "\n",
        "        # First GraphSAGE layer\n",
        "        self.conv1 = SAGEConv(64, 64)\n",
        "\n",
        "        # Second MLP applied after the first GraphSAGE layer and before the second GraphSAGE layer\n",
        "        self.mlp2 = MLP([64, 64, 64], norm='batch', dropout=0.5, relu_first=False)\n",
        "\n",
        "        # Second GraphSAGE layer\n",
        "        self.conv2 = SAGEConv(64, 64)\n",
        "\n",
        "        # Final linear layer for classification\n",
        "        self.lin = Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, data, return_embed=False):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Apply first MLP and then the first GraphSAGE layer\n",
        "        x = self.mlp1(x)\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        # Apply second MLP and then the second GraphSAGE layer\n",
        "        x = self.mlp2(x)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        if return_embed:\n",
        "            return x\n",
        "        # Apply final linear layer\n",
        "        x = self.lin(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WemVwtkYIGZZ"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'GIN': GIN(num_features=x_tensor.size(1), num_classes=2),\n",
        "    'GCN': GCN(num_features=x_tensor.size(1), num_classes=2),\n",
        "    'GAT': GAT(num_features=x_tensor.size(1), num_classes=2),\n",
        "    'GraphSAGE': GraphSAGE(num_features=x_tensor.size(1), num_classes=2),\n",
        "    'DiffGCN': DiffGCN(num_features=x_tensor.size(1), num_classes=2),\n",
        "    # Define other models similarly: GCN, GraphSAGE, GAT, DiffGCN\n",
        "}\n",
        "\n",
        "results = {}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def evaluate_model(model, data, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits[mask].argmax(dim=1)\n",
        "        labels = data.y[mask]\n",
        "\n",
        "    accuracy = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n",
        "    precision = precision_score(labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
        "    recall = recall_score(labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
        "    f1 = f1_score(labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
        "    macro_f1 = f1_score(labels.cpu().numpy(), preds.cpu().numpy(), average='macro')\n",
        "    cm = confusion_matrix(labels.cpu().numpy(), preds.cpu().numpy())\n",
        "\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(labels.cpu().numpy(), preds.cpu().numpy())\n",
        "    except ValueError:\n",
        "        roc_auc = None  # Handle cases where ROC AUC cannot be computed\n",
        "\n",
        "    return accuracy, precision, recall, f1, macro_f1, roc_auc, cm\n",
        "\n",
        "for name, model in models.items():\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    print(f\"Training {name}...\")\n",
        "    for epoch in tqdm(range(500), desc=f\"Epochs ({name})\"):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(pyg_graph)\n",
        "        loss = criterion(output[pyg_graph.train_mask], pyg_graph.y[pyg_graph.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_accuracy, test_precision, test_recall, test_f1, test_macro_f1, test_roc_auc, test_cm = evaluate_model(model, pyg_graph, pyg_graph.test_mask)\n",
        "    results[name] = {\n",
        "        'Test Accuracy': test_accuracy,\n",
        "        'Test Precision': test_precision,\n",
        "        'Test Recall': test_recall,\n",
        "        'Test F1': test_f1,\n",
        "        'Test Macro F1': test_macro_f1,\n",
        "        'Test ROC AUC': test_roc_auc,\n",
        "        'Confusion Matrix': test_cm\n",
        "    }\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Print results\n",
        "for name, metrics in results.items():\n",
        "    print(f\"\\n{name} Results:\")\n",
        "    for metric, value in metrics.items():\n",
        "        if metric == 'Confusion Matrix':\n",
        "            pass\n",
        "            # print(f\"  {metric}: \\n{value}\")  # Print the confusion matrix directly without formatting\n",
        "        else:\n",
        "            if value is not None:\n",
        "                print(f\"  {metric}: {value:.4f}\")  # Use float formatting for other metrics\n",
        "            else:\n",
        "                print(f\"  {metric}: Not applicable\")  # Handle None values, such as when ROC AUC cannot be computed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3r29zo2ILj-"
      },
      "outputs": [],
      "source": [
        "def create_heatmap(matrix, model_name, color_scale=\"Viridis\"):\n",
        "    \"\"\"\n",
        "    Creates and returns a heatmap figure from a confusion matrix for a given model with a customizable color scale.\n",
        "\n",
        "    Parameters:\n",
        "    - matrix (list of lists): Confusion matrix data.\n",
        "    - model_name (str): Name of the model.\n",
        "    - color_scale (str or list of tuples): Color scale for the heatmap.\n",
        "\n",
        "    Returns:\n",
        "    - plotly.graph_objects.Figure: Heatmap figure of the confusion matrix.\n",
        "    \"\"\"\n",
        "    # Create a heatmap using Plotly\n",
        "    heatmap = go.Heatmap(\n",
        "        z=matrix,\n",
        "        x=['Predicted Negative', 'Predicted Positive'],\n",
        "        y=['Actual Negative', 'Actual Positive'],\n",
        "        showscale=True,\n",
        "        text=matrix,\n",
        "        texttemplate=\"%{text}\",\n",
        "        textfont={\"size\": 12},\n",
        "        colorscale=color_scale\n",
        "    )\n",
        "\n",
        "    # Create a figure and add the heatmap\n",
        "    fig = go.Figure(data=heatmap)\n",
        "\n",
        "    # Update layout with a centered title and appropriate margins\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            'text': f'Confusion Matrix for {model_name}',\n",
        "            'y': 0.9,\n",
        "            'x': 0.5,\n",
        "            'xanchor': 'center',\n",
        "            'font': {'size': 14},\n",
        "            'yanchor': 'top'\n",
        "        },\n",
        "        height=400,\n",
        "        width=400,\n",
        "        margin=dict(l=60, r=60, t=80, b=40)\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "# Generate and display each confusion matrix with an attractive color scale\n",
        "for name, data in results.items():\n",
        "    fig = create_heatmap(data['Confusion Matrix'], name, color_scale=\"rdpu\") # agsunset, rdpu, spectral\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBg4KhwMslF2"
      },
      "outputs": [],
      "source": [
        "def feature_importance(model, data):\n",
        "    model.eval()\n",
        "    data = data.clone()  # Clone data to avoid changes to the original data\n",
        "    data.x.requires_grad = True  # Enable gradient computation for input features\n",
        "\n",
        "    logits = model(data)  # Forward pass\n",
        "    pred_class = logits.argmax(dim=-1)\n",
        "    one_hot = torch.zeros_like(logits).scatter(1, pred_class.view(-1, 1), 1)\n",
        "    logits.backward(one_hot)  # Compute gradients with respect to predicted class\n",
        "\n",
        "    grads = data.x.grad  # Extract gradients\n",
        "    feature_importances = grads.abs().mean(dim=0)  # Average gradient magnitude across all examples\n",
        "    return feature_importances\n",
        "\n",
        "importance = feature_importance(models['GraphSAGE'], pyg_graph)\n",
        "print(\"Feature Importance:\", importance)\n",
        "feature_names = x_deep_df_no_missing.columns.tolist()\n",
        "\n",
        "importance_numpy = importance.detach().cpu().numpy() if isinstance(importance, torch.Tensor) else importance\n",
        "\n",
        "# Ensure the number of feature names matches the number of importance scores\n",
        "feature_names = x_deep_df_encoded_no_missing_graphed.columns.tolist()\n",
        "assert len(feature_names) == len(importance_numpy), \"The number of features must match the number of importance scores.\"\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importance_numpy\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance for better visualization\n",
        "importance_df.sort_values('Importance', ascending=True, inplace=True)\n",
        "\n",
        "# Create a bar chart with color scale\n",
        "fig = px.bar(importance_df, x='Importance', y='Feature', orientation='h',\n",
        "             title='Feature Importance from GIN Model',\n",
        "             labels={'Importance': 'Importance', 'Feature': 'Features'},\n",
        "             width=800, height=600,  # Adjust size as needed\n",
        "             color='Importance'  # Color the bars by their importance value\n",
        "\n",
        ")  # Use a color scale, can be adjusted\n",
        "\n",
        "# Show color scale\n",
        "fig.update_layout(coloraxis_showscale=True, title_x=0.5)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLtYLLLM29EJ"
      },
      "outputs": [],
      "source": [
        "# Assuming model and pyg_graph are properly defined and loaded\n",
        "models['GraphSAGE'].eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = models['GraphSAGE'](pyg_graph, return_embed=True).detach().cpu().numpy()\n",
        "    input_features = pyg_graph.x.detach().cpu().numpy()  # Assuming pyg_graph.x are the input features\n",
        "\n",
        "# Apply t-SNE to the model embeddings\n",
        "tsne_model = TSNE(n_components=2, random_state=42, perplexity=300, n_iter=3000)\n",
        "tsne_results_model = tsne_model.fit_transform(embeddings)\n",
        "\n",
        "# Apply t-SNE to the original input features\n",
        "tsne_input = TSNE(n_components=2, random_state=42, perplexity=300, n_iter=3000)\n",
        "tsne_results_input = tsne_input.fit_transform(input_features)\n",
        "\n",
        "# Creating a contrasting color scheme for binary categories\n",
        "colors = ['rgba(255, 22, 84, 0.8)', 'rgba(34, 150, 243, 0.8)']  # Pink and Blue RGBA colors\n",
        "color_map = {0: colors[0], 1: colors[1]}  # Mapping labels to colors\n",
        "\n",
        "# Create subplot layout\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"t-SNE of Model Embeddings\", \"t-SNE of Original Features\"))\n",
        "\n",
        "# Add scatter plot for model embeddings\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=tsne_results_model[:, 0], y=tsne_results_model[:, 1], mode='markers',\n",
        "               marker=dict(color=[color_map[label] for label in labels], size=8, line=dict(width=0, color='DarkSlateGrey')),\n",
        "               name='Embeddings', showlegend=False),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Add scatter plot for original input features\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=tsne_results_input[:, 0], y=tsne_results_input[:, 1], mode='markers',\n",
        "               marker=dict(color=[color_map[label] for label in labels], size=8, line=dict(width=0, color='DarkSlateGrey')),\n",
        "               name='Input Features', showlegend=False),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Update layout to enhance aesthetics\n",
        "fig.update_layout(\n",
        "    height=600, width=1200,\n",
        "    title_text=\"Comparison of t-SNE Projections\",\n",
        "    title_x=0.5,  # Center the main title\n",
        "    plot_bgcolor='white',  # Set background color to white\n",
        "    showlegend=False  # Ensure legend is not shown\n",
        ")\n",
        "\n",
        "# Update axes properties\n",
        "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', gridcolor='lightgrey')\n",
        "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', gridcolor='lightgrey')\n",
        "\n",
        "# Display the plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36gwEfaD-0sH"
      },
      "outputs": [],
      "source": [
        "# Prepare the data for Plotly visualization from the results dictionary\n",
        "model_names = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "macro_f1s = []\n",
        "roc_aucs = []\n",
        "\n",
        "# Populate the lists with data from the results dictionary\n",
        "for name, metrics in results.items():\n",
        "    model_names.append(name)\n",
        "    accuracies.append(f\"{metrics['Test Accuracy']:.4f}\")\n",
        "    precisions.append(f\"{metrics['Test Precision']:.4f}\")\n",
        "    recalls.append(f\"{metrics['Test Recall']:.4f}\")\n",
        "    f1_scores.append(f\"{metrics['Test F1']:.4f}\")\n",
        "    macro_f1s.append(f\"{metrics['Test Macro F1']:.4f}\")\n",
        "    roc_aucs.append(f\"{metrics['Test ROC AUC']:.4f}\" if metrics['Test ROC AUC'] is not None else 'Not applicable')\n",
        "\n",
        "# Define the table for visualization\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(\n",
        "        values=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Macro F1', 'ROC AUC'],\n",
        "        fill_color='#4A5ED7',  # Dark blue header\n",
        "        font=dict(color='white', size=12),\n",
        "        align='left'\n",
        "    ),\n",
        "    cells=dict(\n",
        "        values=[model_names, accuracies, precisions, recalls, f1_scores, macro_f1s, roc_aucs],\n",
        "        fill_color=[['#222222', '#333333'] * len(results)],  # Alternating dark gray colors for rows\n",
        "        font=dict(color='white', size=11),\n",
        "        align='left',\n",
        "        height=30\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Customize the figure layout\n",
        "fig.update_layout(\n",
        "    title=\"Deep GNN Classification Models' Performance\",\n",
        "    title_x=0.5,\n",
        "    width=1200,\n",
        "    height=900,\n",
        "    paper_bgcolor='#333333',  # Dark background for the entire figure\n",
        "    plot_bgcolor='#333333',  # Dark background for the plot area\n",
        "    font=dict(color='white')\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bIj-4Ict5dH"
      },
      "outputs": [],
      "source": [
        "x_deep_df_encoded_no_missing.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teW_E8nQ-1Ey"
      },
      "outputs": [],
      "source": [
        "x_deep_df_encoded_no_missing_app_int_cat = categorize_the_applications(x_deep_df_encoded_no_missing)\n",
        "x_deep_df_encoded_no_missing_app_int_cat = categorize_and_plot_interviews(x_deep_df_encoded_no_missing_app_int_cat)\n",
        "# y_deep_df_no_missing_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5ceoHxuwtg8"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x_deep_df_encoded_no_missing_app_int_cat, y_deep_df_no_missing_classification, test_size=0.2, stratify=y_deep_df_no_missing_classification, random_state=42)\n",
        "X_train, X_test, y_train, y_test = X_train.to_numpy(dtype=np.float32), X_test.to_numpy(dtype=np.float32), y_train.to_numpy(dtype=np.int64), y_test.to_numpy(dtype=np.int64)\n",
        "X_train, X_test, y_train, y_test = torch.from_numpy(X_train), torch.from_numpy(X_test), torch.from_numpy(y_train), torch.from_numpy(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP14Xxjd4Zle"
      },
      "outputs": [],
      "source": [
        "class ThreeLayerNetWithDropoutAndSkip(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(ThreeLayerNetWithDropoutAndSkip, self).__init__()\n",
        "\n",
        "        # Define the first layer\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Define the second layer\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        # Define the third layer\n",
        "        self.layer3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # Initialize skip connections\n",
        "        self.skip1 = nn.Linear(input_size, hidden_size)\n",
        "        self.skip2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First layer with skip connection\n",
        "        out1 = self.relu(self.layer1(x))\n",
        "        skip_out1 = self.relu(self.skip1(x))\n",
        "        out1 = out1 + skip_out1\n",
        "        out1 = self.dropout(out1)\n",
        "\n",
        "        # Second layer\n",
        "        out2 = self.relu(self.layer2(out1))\n",
        "\n",
        "        # Third layer with skip connection from first layer output\n",
        "        skip_out2 = self.skip2(out1)\n",
        "        out3 = self.layer3(out2) + skip_out2\n",
        "\n",
        "        return out3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtrGTMyqzMtv"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(X, y, batch_size=64, shuffle=True):\n",
        "    tensor_x = torch.tensor(X, dtype=torch.float32)  # Convert features to tensor\n",
        "    tensor_y = torch.tensor(y, dtype=torch.long)     # Convert labels to tensor\n",
        "    dataset = TensorDataset(tensor_x, tensor_y)      # Create dataset\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "# Original data loaders\n",
        "train_loader = create_data_loader(X_train, y_train)\n",
        "test_loader = create_data_loader(X_test, y_test, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9hJSoK_zaVu"
      },
      "outputs": [],
      "source": [
        "def apply_smote(X, y):\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_res, y_res = smote.fit_resample(X, y)\n",
        "    return X_res, y_res\n",
        "\n",
        "# Applying SMOTE\n",
        "X_train_smote, y_train_smote = apply_smote(X_train, y_train)\n",
        "smote_train_loader = create_data_loader(X_train_smote, y_train_smote)\n",
        "\n",
        "def calculate_class_weights(y):\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    classes = np.unique(y)  # This dynamically finds all unique classes\n",
        "    class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
        "    return torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "# Ensure y_train is a numpy array before passing it\n",
        "y_train_np = y_train.numpy() if isinstance(y_train, torch.Tensor) else y_train\n",
        "class_weights = calculate_class_weights(y_train_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA8qmlIXtHQJ"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, train_loader, test_loader, class_weights=None):\n",
        "    # Adjusting criterion for class weights\n",
        "    if class_weights is not None:\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop with tqdm\n",
        "    model.train()\n",
        "    for epoch in range(200):  # Assume 10 epochs for simplicity\n",
        "        loop = tqdm(train_loader, leave=False, desc=f'Epoch {epoch+1}/10')\n",
        "        for inputs, labels in loop:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loop.set_description(f\"Epoch [{epoch+1}/500]\")\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Testing loop\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    y_scores = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            y_true.extend(labels.tolist())\n",
        "            y_pred.extend(predicted.tolist())\n",
        "            # Assuming the model outputs logit scores for ROC AUC which needs softmax for probabilities\n",
        "            softmax_scores = nn.functional.softmax(outputs, dim=1)\n",
        "            y_scores.extend(softmax_scores[:, 1].tolist())  # Assuming class \"1\" is the positive class\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    roc_auc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"Test Precision: {precision:.2f}\")\n",
        "    print(f\"Test Recall: {recall:.2f}\")\n",
        "    print(f\"Test F1: {f1:.2f}\")\n",
        "    print(f\"Test Macro F1: {macro_f1:.2f}\")\n",
        "    print(f\"Test ROC AUC: {roc_auc:.2f}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxiIdSlrrbTt"
      },
      "outputs": [],
      "source": [
        "model = ThreeLayerNetWithDropoutAndSkip(X_train.shape[1], 64, 2)\n",
        "\n",
        "# Test different setups\n",
        "print(\"Training on Original Data:\")\n",
        "train_and_evaluate(model, train_loader, test_loader)\n",
        "\n",
        "print(\"Training on SMOTE Data:\")\n",
        "train_and_evaluate(model, smote_train_loader, test_loader)\n",
        "\n",
        "print(\"Training with Class Weights:\")\n",
        "train_and_evaluate(model, train_loader, test_loader, class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7B39_-FthOJ"
      },
      "outputs": [],
      "source": [
        "class EmbeddingNet(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, output_size):\n",
        "        super(EmbeddingNet, self).__init__()\n",
        "        # The embedding generator part\n",
        "        self.embedding_part = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, embedding_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # The classifier part\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(embedding_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = self.embedding_part(x)\n",
        "        output = self.classifier(embeddings)\n",
        "        return embeddings, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjqv9-LW2t1b"
      },
      "outputs": [],
      "source": [
        "def train_to_get_embeddings(model, train_loader, device):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    model.train()\n",
        "    for epoch in range(100):  # Less epochs as we only need embeddings initially\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            _, outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    print(\"Finished initial training for embeddings.\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czo8Sjze2vwE"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA  # For visualization if needed\n",
        "\n",
        "def oversample_embeddings(model, data_loader, device):\n",
        "    model.eval()\n",
        "    embeddings, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            emb, _ = model(inputs)\n",
        "            embeddings.append(emb.cpu().numpy())\n",
        "            labels.append(targets.cpu().numpy())\n",
        "    embeddings = np.concatenate(embeddings, axis=0)\n",
        "    labels = np.concatenate(labels, axis=0)\n",
        "\n",
        "    # Apply SMOTE in embedding space\n",
        "    smote = SMOTE(random_state=42)\n",
        "    embeddings_smote, labels_smote = smote.fit_resample(embeddings, labels)\n",
        "    return embeddings_smote, labels_smote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB4iO4S823a2"
      },
      "outputs": [],
      "source": [
        "def create_loader_from_embeddings(embeddings, labels, batch_size=64):\n",
        "    embeddings_tensor = torch.tensor(embeddings, dtype=torch.float32)\n",
        "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "    dataset = TensorDataset(embeddings_tensor, labels_tensor)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd2ez_9G28zB"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    y_true, y_pred, y_scores = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            embeddings, outputs = model(inputs)  # Assuming model returns embeddings and output\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "            # Assuming outputs are logits and binary classification; apply sigmoid if needed\n",
        "            probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
        "            y_scores.extend(probabilities[:, 1])  # Adjust depending on your output layer's configuration\n",
        "\n",
        "    # Compute metrics, ensuring all arrays are numpy arrays of the same length\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    roc_auc = roc_auc_score(y_true, y_scores)  # Ensure y_scores are probabilities for the positive class\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Test Precision: {precision:.2f}\")\n",
        "    print(f\"Test Recall: {recall:.2f}\")\n",
        "    print(f\"Test F1: {f1:.2f}\")\n",
        "    print(f\"Test Macro F1: {macro_f1:.2f}\")\n",
        "    print(f\"Test ROC AUC: {roc_auc:.2f}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu22FZH54bJx"
      },
      "outputs": [],
      "source": [
        "model = EmbeddingNet(X_train.shape[1], 64, 2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "trained_model = train_to_get_embeddings(model, train_loader, device)\n",
        "embeddings_smote, labels_smote = oversample_embeddings(trained_model, train_loader, device)\n",
        "smote_loader = create_loader_from_embeddings(embeddings_smote, labels_smote)\n",
        "evaluate_model(trained_model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVjgZzpY4os1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}